# Glove 词向量模型

词向量模型可以分为两种：

1. **全局的词-文本矩阵分解（LSA）**，该方法能有效收集每一个词的统计信息，但却不能捕捉到词的上下文信息（语义的表达能力不够）；这类方法**没有使用到神经网络，属于无监督学习**，具有统计的韵味。

   优点：能够较好的使用到全局的统计信息，并且训练速度较快。

   缺点：最频繁的词对相似性度量的贡献不成比例：例如，两个词与 or 和 and 共同出现的次数将对它们的相似性产生很大影响，但是传达的语义相关性相对较少。同时由于是全局的信息，所以对于语法的贡献也相对弱一些，个人认为语法的信息具有局部性。

2. 基于**局部窗口信息（Word2Vec）**，也就是**基于窗口词的预测方法**，虽然能在词的语义上有更丰富的表达，但是却不能很好的捕捉词的全局统计信息。这类方法使用到了神经网络进行训练，**word2vec本身是无监督的，但是其模型却是有监督的，只不过这个监督学习不需要用户标注，而是自然存在于语料里面**。

   优点：个人认为与构建矩阵方法相比，能够更好的捕捉语法的信息。

   缺点：没有使用到全局的统计信息，在语义相关性方面有所不足。

`GloVe`词向量模型融合了全局矩阵分解方法（Matrix Factorization）和局部文本框捕捉方法（word2vec），是一种用于获得单词矢量表示的**无监督学习**算法——Glove模型则主要将两者进行一定的结合，体现在使用滑动窗口遍历语料库，同时在滑动窗口内更新term-term共现矩阵，这是区别于`LSA`在全局构建[共现矩阵](https://cloud.tencent.com/developer/article/2031146)的，同时又使用到窗口机制的优点。

- 模型目标：进行词的向量化表示，使得向量之间尽可能多地蕴含语义和语法的信息。
- 输入：语料库
- 输出：词向量
- 方法概述：首先基于语料库构建词的共现矩阵，然后基于共现矩阵和`GloVe`模型学习词向量。

> Count-based模型，如GloVe，**本质上是对共现矩阵进行降维。**首先，构建一个词汇的共现矩阵，每一行是一个word，每一列是context。共现矩阵就是计算每个word在每个context出现的频率。由于context是多种词汇的组合，其维度非常大，我们希望像network embedding一样，在context的维度上降维，学习word的低维表示。这一过程可以视为共现矩阵的重构问题，即reconstruction loss。
>
> (降维或者重构的本质是什么？我们选择留下某个维度和丢掉某个维度的标准是什么？Find the lower-dimensional representations which can explain most of the variance in the high-dimensional data，其实也是主成分分析Principal Component Analysis，简称`PCA`，的原理)。

## Glove模型原理

共现矩阵和共现概率比的介绍可见：https://cloud.tencent.com/developer/article/2031146

模型流程：

1）创建term-term共现矩阵

2）依据目标函数进行训练，降低loss

对于term-term共现矩阵只需要定义好窗口大小，语料库等，不同的遍历更新矩阵即可。

构建目标函数的过程：寻找F函数，使得式子成立：$F(w_i,w_j,w_k)=\frac{P_{i,k}}{P_{j,k}}$，其中：

- $w_i$，$w_j$，$w_k$分别是i，j，k的词向量；
- 右边P概率分别表示，i,k与j,k的共现概率，可以从先前建好的term-term矩阵获得

寻找F的过程在此处略，具体详见原论文，这里直接给出最终的目标函数：

![最终的目标函数](https://pic3.zhimg.com/80/v2-64c75191a707e7838c74a787d96202ba_720w.jpg)

实质上就是使用最小二乘法，尽量的缩小下面两者的差异：

![](https://pic1.zhimg.com/80/v2-3c29eeb569ff1c1dae9ef3cf2aabc994_720w.png)

![](https://pic2.zhimg.com/80/v2-796b198c7212e8393771ad8ce648f3dd_720w.png)

同是对于不同的$i$，$j$给予不同的权重，因为不同的词词共现的次数不一样，对于信息的贡献程度也不一样。其权重分配函数为：

![](https://pic3.zhimg.com/80/v2-10dd27b6c2846de37fc92e0b40425cc6_720w.jpg)
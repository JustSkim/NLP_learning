{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "这一篇博客中同样实现了word2vec的计算方法，没有使用到gensim库，使用了torch，numpy，panda和sklearn。\n",
    "\n",
    "\n",
    "博客地址 https://blog.csdn.net/ParisCutie/article/details/109393772\n",
    "在该博客中给出了训练数据下载地址：\n",
    "> 链接:https://pan.baidu.com/s/1tFeK3mXuVXEy3EMarfeWvg 密码:v2z5\n",
    "\n",
    "**训练注意事项**\n",
    "\n",
    "假如有10000个单词的词汇表，再嵌入300维的词向量，那么就会有10000*300多个权重需要计算，这也是很恐怖的维度灾难\n",
    "下面主要介绍这种方法优化训练过程\n",
    "负例采样\n",
    "negative sampling 每次让一个训练样本仅仅更新一小部分的权重参数，从而降低梯度下降过程中的计算量。\n",
    "如果 vocabulary 大小为1万时， 当输入样本 ( “fox”, “quick”) 到神经网络时， “ fox” 经过 one-hot 编码，在输出层我们期望对应 “quick” 单词的那个神经元结点输出 1，其余 9999 个都应该输出 0。在这里，这9999个我们期望输出为0的神经元结点所对应的单词我们为 negative word. negative sampling 的想法也很直接 ，将随机选择一小部分的 negative words，比如选 10个 negative words 来更新对应的权重参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as tud\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\"\"\"\n",
    "先进行一些预处理，导包、用GPU运行、设置随机种子、超参数、还有分词\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "\n",
    "# 为了保证实验结果可以复现，我们经常会把各种random seed固定在某一个值\n",
    "random.seed(53113)\n",
    "np.random.seed(53113)\n",
    "torch.manual_seed(53113)\n",
    "if USE_CUDA:\n",
    "    torch.cuda.manual_seed(53113)\n",
    "    \n",
    "# 设定一些超参数\n",
    "    \n",
    "K = 100 #负样本'''\n",
    "C = 3   #附近词个数'''\n",
    "NUM_EPOCHS = 2 #训练epoch''' \n",
    "MAX_VOCAB_SIZE = 30000 #词典最大数'''\n",
    "BATCH_SIZE = 128 # the batch size\n",
    "LEARNING_RATE = 0.2 # the initial learning rate\n",
    "EMBEDDING_SIZE = 100\n",
    "       \n",
    "    \n",
    "LOG_FILE = \"word-embedding.log\"\n",
    "\n",
    "# tokenize函数，把一篇文本转化成一个个单词\n",
    "def word_tokenize(text):\n",
    "    return text.split()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以通过文本文件读取文字，再创建一个词汇表，前面设置的词汇表最大是30000个，它就是一个字典，然后再添加一个unk表示未知词，再记录单词到index的mapping和index到单词的mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 0,\n",
       " 'of': 1,\n",
       " 'and': 2,\n",
       " 'one': 3,\n",
       " 'in': 4,\n",
       " 'a': 5,\n",
       " 'to': 6,\n",
       " 'zero': 7,\n",
       " 'nine': 8,\n",
       " 'two': 9,\n",
       " 'is': 10,\n",
       " 'as': 11,\n",
       " 'eight': 12,\n",
       " 'for': 13,\n",
       " 's': 14,\n",
       " 'five': 15,\n",
       " 'three': 16,\n",
       " 'was': 17,\n",
       " 'by': 18,\n",
       " 'that': 19,\n",
       " 'four': 20,\n",
       " 'six': 21,\n",
       " 'seven': 22,\n",
       " 'with': 23,\n",
       " 'on': 24,\n",
       " 'are': 25,\n",
       " 'it': 26,\n",
       " 'from': 27,\n",
       " 'or': 28,\n",
       " 'his': 29,\n",
       " 'an': 30,\n",
       " 'be': 31,\n",
       " 'this': 32,\n",
       " 'which': 33,\n",
       " 'at': 34,\n",
       " 'he': 35,\n",
       " 'not': 36,\n",
       " 'also': 37,\n",
       " 'have': 38,\n",
       " 'were': 39,\n",
       " 'has': 40,\n",
       " 'but': 41,\n",
       " 'other': 42,\n",
       " 'their': 43,\n",
       " 'its': 44,\n",
       " 'they': 45,\n",
       " 'first': 46,\n",
       " 'some': 47,\n",
       " 'had': 48,\n",
       " 'more': 49,\n",
       " 'all': 50,\n",
       " 'can': 51,\n",
       " 'most': 52,\n",
       " 'been': 53,\n",
       " 'such': 54,\n",
       " 'many': 55,\n",
       " 'who': 56,\n",
       " 'new': 57,\n",
       " 'there': 58,\n",
       " 'used': 59,\n",
       " 'after': 60,\n",
       " 'when': 61,\n",
       " 'time': 62,\n",
       " 'into': 63,\n",
       " 'these': 64,\n",
       " 'only': 65,\n",
       " 'american': 66,\n",
       " 'see': 67,\n",
       " 'may': 68,\n",
       " 'than': 69,\n",
       " 'i': 70,\n",
       " 'world': 71,\n",
       " 'would': 72,\n",
       " 'b': 73,\n",
       " 'no': 74,\n",
       " 'd': 75,\n",
       " 'however': 76,\n",
       " 'between': 77,\n",
       " 'about': 78,\n",
       " 'over': 79,\n",
       " 'states': 80,\n",
       " 'years': 81,\n",
       " 'people': 82,\n",
       " 'if': 83,\n",
       " 'war': 84,\n",
       " 'during': 85,\n",
       " 'known': 86,\n",
       " 'united': 87,\n",
       " 'called': 88,\n",
       " 'use': 89,\n",
       " 'th': 90,\n",
       " 'system': 91,\n",
       " 'often': 92,\n",
       " 'so': 93,\n",
       " 'state': 94,\n",
       " 'history': 95,\n",
       " 'will': 96,\n",
       " 'up': 97,\n",
       " 'while': 98,\n",
       " 'where': 99,\n",
       " 'city': 100,\n",
       " 'being': 101,\n",
       " 'any': 102,\n",
       " 'then': 103,\n",
       " 'out': 104,\n",
       " 'under': 105,\n",
       " 'both': 106,\n",
       " 'made': 107,\n",
       " 'english': 108,\n",
       " 'e': 109,\n",
       " 'well': 110,\n",
       " 'them': 111,\n",
       " 'number': 112,\n",
       " 'government': 113,\n",
       " 'later': 114,\n",
       " 'him': 115,\n",
       " 'her': 116,\n",
       " 'c': 117,\n",
       " 'since': 118,\n",
       " 'century': 119,\n",
       " 'part': 120,\n",
       " 'name': 121,\n",
       " 'through': 122,\n",
       " 'because': 123,\n",
       " 'university': 124,\n",
       " 'x': 125,\n",
       " 'british': 126,\n",
       " 'early': 127,\n",
       " 'life': 128,\n",
       " 'm': 129,\n",
       " 'like': 130,\n",
       " 'same': 131,\n",
       " 'year': 132,\n",
       " 'including': 133,\n",
       " 'example': 134,\n",
       " 'each': 135,\n",
       " 'became': 136,\n",
       " 'work': 137,\n",
       " 'even': 138,\n",
       " 'language': 139,\n",
       " 'although': 140,\n",
       " 'day': 141,\n",
       " 'form': 142,\n",
       " 'several': 143,\n",
       " 'national': 144,\n",
       " 'john': 145,\n",
       " 'u': 146,\n",
       " 'much': 147,\n",
       " 'g': 148,\n",
       " 'very': 149,\n",
       " 'before': 150,\n",
       " 'general': 151,\n",
       " 'french': 152,\n",
       " 'what': 153,\n",
       " 't': 154,\n",
       " 'against': 155,\n",
       " 'n': 156,\n",
       " 'those': 157,\n",
       " 'high': 158,\n",
       " 'links': 159,\n",
       " 'now': 160,\n",
       " 'could': 161,\n",
       " 'based': 162,\n",
       " 'second': 163,\n",
       " 'another': 164,\n",
       " 'great': 165,\n",
       " 'f': 166,\n",
       " 'do': 167,\n",
       " 'large': 168,\n",
       " 'external': 169,\n",
       " 'list': 170,\n",
       " 'modern': 171,\n",
       " 'different': 172,\n",
       " 'de': 173,\n",
       " 'common': 174,\n",
       " 'german': 175,\n",
       " 'series': 176,\n",
       " 'south': 177,\n",
       " 'music': 178,\n",
       " 'law': 179,\n",
       " 'power': 180,\n",
       " 'set': 181,\n",
       " 'long': 182,\n",
       " 'country': 183,\n",
       " 'major': 184,\n",
       " 'film': 185,\n",
       " 'still': 186,\n",
       " 'until': 187,\n",
       " 'group': 188,\n",
       " 'king': 189,\n",
       " 'game': 190,\n",
       " 'north': 191,\n",
       " 'she': 192,\n",
       " 'international': 193,\n",
       " 'term': 194,\n",
       " 'book': 195,\n",
       " 'we': 196,\n",
       " 'found': 197,\n",
       " 'end': 198,\n",
       " 'own': 199,\n",
       " 'order': 200,\n",
       " 'political': 201,\n",
       " 'usually': 202,\n",
       " 'church': 203,\n",
       " 'party': 204,\n",
       " 'death': 205,\n",
       " 'you': 206,\n",
       " 'god': 207,\n",
       " 'president': 208,\n",
       " 'area': 209,\n",
       " 'around': 210,\n",
       " 'theory': 211,\n",
       " 'include': 212,\n",
       " 'way': 213,\n",
       " 'did': 214,\n",
       " 'though': 215,\n",
       " 'ii': 216,\n",
       " 'using': 217,\n",
       " 'small': 218,\n",
       " 'following': 219,\n",
       " 'within': 220,\n",
       " 'non': 221,\n",
       " 'human': 222,\n",
       " 'left': 223,\n",
       " 'military': 224,\n",
       " 'point': 225,\n",
       " 'among': 226,\n",
       " 'p': 227,\n",
       " 'population': 228,\n",
       " 'main': 229,\n",
       " 'r': 230,\n",
       " 'considered': 231,\n",
       " 'due': 232,\n",
       " 'public': 233,\n",
       " 'west': 234,\n",
       " 'computer': 235,\n",
       " 'information': 236,\n",
       " 'family': 237,\n",
       " 'important': 238,\n",
       " 'right': 239,\n",
       " 'east': 240,\n",
       " 'popular': 241,\n",
       " 'sometimes': 242,\n",
       " 'european': 243,\n",
       " 'man': 244,\n",
       " 'old': 245,\n",
       " 'free': 246,\n",
       " 'without': 247,\n",
       " 'given': 248,\n",
       " 'members': 249,\n",
       " 'us': 250,\n",
       " 'last': 251,\n",
       " 'word': 252,\n",
       " 'times': 253,\n",
       " 'roman': 254,\n",
       " 'h': 255,\n",
       " 'make': 256,\n",
       " 'science': 257,\n",
       " 'age': 258,\n",
       " 'place': 259,\n",
       " 'l': 260,\n",
       " 'thus': 261,\n",
       " 'case': 262,\n",
       " 'does': 263,\n",
       " 'house': 264,\n",
       " 'languages': 265,\n",
       " 'countries': 266,\n",
       " 'article': 267,\n",
       " 'become': 268,\n",
       " 'born': 269,\n",
       " 'union': 270,\n",
       " 'york': 271,\n",
       " 'isbn': 272,\n",
       " 'should': 273,\n",
       " 'others': 274,\n",
       " 'back': 275,\n",
       " 'period': 276,\n",
       " 'systems': 277,\n",
       " 'water': 278,\n",
       " 'led': 279,\n",
       " 'various': 280,\n",
       " 'k': 281,\n",
       " 'central': 282,\n",
       " 'line': 283,\n",
       " 'europe': 284,\n",
       " 'st': 285,\n",
       " 'few': 286,\n",
       " 'began': 287,\n",
       " 'generally': 288,\n",
       " 'home': 289,\n",
       " 'must': 290,\n",
       " 'less': 291,\n",
       " 'written': 292,\n",
       " 'control': 293,\n",
       " 'island': 294,\n",
       " 'western': 295,\n",
       " 'similar': 296,\n",
       " 'best': 297,\n",
       " 'original': 298,\n",
       " 'according': 299,\n",
       " 'air': 300,\n",
       " 'school': 301,\n",
       " 'works': 302,\n",
       " 'v': 303,\n",
       " 'player': 304,\n",
       " 'land': 305,\n",
       " 'single': 306,\n",
       " 'force': 307,\n",
       " 'france': 308,\n",
       " 'down': 309,\n",
       " 'how': 310,\n",
       " 'groups': 311,\n",
       " 'england': 312,\n",
       " 'development': 313,\n",
       " 'official': 314,\n",
       " 'rather': 315,\n",
       " 'greek': 316,\n",
       " 'space': 317,\n",
       " 'j': 318,\n",
       " 'support': 319,\n",
       " 'germany': 320,\n",
       " 'london': 321,\n",
       " 'data': 322,\n",
       " 'km': 323,\n",
       " 'named': 324,\n",
       " 'published': 325,\n",
       " 'just': 326,\n",
       " 'said': 327,\n",
       " 'black': 328,\n",
       " 'games': 329,\n",
       " 'every': 330,\n",
       " 'late': 331,\n",
       " 'christian': 332,\n",
       " 'short': 333,\n",
       " 'body': 334,\n",
       " 'off': 335,\n",
       " 'earth': 336,\n",
       " 'empire': 337,\n",
       " 'o': 338,\n",
       " 'economic': 339,\n",
       " 'college': 340,\n",
       " 'army': 341,\n",
       " 'company': 342,\n",
       " 'either': 343,\n",
       " 'social': 344,\n",
       " 'version': 345,\n",
       " 'million': 346,\n",
       " 'kingdom': 347,\n",
       " 'court': 348,\n",
       " 'field': 349,\n",
       " 'standard': 350,\n",
       " 'along': 351,\n",
       " 'service': 352,\n",
       " 'sea': 353,\n",
       " 'developed': 354,\n",
       " 'means': 355,\n",
       " 'america': 356,\n",
       " 'result': 357,\n",
       " 'light': 358,\n",
       " 'never': 359,\n",
       " 'today': 360,\n",
       " 'team': 361,\n",
       " 'especially': 362,\n",
       " 'held': 363,\n",
       " 'society': 364,\n",
       " 'further': 365,\n",
       " 'character': 366,\n",
       " 'take': 367,\n",
       " 'third': 368,\n",
       " 'forces': 369,\n",
       " 'open': 370,\n",
       " 'books': 371,\n",
       " 'republic': 372,\n",
       " 'possible': 373,\n",
       " 'fact': 374,\n",
       " 'men': 375,\n",
       " 'show': 376,\n",
       " 'took': 377,\n",
       " 'battle': 378,\n",
       " 'good': 379,\n",
       " 'children': 380,\n",
       " 'natural': 381,\n",
       " 'son': 382,\n",
       " 'having': 383,\n",
       " 'present': 384,\n",
       " 'himself': 385,\n",
       " 'current': 386,\n",
       " 'former': 387,\n",
       " 'local': 388,\n",
       " 'person': 389,\n",
       " 'process': 390,\n",
       " 'islands': 391,\n",
       " 'words': 392,\n",
       " 'white': 393,\n",
       " 'little': 394,\n",
       " 'above': 395,\n",
       " 'near': 396,\n",
       " 'father': 397,\n",
       " 'total': 398,\n",
       " 'soviet': 399,\n",
       " 'itself': 400,\n",
       " 'side': 401,\n",
       " 'upon': 402,\n",
       " 'red': 403,\n",
       " 'seen': 404,\n",
       " 'culture': 405,\n",
       " 'references': 406,\n",
       " 'play': 407,\n",
       " 'days': 408,\n",
       " 'river': 409,\n",
       " 'came': 410,\n",
       " 'level': 411,\n",
       " 'certain': 412,\n",
       " 'largest': 413,\n",
       " 'press': 414,\n",
       " 'once': 415,\n",
       " 'created': 416,\n",
       " 'famous': 417,\n",
       " 'jewish': 418,\n",
       " 'almost': 419,\n",
       " 'full': 420,\n",
       " 'james': 421,\n",
       " 'software': 422,\n",
       " 'numbers': 423,\n",
       " 'al': 424,\n",
       " 'role': 425,\n",
       " 'january': 426,\n",
       " 'region': 427,\n",
       " 'site': 428,\n",
       " 'member': 429,\n",
       " 'areas': 430,\n",
       " 'image': 431,\n",
       " 'story': 432,\n",
       " 'religious': 433,\n",
       " 'community': 434,\n",
       " 'again': 435,\n",
       " 'ancient': 436,\n",
       " 'act': 437,\n",
       " 'art': 438,\n",
       " 'real': 439,\n",
       " 'played': 440,\n",
       " 'related': 441,\n",
       " 'view': 442,\n",
       " 'league': 443,\n",
       " 'movement': 444,\n",
       " 'rights': 445,\n",
       " 'production': 446,\n",
       " 'terms': 447,\n",
       " 'center': 448,\n",
       " 'low': 449,\n",
       " 'energy': 450,\n",
       " 'foreign': 451,\n",
       " 'died': 452,\n",
       " 'council': 453,\n",
       " 'change': 454,\n",
       " 'type': 455,\n",
       " 'source': 456,\n",
       " 'research': 457,\n",
       " 'living': 458,\n",
       " 'december': 459,\n",
       " 'produced': 460,\n",
       " 'class': 461,\n",
       " 'canada': 462,\n",
       " 'bc': 463,\n",
       " 'particular': 464,\n",
       " 'making': 465,\n",
       " 'head': 466,\n",
       " 'william': 467,\n",
       " 'latin': 468,\n",
       " 'northern': 469,\n",
       " 'forms': 470,\n",
       " 'design': 471,\n",
       " 'minister': 472,\n",
       " 'style': 473,\n",
       " 'david': 474,\n",
       " 'available': 475,\n",
       " 'civil': 476,\n",
       " 'japanese': 477,\n",
       " 'next': 478,\n",
       " 'special': 479,\n",
       " 'position': 480,\n",
       " 'program': 481,\n",
       " 'w': 482,\n",
       " 'march': 483,\n",
       " 'far': 484,\n",
       " 'women': 485,\n",
       " 'chinese': 486,\n",
       " 'released': 487,\n",
       " 'established': 488,\n",
       " 'y': 489,\n",
       " 'television': 490,\n",
       " 'george': 491,\n",
       " 'together': 492,\n",
       " 'eastern': 493,\n",
       " 'function': 494,\n",
       " 'hand': 495,\n",
       " 'middle': 496,\n",
       " 'july': 497,\n",
       " 'charles': 498,\n",
       " 'might': 499,\n",
       " 'parts': 500,\n",
       " 'china': 501,\n",
       " 'instead': 502,\n",
       " 'code': 503,\n",
       " 'band': 504,\n",
       " 'built': 505,\n",
       " 'thought': 506,\n",
       " 'least': 507,\n",
       " 'india': 508,\n",
       " 'included': 509,\n",
       " 'study': 510,\n",
       " 'meaning': 511,\n",
       " 'emperor': 512,\n",
       " 'june': 513,\n",
       " 'half': 514,\n",
       " 'text': 515,\n",
       " 'always': 516,\n",
       " 'anti': 517,\n",
       " 'range': 518,\n",
       " 'actor': 519,\n",
       " 'trade': 520,\n",
       " 'per': 521,\n",
       " 'final': 522,\n",
       " 'traditional': 523,\n",
       " 'capital': 524,\n",
       " 'uk': 525,\n",
       " 'young': 526,\n",
       " 'taken': 527,\n",
       " 'prime': 528,\n",
       " 'november': 529,\n",
       " 'economy': 530,\n",
       " 'nature': 531,\n",
       " 'october': 532,\n",
       " 'august': 533,\n",
       " 'lost': 534,\n",
       " 'players': 535,\n",
       " 'april': 536,\n",
       " 'addition': 537,\n",
       " 'spanish': 538,\n",
       " 'uses': 539,\n",
       " 'live': 540,\n",
       " 'run': 541,\n",
       " 'true': 542,\n",
       " 'recent': 543,\n",
       " 'value': 544,\n",
       " 'project': 545,\n",
       " 'wrote': 546,\n",
       " 'effect': 547,\n",
       " 'technology': 548,\n",
       " 'september': 549,\n",
       " 'evidence': 550,\n",
       " 'southern': 551,\n",
       " 'catholic': 552,\n",
       " 'note': 553,\n",
       " 'historical': 554,\n",
       " 'radio': 555,\n",
       " 'whose': 556,\n",
       " 'album': 557,\n",
       " 'model': 558,\n",
       " 'top': 559,\n",
       " 'italian': 560,\n",
       " 'africa': 561,\n",
       " 'self': 562,\n",
       " 'rule': 563,\n",
       " 'won': 564,\n",
       " 'australia': 565,\n",
       " 'done': 566,\n",
       " 'particularly': 567,\n",
       " 'themselves': 568,\n",
       " 'philosophy': 569,\n",
       " 'cases': 570,\n",
       " 'influence': 571,\n",
       " 'species': 572,\n",
       " 'structure': 573,\n",
       " 'rate': 574,\n",
       " 'subject': 575,\n",
       " 'record': 576,\n",
       " 'nations': 577,\n",
       " 'russian': 578,\n",
       " 'referred': 579,\n",
       " 'our': 580,\n",
       " 'below': 581,\n",
       " 'love': 582,\n",
       " 'throughout': 583,\n",
       " 'continued': 584,\n",
       " 'problem': 585,\n",
       " 'star': 586,\n",
       " 'japan': 587,\n",
       " 'whether': 588,\n",
       " 'therefore': 589,\n",
       " 'education': 590,\n",
       " 'rock': 591,\n",
       " 'song': 592,\n",
       " 'israel': 593,\n",
       " 'irish': 594,\n",
       " 'come': 595,\n",
       " 'names': 596,\n",
       " 'title': 597,\n",
       " 'higher': 598,\n",
       " 'films': 599,\n",
       " 'town': 600,\n",
       " 'too': 601,\n",
       " 'com': 602,\n",
       " 'jews': 603,\n",
       " 'action': 604,\n",
       " 'originally': 605,\n",
       " 'february': 606,\n",
       " 'individual': 607,\n",
       " 'cities': 608,\n",
       " 'paul': 609,\n",
       " 'strong': 610,\n",
       " 'elements': 611,\n",
       " 'market': 612,\n",
       " 'football': 613,\n",
       " 'my': 614,\n",
       " 'here': 615,\n",
       " 'sound': 616,\n",
       " 'network': 617,\n",
       " 'eventually': 618,\n",
       " 'est': 619,\n",
       " 'independent': 620,\n",
       " 'author': 621,\n",
       " 'described': 622,\n",
       " 'base': 623,\n",
       " 'despite': 624,\n",
       " 'problems': 625,\n",
       " 'characters': 626,\n",
       " 'robert': 627,\n",
       " 'female': 628,\n",
       " 'la': 629,\n",
       " 'food': 630,\n",
       " 'internet': 631,\n",
       " 'able': 632,\n",
       " 'formed': 633,\n",
       " 'practice': 634,\n",
       " 're': 635,\n",
       " 'office': 636,\n",
       " 'royal': 637,\n",
       " 'complex': 638,\n",
       " 'commonly': 639,\n",
       " 'events': 640,\n",
       " 'fiction': 641,\n",
       " 'parliament': 642,\n",
       " 'received': 643,\n",
       " 'season': 644,\n",
       " 'key': 645,\n",
       " 'lower': 646,\n",
       " 'african': 647,\n",
       " 'writer': 648,\n",
       " 'legal': 649,\n",
       " 'outside': 650,\n",
       " 'typically': 651,\n",
       " 'complete': 652,\n",
       " 'followed': 653,\n",
       " 'significant': 654,\n",
       " 'page': 655,\n",
       " 'basic': 656,\n",
       " 'actually': 657,\n",
       " 'includes': 658,\n",
       " 'business': 659,\n",
       " 'aircraft': 660,\n",
       " 'widely': 661,\n",
       " 'scientific': 662,\n",
       " 'beginning': 663,\n",
       " 'male': 664,\n",
       " 'laws': 665,\n",
       " 'physical': 666,\n",
       " 'types': 667,\n",
       " 'deaths': 668,\n",
       " 'building': 669,\n",
       " 'henry': 670,\n",
       " 'future': 671,\n",
       " 'leader': 672,\n",
       " 'material': 673,\n",
       " 'went': 674,\n",
       " 'cannot': 675,\n",
       " 'britain': 676,\n",
       " 'news': 677,\n",
       " 'get': 678,\n",
       " 'simply': 679,\n",
       " 'cross': 680,\n",
       " 'ever': 681,\n",
       " 'ireland': 682,\n",
       " 'services': 683,\n",
       " 'industry': 684,\n",
       " 'fire': 685,\n",
       " 'elected': 686,\n",
       " 'close': 687,\n",
       " 'method': 688,\n",
       " 'specific': 689,\n",
       " 'cause': 690,\n",
       " 'defined': 691,\n",
       " 'canadian': 692,\n",
       " 'go': 693,\n",
       " 'believe': 694,\n",
       " 'examples': 695,\n",
       " 'writing': 696,\n",
       " 'california': 697,\n",
       " 'post': 698,\n",
       " 'mass': 699,\n",
       " 'births': 700,\n",
       " 'size': 701,\n",
       " 'lead': 702,\n",
       " 'video': 703,\n",
       " 'return': 704,\n",
       " 'knowledge': 705,\n",
       " 'independence': 706,\n",
       " 'idea': 707,\n",
       " 'points': 708,\n",
       " 'organization': 709,\n",
       " 'associated': 710,\n",
       " 'personal': 711,\n",
       " 'sense': 712,\n",
       " 'soon': 713,\n",
       " 'classical': 714,\n",
       " 'introduced': 715,\n",
       " 'required': 716,\n",
       " 'majority': 717,\n",
       " 'movie': 718,\n",
       " 'concept': 719,\n",
       " 'designed': 720,\n",
       " 'yet': 721,\n",
       " 'away': 722,\n",
       " 'changes': 723,\n",
       " 'believed': 724,\n",
       " 'located': 725,\n",
       " 'co': 726,\n",
       " 'county': 727,\n",
       " 'studies': 728,\n",
       " 'religion': 729,\n",
       " 'lord': 730,\n",
       " 'blue': 731,\n",
       " 'indian': 732,\n",
       " 'rules': 733,\n",
       " 'find': 734,\n",
       " 'features': 735,\n",
       " 'started': 736,\n",
       " 'mother': 737,\n",
       " 'put': 738,\n",
       " 'currently': 739,\n",
       " 'ball': 740,\n",
       " 'working': 741,\n",
       " 'policy': 742,\n",
       " 'russia': 743,\n",
       " 'earlier': 744,\n",
       " 'election': 745,\n",
       " 'thomas': 746,\n",
       " 'sources': 747,\n",
       " 'brought': 748,\n",
       " 'provide': 749,\n",
       " 'allowed': 750,\n",
       " 'association': 751,\n",
       " 'things': 752,\n",
       " 'greater': 753,\n",
       " 'online': 754,\n",
       " 'australian': 755,\n",
       " 'attack': 756,\n",
       " 'added': 757,\n",
       " 'across': 758,\n",
       " 'founded': 759,\n",
       " 'relations': 760,\n",
       " 'object': 761,\n",
       " 'limited': 762,\n",
       " 'mostly': 763,\n",
       " 'federal': 764,\n",
       " 'effects': 765,\n",
       " 'interest': 766,\n",
       " 'z': 767,\n",
       " 'probably': 768,\n",
       " 'reference': 769,\n",
       " 'past': 770,\n",
       " 'career': 771,\n",
       " 'security': 772,\n",
       " 'stories': 773,\n",
       " 'need': 774,\n",
       " 'your': 775,\n",
       " 'simple': 776,\n",
       " 'gave': 777,\n",
       " 'constitution': 778,\n",
       " 'park': 779,\n",
       " 'letter': 780,\n",
       " 'remains': 781,\n",
       " 'me': 782,\n",
       " 'success': 783,\n",
       " 'longer': 784,\n",
       " 'growth': 785,\n",
       " 'killed': 786,\n",
       " 'say': 787,\n",
       " 'give': 788,\n",
       " 'chief': 789,\n",
       " 'definition': 790,\n",
       " 'media': 791,\n",
       " 'wide': 792,\n",
       " 'night': 793,\n",
       " 'letters': 794,\n",
       " 'leading': 795,\n",
       " 'website': 796,\n",
       " 'library': 797,\n",
       " 'contains': 798,\n",
       " 'green': 799,\n",
       " 'remained': 800,\n",
       " 'etc': 801,\n",
       " 'largely': 802,\n",
       " 'color': 803,\n",
       " 'moved': 804,\n",
       " 'months': 805,\n",
       " 'spain': 806,\n",
       " 'dead': 807,\n",
       " 'big': 808,\n",
       " 'better': 809,\n",
       " 'larger': 810,\n",
       " 'already': 811,\n",
       " 'perhaps': 812,\n",
       " 'novel': 813,\n",
       " 'speed': 814,\n",
       " 'peace': 815,\n",
       " 'holy': 816,\n",
       " 'help': 817,\n",
       " 'territory': 818,\n",
       " 'cell': 819,\n",
       " 'parties': 820,\n",
       " 'cultural': 821,\n",
       " 'politics': 822,\n",
       " 'origin': 823,\n",
       " 'companies': 824,\n",
       " 'lake': 825,\n",
       " 'private': 826,\n",
       " 'claim': 827,\n",
       " 'saint': 828,\n",
       " 'iii': 829,\n",
       " 'wife': 830,\n",
       " 'saw': 831,\n",
       " 'dutch': 832,\n",
       " 'revolution': 833,\n",
       " 'appeared': 834,\n",
       " 'refer': 835,\n",
       " 'matter': 836,\n",
       " 'makes': 837,\n",
       " 'whole': 838,\n",
       " 'lines': 839,\n",
       " 'era': 840,\n",
       " 'directly': 841,\n",
       " 'separate': 842,\n",
       " 'products': 843,\n",
       " 'italy': 844,\n",
       " 'results': 845,\n",
       " 'produce': 846,\n",
       " 'surface': 847,\n",
       " 'asia': 848,\n",
       " 'highly': 849,\n",
       " 'caused': 850,\n",
       " 'attempt': 851,\n",
       " 'authority': 852,\n",
       " 'double': 853,\n",
       " 'coast': 854,\n",
       " 'status': 855,\n",
       " 'alexander': 856,\n",
       " 'successful': 857,\n",
       " 'health': 858,\n",
       " 'turn': 859,\n",
       " 'literature': 860,\n",
       " 'towards': 861,\n",
       " 'playing': 862,\n",
       " 'direct': 863,\n",
       " 'oil': 864,\n",
       " 'blood': 865,\n",
       " 'richard': 866,\n",
       " 'singer': 867,\n",
       " 'latter': 868,\n",
       " 'whom': 869,\n",
       " 'primary': 870,\n",
       " 'treaty': 871,\n",
       " 'division': 872,\n",
       " 'becomes': 873,\n",
       " 'basis': 874,\n",
       " 'analysis': 875,\n",
       " 'date': 876,\n",
       " 'enough': 877,\n",
       " 'married': 878,\n",
       " 'edition': 879,\n",
       " 'chemical': 880,\n",
       " 'exist': 881,\n",
       " 'nation': 882,\n",
       " 'prize': 883,\n",
       " 'issues': 884,\n",
       " 'native': 885,\n",
       " 'programming': 886,\n",
       " 'likely': 887,\n",
       " 'commercial': 888,\n",
       " 'property': 889,\n",
       " 'release': 890,\n",
       " 'web': 891,\n",
       " 'amount': 892,\n",
       " 'allow': 893,\n",
       " 'course': 894,\n",
       " 'reason': 895,\n",
       " 'machine': 896,\n",
       " 'provided': 897,\n",
       " 'sun': 898,\n",
       " 'smaller': 899,\n",
       " 'money': 900,\n",
       " 'museum': 901,\n",
       " 'digital': 902,\n",
       " 'functions': 903,\n",
       " 'jesus': 904,\n",
       " 'divided': 905,\n",
       " 'average': 906,\n",
       " 'replaced': 907,\n",
       " 'metal': 908,\n",
       " 'length': 909,\n",
       " 'degree': 910,\n",
       " 'gas': 911,\n",
       " 'peter': 912,\n",
       " 'tradition': 913,\n",
       " 'memory': 914,\n",
       " 'claims': 915,\n",
       " 'nearly': 916,\n",
       " 'tv': 917,\n",
       " 'washington': 918,\n",
       " 'access': 919,\n",
       " 'difficult': 920,\n",
       " 'rome': 921,\n",
       " 'notable': 922,\n",
       " 'ground': 923,\n",
       " 'medical': 924,\n",
       " 'queen': 925,\n",
       " 'claimed': 926,\n",
       " 'mid': 927,\n",
       " 'recently': 928,\n",
       " 'ten': 929,\n",
       " 'records': 930,\n",
       " 'collection': 931,\n",
       " 'animals': 932,\n",
       " 'involved': 933,\n",
       " 'schools': 934,\n",
       " 'read': 935,\n",
       " 'finally': 936,\n",
       " 'front': 937,\n",
       " 'sent': 938,\n",
       " 'performance': 939,\n",
       " 'variety': 940,\n",
       " 'changed': 941,\n",
       " 'director': 942,\n",
       " 'elections': 943,\n",
       " 'frequently': 944,\n",
       " 'liberal': 945,\n",
       " 'congress': 946,\n",
       " 'entire': 947,\n",
       " 'hard': 948,\n",
       " 'highest': 949,\n",
       " 'methods': 950,\n",
       " 'club': 951,\n",
       " 'democratic': 952,\n",
       " 'mark': 953,\n",
       " 'ideas': 954,\n",
       " 'product': 955,\n",
       " 'don': 956,\n",
       " 'served': 957,\n",
       " 'christ': 958,\n",
       " 'programs': 959,\n",
       " 'section': 960,\n",
       " 'increased': 961,\n",
       " 'louis': 962,\n",
       " 'call': 963,\n",
       " 'board': 964,\n",
       " 'relationship': 965,\n",
       " 'bbc': 966,\n",
       " 'students': 967,\n",
       " 'michael': 968,\n",
       " 'relatively': 969,\n",
       " 'discovered': 970,\n",
       " 'element': 971,\n",
       " 'conditions': 972,\n",
       " 'objects': 973,\n",
       " 'increase': 974,\n",
       " 'unit': 975,\n",
       " 'actress': 976,\n",
       " 'child': 977,\n",
       " 'appear': 978,\n",
       " 'returned': 979,\n",
       " 'existence': 980,\n",
       " 'rest': 981,\n",
       " 'appears': 982,\n",
       " 'map': 983,\n",
       " 'fall': 984,\n",
       " 'musical': 985,\n",
       " 'know': 986,\n",
       " 'minor': 987,\n",
       " 'baseball': 988,\n",
       " 'adopted': 989,\n",
       " 'orthodox': 990,\n",
       " 'except': 991,\n",
       " 'assembly': 992,\n",
       " 'nuclear': 993,\n",
       " 'user': 994,\n",
       " 'takes': 995,\n",
       " 'san': 996,\n",
       " 'event': 997,\n",
       " 'hall': 998,\n",
       " 'heavy': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 这里导入作者给出的数据集中的训练集，在数据集文件夹的readme.md文件中有进行说明\n",
    "with open(\"F:\\\\自然语言处理数据集\\\\text8\\\\text8.train.txt\", \"r\") as fin:\n",
    "    text = fin.read()\n",
    "    \n",
    "\n",
    "#分词后变小写\n",
    "text = [w for w in word_tokenize(text.lower())]\n",
    "vocab = dict(Counter(text).most_common(MAX_VOCAB_SIZE-1))\n",
    "# 未知词\n",
    "vocab[\"<unk>\"] = len(text) - np.sum(list(vocab.values()))\n",
    "idx_to_word = [word for word in vocab.keys()] \n",
    "word_to_idx = {word:i for i, word in enumerate(idx_to_word)}\n",
    "word_to_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 0,\n",
       " 'of': 1,\n",
       " 'and': 2,\n",
       " 'one': 3,\n",
       " 'in': 4,\n",
       " 'a': 5,\n",
       " 'to': 6,\n",
       " 'zero': 7,\n",
       " 'nine': 8,\n",
       " 'two': 9,\n",
       " 'is': 10,\n",
       " 'as': 11,\n",
       " 'eight': 12,\n",
       " 'for': 13,\n",
       " 's': 14,\n",
       " 'five': 15,\n",
       " 'three': 16,\n",
       " 'was': 17,\n",
       " 'by': 18,\n",
       " 'that': 19,\n",
       " 'four': 20,\n",
       " 'six': 21,\n",
       " 'seven': 22,\n",
       " 'with': 23,\n",
       " 'on': 24,\n",
       " 'are': 25,\n",
       " 'it': 26,\n",
       " 'from': 27,\n",
       " 'or': 28,\n",
       " 'his': 29,\n",
       " 'an': 30,\n",
       " 'be': 31,\n",
       " 'this': 32,\n",
       " 'which': 33,\n",
       " 'at': 34,\n",
       " 'he': 35,\n",
       " 'not': 36,\n",
       " 'also': 37,\n",
       " 'have': 38,\n",
       " 'were': 39,\n",
       " 'has': 40,\n",
       " 'but': 41,\n",
       " 'other': 42,\n",
       " 'their': 43,\n",
       " 'its': 44,\n",
       " 'they': 45,\n",
       " 'first': 46,\n",
       " 'some': 47,\n",
       " 'had': 48,\n",
       " 'more': 49,\n",
       " 'all': 50,\n",
       " 'can': 51,\n",
       " 'most': 52,\n",
       " 'been': 53,\n",
       " 'such': 54,\n",
       " 'many': 55,\n",
       " 'who': 56,\n",
       " 'new': 57,\n",
       " 'there': 58,\n",
       " 'used': 59,\n",
       " 'after': 60,\n",
       " 'when': 61,\n",
       " 'time': 62,\n",
       " 'into': 63,\n",
       " 'these': 64,\n",
       " 'only': 65,\n",
       " 'american': 66,\n",
       " 'see': 67,\n",
       " 'may': 68,\n",
       " 'than': 69,\n",
       " 'i': 70,\n",
       " 'world': 71,\n",
       " 'would': 72,\n",
       " 'b': 73,\n",
       " 'no': 74,\n",
       " 'd': 75,\n",
       " 'however': 76,\n",
       " 'between': 77,\n",
       " 'about': 78,\n",
       " 'over': 79,\n",
       " 'states': 80,\n",
       " 'years': 81,\n",
       " 'people': 82,\n",
       " 'if': 83,\n",
       " 'war': 84,\n",
       " 'during': 85,\n",
       " 'known': 86,\n",
       " 'united': 87,\n",
       " 'called': 88,\n",
       " 'use': 89,\n",
       " 'th': 90,\n",
       " 'system': 91,\n",
       " 'often': 92,\n",
       " 'so': 93,\n",
       " 'state': 94,\n",
       " 'history': 95,\n",
       " 'will': 96,\n",
       " 'up': 97,\n",
       " 'while': 98,\n",
       " 'where': 99,\n",
       " 'city': 100,\n",
       " 'being': 101,\n",
       " 'any': 102,\n",
       " 'then': 103,\n",
       " 'out': 104,\n",
       " 'under': 105,\n",
       " 'both': 106,\n",
       " 'made': 107,\n",
       " 'english': 108,\n",
       " 'e': 109,\n",
       " 'well': 110,\n",
       " 'them': 111,\n",
       " 'number': 112,\n",
       " 'government': 113,\n",
       " 'later': 114,\n",
       " 'him': 115,\n",
       " 'her': 116,\n",
       " 'c': 117,\n",
       " 'since': 118,\n",
       " 'century': 119,\n",
       " 'part': 120,\n",
       " 'name': 121,\n",
       " 'through': 122,\n",
       " 'because': 123,\n",
       " 'university': 124,\n",
       " 'x': 125,\n",
       " 'british': 126,\n",
       " 'early': 127,\n",
       " 'life': 128,\n",
       " 'm': 129,\n",
       " 'like': 130,\n",
       " 'same': 131,\n",
       " 'year': 132,\n",
       " 'including': 133,\n",
       " 'example': 134,\n",
       " 'each': 135,\n",
       " 'became': 136,\n",
       " 'work': 137,\n",
       " 'even': 138,\n",
       " 'language': 139,\n",
       " 'although': 140,\n",
       " 'day': 141,\n",
       " 'form': 142,\n",
       " 'several': 143,\n",
       " 'national': 144,\n",
       " 'john': 145,\n",
       " 'u': 146,\n",
       " 'much': 147,\n",
       " 'g': 148,\n",
       " 'very': 149,\n",
       " 'before': 150,\n",
       " 'general': 151,\n",
       " 'french': 152,\n",
       " 'what': 153,\n",
       " 't': 154,\n",
       " 'against': 155,\n",
       " 'n': 156,\n",
       " 'those': 157,\n",
       " 'high': 158,\n",
       " 'links': 159,\n",
       " 'now': 160,\n",
       " 'could': 161,\n",
       " 'based': 162,\n",
       " 'second': 163,\n",
       " 'another': 164,\n",
       " 'great': 165,\n",
       " 'f': 166,\n",
       " 'do': 167,\n",
       " 'large': 168,\n",
       " 'external': 169,\n",
       " 'list': 170,\n",
       " 'modern': 171,\n",
       " 'different': 172,\n",
       " 'de': 173,\n",
       " 'common': 174,\n",
       " 'german': 175,\n",
       " 'series': 176,\n",
       " 'south': 177,\n",
       " 'music': 178,\n",
       " 'law': 179,\n",
       " 'power': 180,\n",
       " 'set': 181,\n",
       " 'long': 182,\n",
       " 'country': 183,\n",
       " 'major': 184,\n",
       " 'film': 185,\n",
       " 'still': 186,\n",
       " 'until': 187,\n",
       " 'group': 188,\n",
       " 'king': 189,\n",
       " 'game': 190,\n",
       " 'north': 191,\n",
       " 'she': 192,\n",
       " 'international': 193,\n",
       " 'term': 194,\n",
       " 'book': 195,\n",
       " 'we': 196,\n",
       " 'found': 197,\n",
       " 'end': 198,\n",
       " 'own': 199,\n",
       " 'order': 200,\n",
       " 'political': 201,\n",
       " 'usually': 202,\n",
       " 'church': 203,\n",
       " 'party': 204,\n",
       " 'death': 205,\n",
       " 'you': 206,\n",
       " 'god': 207,\n",
       " 'president': 208,\n",
       " 'area': 209,\n",
       " 'around': 210,\n",
       " 'theory': 211,\n",
       " 'include': 212,\n",
       " 'way': 213,\n",
       " 'did': 214,\n",
       " 'though': 215,\n",
       " 'ii': 216,\n",
       " 'using': 217,\n",
       " 'small': 218,\n",
       " 'following': 219,\n",
       " 'within': 220,\n",
       " 'non': 221,\n",
       " 'human': 222,\n",
       " 'left': 223,\n",
       " 'military': 224,\n",
       " 'point': 225,\n",
       " 'among': 226,\n",
       " 'p': 227,\n",
       " 'population': 228,\n",
       " 'main': 229,\n",
       " 'r': 230,\n",
       " 'considered': 231,\n",
       " 'due': 232,\n",
       " 'public': 233,\n",
       " 'west': 234,\n",
       " 'computer': 235,\n",
       " 'information': 236,\n",
       " 'family': 237,\n",
       " 'important': 238,\n",
       " 'right': 239,\n",
       " 'east': 240,\n",
       " 'popular': 241,\n",
       " 'sometimes': 242,\n",
       " 'european': 243,\n",
       " 'man': 244,\n",
       " 'old': 245,\n",
       " 'free': 246,\n",
       " 'without': 247,\n",
       " 'given': 248,\n",
       " 'members': 249,\n",
       " 'us': 250,\n",
       " 'last': 251,\n",
       " 'word': 252,\n",
       " 'times': 253,\n",
       " 'roman': 254,\n",
       " 'h': 255,\n",
       " 'make': 256,\n",
       " 'science': 257,\n",
       " 'age': 258,\n",
       " 'place': 259,\n",
       " 'l': 260,\n",
       " 'thus': 261,\n",
       " 'case': 262,\n",
       " 'does': 263,\n",
       " 'house': 264,\n",
       " 'languages': 265,\n",
       " 'countries': 266,\n",
       " 'article': 267,\n",
       " 'become': 268,\n",
       " 'born': 269,\n",
       " 'union': 270,\n",
       " 'york': 271,\n",
       " 'isbn': 272,\n",
       " 'should': 273,\n",
       " 'others': 274,\n",
       " 'back': 275,\n",
       " 'period': 276,\n",
       " 'systems': 277,\n",
       " 'water': 278,\n",
       " 'led': 279,\n",
       " 'various': 280,\n",
       " 'k': 281,\n",
       " 'central': 282,\n",
       " 'line': 283,\n",
       " 'europe': 284,\n",
       " 'st': 285,\n",
       " 'few': 286,\n",
       " 'began': 287,\n",
       " 'generally': 288,\n",
       " 'home': 289,\n",
       " 'must': 290,\n",
       " 'less': 291,\n",
       " 'written': 292,\n",
       " 'control': 293,\n",
       " 'island': 294,\n",
       " 'western': 295,\n",
       " 'similar': 296,\n",
       " 'best': 297,\n",
       " 'original': 298,\n",
       " 'according': 299,\n",
       " 'air': 300,\n",
       " 'school': 301,\n",
       " 'works': 302,\n",
       " 'v': 303,\n",
       " 'player': 304,\n",
       " 'land': 305,\n",
       " 'single': 306,\n",
       " 'force': 307,\n",
       " 'france': 308,\n",
       " 'down': 309,\n",
       " 'how': 310,\n",
       " 'groups': 311,\n",
       " 'england': 312,\n",
       " 'development': 313,\n",
       " 'official': 314,\n",
       " 'rather': 315,\n",
       " 'greek': 316,\n",
       " 'space': 317,\n",
       " 'j': 318,\n",
       " 'support': 319,\n",
       " 'germany': 320,\n",
       " 'london': 321,\n",
       " 'data': 322,\n",
       " 'km': 323,\n",
       " 'named': 324,\n",
       " 'published': 325,\n",
       " 'just': 326,\n",
       " 'said': 327,\n",
       " 'black': 328,\n",
       " 'games': 329,\n",
       " 'every': 330,\n",
       " 'late': 331,\n",
       " 'christian': 332,\n",
       " 'short': 333,\n",
       " 'body': 334,\n",
       " 'off': 335,\n",
       " 'earth': 336,\n",
       " 'empire': 337,\n",
       " 'o': 338,\n",
       " 'economic': 339,\n",
       " 'college': 340,\n",
       " 'army': 341,\n",
       " 'company': 342,\n",
       " 'either': 343,\n",
       " 'social': 344,\n",
       " 'version': 345,\n",
       " 'million': 346,\n",
       " 'kingdom': 347,\n",
       " 'court': 348,\n",
       " 'field': 349,\n",
       " 'standard': 350,\n",
       " 'along': 351,\n",
       " 'service': 352,\n",
       " 'sea': 353,\n",
       " 'developed': 354,\n",
       " 'means': 355,\n",
       " 'america': 356,\n",
       " 'result': 357,\n",
       " 'light': 358,\n",
       " 'never': 359,\n",
       " 'today': 360,\n",
       " 'team': 361,\n",
       " 'especially': 362,\n",
       " 'held': 363,\n",
       " 'society': 364,\n",
       " 'further': 365,\n",
       " 'character': 366,\n",
       " 'take': 367,\n",
       " 'third': 368,\n",
       " 'forces': 369,\n",
       " 'open': 370,\n",
       " 'books': 371,\n",
       " 'republic': 372,\n",
       " 'possible': 373,\n",
       " 'fact': 374,\n",
       " 'men': 375,\n",
       " 'show': 376,\n",
       " 'took': 377,\n",
       " 'battle': 378,\n",
       " 'good': 379,\n",
       " 'children': 380,\n",
       " 'natural': 381,\n",
       " 'son': 382,\n",
       " 'having': 383,\n",
       " 'present': 384,\n",
       " 'himself': 385,\n",
       " 'current': 386,\n",
       " 'former': 387,\n",
       " 'local': 388,\n",
       " 'person': 389,\n",
       " 'process': 390,\n",
       " 'islands': 391,\n",
       " 'words': 392,\n",
       " 'white': 393,\n",
       " 'little': 394,\n",
       " 'above': 395,\n",
       " 'near': 396,\n",
       " 'father': 397,\n",
       " 'total': 398,\n",
       " 'soviet': 399,\n",
       " 'itself': 400,\n",
       " 'side': 401,\n",
       " 'upon': 402,\n",
       " 'red': 403,\n",
       " 'seen': 404,\n",
       " 'culture': 405,\n",
       " 'references': 406,\n",
       " 'play': 407,\n",
       " 'days': 408,\n",
       " 'river': 409,\n",
       " 'came': 410,\n",
       " 'level': 411,\n",
       " 'certain': 412,\n",
       " 'largest': 413,\n",
       " 'press': 414,\n",
       " 'once': 415,\n",
       " 'created': 416,\n",
       " 'famous': 417,\n",
       " 'jewish': 418,\n",
       " 'almost': 419,\n",
       " 'full': 420,\n",
       " 'james': 421,\n",
       " 'software': 422,\n",
       " 'numbers': 423,\n",
       " 'al': 424,\n",
       " 'role': 425,\n",
       " 'january': 426,\n",
       " 'region': 427,\n",
       " 'site': 428,\n",
       " 'member': 429,\n",
       " 'areas': 430,\n",
       " 'image': 431,\n",
       " 'story': 432,\n",
       " 'religious': 433,\n",
       " 'community': 434,\n",
       " 'again': 435,\n",
       " 'ancient': 436,\n",
       " 'act': 437,\n",
       " 'art': 438,\n",
       " 'real': 439,\n",
       " 'played': 440,\n",
       " 'related': 441,\n",
       " 'view': 442,\n",
       " 'league': 443,\n",
       " 'movement': 444,\n",
       " 'rights': 445,\n",
       " 'production': 446,\n",
       " 'terms': 447,\n",
       " 'center': 448,\n",
       " 'low': 449,\n",
       " 'energy': 450,\n",
       " 'foreign': 451,\n",
       " 'died': 452,\n",
       " 'council': 453,\n",
       " 'change': 454,\n",
       " 'type': 455,\n",
       " 'source': 456,\n",
       " 'research': 457,\n",
       " 'living': 458,\n",
       " 'december': 459,\n",
       " 'produced': 460,\n",
       " 'class': 461,\n",
       " 'canada': 462,\n",
       " 'bc': 463,\n",
       " 'particular': 464,\n",
       " 'making': 465,\n",
       " 'head': 466,\n",
       " 'william': 467,\n",
       " 'latin': 468,\n",
       " 'northern': 469,\n",
       " 'forms': 470,\n",
       " 'design': 471,\n",
       " 'minister': 472,\n",
       " 'style': 473,\n",
       " 'david': 474,\n",
       " 'available': 475,\n",
       " 'civil': 476,\n",
       " 'japanese': 477,\n",
       " 'next': 478,\n",
       " 'special': 479,\n",
       " 'position': 480,\n",
       " 'program': 481,\n",
       " 'w': 482,\n",
       " 'march': 483,\n",
       " 'far': 484,\n",
       " 'women': 485,\n",
       " 'chinese': 486,\n",
       " 'released': 487,\n",
       " 'established': 488,\n",
       " 'y': 489,\n",
       " 'television': 490,\n",
       " 'george': 491,\n",
       " 'together': 492,\n",
       " 'eastern': 493,\n",
       " 'function': 494,\n",
       " 'hand': 495,\n",
       " 'middle': 496,\n",
       " 'july': 497,\n",
       " 'charles': 498,\n",
       " 'might': 499,\n",
       " 'parts': 500,\n",
       " 'china': 501,\n",
       " 'instead': 502,\n",
       " 'code': 503,\n",
       " 'band': 504,\n",
       " 'built': 505,\n",
       " 'thought': 506,\n",
       " 'least': 507,\n",
       " 'india': 508,\n",
       " 'included': 509,\n",
       " 'study': 510,\n",
       " 'meaning': 511,\n",
       " 'emperor': 512,\n",
       " 'june': 513,\n",
       " 'half': 514,\n",
       " 'text': 515,\n",
       " 'always': 516,\n",
       " 'anti': 517,\n",
       " 'range': 518,\n",
       " 'actor': 519,\n",
       " 'trade': 520,\n",
       " 'per': 521,\n",
       " 'final': 522,\n",
       " 'traditional': 523,\n",
       " 'capital': 524,\n",
       " 'uk': 525,\n",
       " 'young': 526,\n",
       " 'taken': 527,\n",
       " 'prime': 528,\n",
       " 'november': 529,\n",
       " 'economy': 530,\n",
       " 'nature': 531,\n",
       " 'october': 532,\n",
       " 'august': 533,\n",
       " 'lost': 534,\n",
       " 'players': 535,\n",
       " 'april': 536,\n",
       " 'addition': 537,\n",
       " 'spanish': 538,\n",
       " 'uses': 539,\n",
       " 'live': 540,\n",
       " 'run': 541,\n",
       " 'true': 542,\n",
       " 'recent': 543,\n",
       " 'value': 544,\n",
       " 'project': 545,\n",
       " 'wrote': 546,\n",
       " 'effect': 547,\n",
       " 'technology': 548,\n",
       " 'september': 549,\n",
       " 'evidence': 550,\n",
       " 'southern': 551,\n",
       " 'catholic': 552,\n",
       " 'note': 553,\n",
       " 'historical': 554,\n",
       " 'radio': 555,\n",
       " 'whose': 556,\n",
       " 'album': 557,\n",
       " 'model': 558,\n",
       " 'top': 559,\n",
       " 'italian': 560,\n",
       " 'africa': 561,\n",
       " 'self': 562,\n",
       " 'rule': 563,\n",
       " 'won': 564,\n",
       " 'australia': 565,\n",
       " 'done': 566,\n",
       " 'particularly': 567,\n",
       " 'themselves': 568,\n",
       " 'philosophy': 569,\n",
       " 'cases': 570,\n",
       " 'influence': 571,\n",
       " 'species': 572,\n",
       " 'structure': 573,\n",
       " 'rate': 574,\n",
       " 'subject': 575,\n",
       " 'record': 576,\n",
       " 'nations': 577,\n",
       " 'russian': 578,\n",
       " 'referred': 579,\n",
       " 'our': 580,\n",
       " 'below': 581,\n",
       " 'love': 582,\n",
       " 'throughout': 583,\n",
       " 'continued': 584,\n",
       " 'problem': 585,\n",
       " 'star': 586,\n",
       " 'japan': 587,\n",
       " 'whether': 588,\n",
       " 'therefore': 589,\n",
       " 'education': 590,\n",
       " 'rock': 591,\n",
       " 'song': 592,\n",
       " 'israel': 593,\n",
       " 'irish': 594,\n",
       " 'come': 595,\n",
       " 'names': 596,\n",
       " 'title': 597,\n",
       " 'higher': 598,\n",
       " 'films': 599,\n",
       " 'town': 600,\n",
       " 'too': 601,\n",
       " 'com': 602,\n",
       " 'jews': 603,\n",
       " 'action': 604,\n",
       " 'originally': 605,\n",
       " 'february': 606,\n",
       " 'individual': 607,\n",
       " 'cities': 608,\n",
       " 'paul': 609,\n",
       " 'strong': 610,\n",
       " 'elements': 611,\n",
       " 'market': 612,\n",
       " 'football': 613,\n",
       " 'my': 614,\n",
       " 'here': 615,\n",
       " 'sound': 616,\n",
       " 'network': 617,\n",
       " 'eventually': 618,\n",
       " 'est': 619,\n",
       " 'independent': 620,\n",
       " 'author': 621,\n",
       " 'described': 622,\n",
       " 'base': 623,\n",
       " 'despite': 624,\n",
       " 'problems': 625,\n",
       " 'characters': 626,\n",
       " 'robert': 627,\n",
       " 'female': 628,\n",
       " 'la': 629,\n",
       " 'food': 630,\n",
       " 'internet': 631,\n",
       " 'able': 632,\n",
       " 'formed': 633,\n",
       " 'practice': 634,\n",
       " 're': 635,\n",
       " 'office': 636,\n",
       " 'royal': 637,\n",
       " 'complex': 638,\n",
       " 'commonly': 639,\n",
       " 'events': 640,\n",
       " 'fiction': 641,\n",
       " 'parliament': 642,\n",
       " 'received': 643,\n",
       " 'season': 644,\n",
       " 'key': 645,\n",
       " 'lower': 646,\n",
       " 'african': 647,\n",
       " 'writer': 648,\n",
       " 'legal': 649,\n",
       " 'outside': 650,\n",
       " 'typically': 651,\n",
       " 'complete': 652,\n",
       " 'followed': 653,\n",
       " 'significant': 654,\n",
       " 'page': 655,\n",
       " 'basic': 656,\n",
       " 'actually': 657,\n",
       " 'includes': 658,\n",
       " 'business': 659,\n",
       " 'aircraft': 660,\n",
       " 'widely': 661,\n",
       " 'scientific': 662,\n",
       " 'beginning': 663,\n",
       " 'male': 664,\n",
       " 'laws': 665,\n",
       " 'physical': 666,\n",
       " 'types': 667,\n",
       " 'deaths': 668,\n",
       " 'building': 669,\n",
       " 'henry': 670,\n",
       " 'future': 671,\n",
       " 'leader': 672,\n",
       " 'material': 673,\n",
       " 'went': 674,\n",
       " 'cannot': 675,\n",
       " 'britain': 676,\n",
       " 'news': 677,\n",
       " 'get': 678,\n",
       " 'simply': 679,\n",
       " 'cross': 680,\n",
       " 'ever': 681,\n",
       " 'ireland': 682,\n",
       " 'services': 683,\n",
       " 'industry': 684,\n",
       " 'fire': 685,\n",
       " 'elected': 686,\n",
       " 'close': 687,\n",
       " 'method': 688,\n",
       " 'specific': 689,\n",
       " 'cause': 690,\n",
       " 'defined': 691,\n",
       " 'canadian': 692,\n",
       " 'go': 693,\n",
       " 'believe': 694,\n",
       " 'examples': 695,\n",
       " 'writing': 696,\n",
       " 'california': 697,\n",
       " 'post': 698,\n",
       " 'mass': 699,\n",
       " 'births': 700,\n",
       " 'size': 701,\n",
       " 'lead': 702,\n",
       " 'video': 703,\n",
       " 'return': 704,\n",
       " 'knowledge': 705,\n",
       " 'independence': 706,\n",
       " 'idea': 707,\n",
       " 'points': 708,\n",
       " 'organization': 709,\n",
       " 'associated': 710,\n",
       " 'personal': 711,\n",
       " 'sense': 712,\n",
       " 'soon': 713,\n",
       " 'classical': 714,\n",
       " 'introduced': 715,\n",
       " 'required': 716,\n",
       " 'majority': 717,\n",
       " 'movie': 718,\n",
       " 'concept': 719,\n",
       " 'designed': 720,\n",
       " 'yet': 721,\n",
       " 'away': 722,\n",
       " 'changes': 723,\n",
       " 'believed': 724,\n",
       " 'located': 725,\n",
       " 'co': 726,\n",
       " 'county': 727,\n",
       " 'studies': 728,\n",
       " 'religion': 729,\n",
       " 'lord': 730,\n",
       " 'blue': 731,\n",
       " 'indian': 732,\n",
       " 'rules': 733,\n",
       " 'find': 734,\n",
       " 'features': 735,\n",
       " 'started': 736,\n",
       " 'mother': 737,\n",
       " 'put': 738,\n",
       " 'currently': 739,\n",
       " 'ball': 740,\n",
       " 'working': 741,\n",
       " 'policy': 742,\n",
       " 'russia': 743,\n",
       " 'earlier': 744,\n",
       " 'election': 745,\n",
       " 'thomas': 746,\n",
       " 'sources': 747,\n",
       " 'brought': 748,\n",
       " 'provide': 749,\n",
       " 'allowed': 750,\n",
       " 'association': 751,\n",
       " 'things': 752,\n",
       " 'greater': 753,\n",
       " 'online': 754,\n",
       " 'australian': 755,\n",
       " 'attack': 756,\n",
       " 'added': 757,\n",
       " 'across': 758,\n",
       " 'founded': 759,\n",
       " 'relations': 760,\n",
       " 'object': 761,\n",
       " 'limited': 762,\n",
       " 'mostly': 763,\n",
       " 'federal': 764,\n",
       " 'effects': 765,\n",
       " 'interest': 766,\n",
       " 'z': 767,\n",
       " 'probably': 768,\n",
       " 'reference': 769,\n",
       " 'past': 770,\n",
       " 'career': 771,\n",
       " 'security': 772,\n",
       " 'stories': 773,\n",
       " 'need': 774,\n",
       " 'your': 775,\n",
       " 'simple': 776,\n",
       " 'gave': 777,\n",
       " 'constitution': 778,\n",
       " 'park': 779,\n",
       " 'letter': 780,\n",
       " 'remains': 781,\n",
       " 'me': 782,\n",
       " 'success': 783,\n",
       " 'longer': 784,\n",
       " 'growth': 785,\n",
       " 'killed': 786,\n",
       " 'say': 787,\n",
       " 'give': 788,\n",
       " 'chief': 789,\n",
       " 'definition': 790,\n",
       " 'media': 791,\n",
       " 'wide': 792,\n",
       " 'night': 793,\n",
       " 'letters': 794,\n",
       " 'leading': 795,\n",
       " 'website': 796,\n",
       " 'library': 797,\n",
       " 'contains': 798,\n",
       " 'green': 799,\n",
       " 'remained': 800,\n",
       " 'etc': 801,\n",
       " 'largely': 802,\n",
       " 'color': 803,\n",
       " 'moved': 804,\n",
       " 'months': 805,\n",
       " 'spain': 806,\n",
       " 'dead': 807,\n",
       " 'big': 808,\n",
       " 'better': 809,\n",
       " 'larger': 810,\n",
       " 'already': 811,\n",
       " 'perhaps': 812,\n",
       " 'novel': 813,\n",
       " 'speed': 814,\n",
       " 'peace': 815,\n",
       " 'holy': 816,\n",
       " 'help': 817,\n",
       " 'territory': 818,\n",
       " 'cell': 819,\n",
       " 'parties': 820,\n",
       " 'cultural': 821,\n",
       " 'politics': 822,\n",
       " 'origin': 823,\n",
       " 'companies': 824,\n",
       " 'lake': 825,\n",
       " 'private': 826,\n",
       " 'claim': 827,\n",
       " 'saint': 828,\n",
       " 'iii': 829,\n",
       " 'wife': 830,\n",
       " 'saw': 831,\n",
       " 'dutch': 832,\n",
       " 'revolution': 833,\n",
       " 'appeared': 834,\n",
       " 'refer': 835,\n",
       " 'matter': 836,\n",
       " 'makes': 837,\n",
       " 'whole': 838,\n",
       " 'lines': 839,\n",
       " 'era': 840,\n",
       " 'directly': 841,\n",
       " 'separate': 842,\n",
       " 'products': 843,\n",
       " 'italy': 844,\n",
       " 'results': 845,\n",
       " 'produce': 846,\n",
       " 'surface': 847,\n",
       " 'asia': 848,\n",
       " 'highly': 849,\n",
       " 'caused': 850,\n",
       " 'attempt': 851,\n",
       " 'authority': 852,\n",
       " 'double': 853,\n",
       " 'coast': 854,\n",
       " 'status': 855,\n",
       " 'alexander': 856,\n",
       " 'successful': 857,\n",
       " 'health': 858,\n",
       " 'turn': 859,\n",
       " 'literature': 860,\n",
       " 'towards': 861,\n",
       " 'playing': 862,\n",
       " 'direct': 863,\n",
       " 'oil': 864,\n",
       " 'blood': 865,\n",
       " 'richard': 866,\n",
       " 'singer': 867,\n",
       " 'latter': 868,\n",
       " 'whom': 869,\n",
       " 'primary': 870,\n",
       " 'treaty': 871,\n",
       " 'division': 872,\n",
       " 'becomes': 873,\n",
       " 'basis': 874,\n",
       " 'analysis': 875,\n",
       " 'date': 876,\n",
       " 'enough': 877,\n",
       " 'married': 878,\n",
       " 'edition': 879,\n",
       " 'chemical': 880,\n",
       " 'exist': 881,\n",
       " 'nation': 882,\n",
       " 'prize': 883,\n",
       " 'issues': 884,\n",
       " 'native': 885,\n",
       " 'programming': 886,\n",
       " 'likely': 887,\n",
       " 'commercial': 888,\n",
       " 'property': 889,\n",
       " 'release': 890,\n",
       " 'web': 891,\n",
       " 'amount': 892,\n",
       " 'allow': 893,\n",
       " 'course': 894,\n",
       " 'reason': 895,\n",
       " 'machine': 896,\n",
       " 'provided': 897,\n",
       " 'sun': 898,\n",
       " 'smaller': 899,\n",
       " 'money': 900,\n",
       " 'museum': 901,\n",
       " 'digital': 902,\n",
       " 'functions': 903,\n",
       " 'jesus': 904,\n",
       " 'divided': 905,\n",
       " 'average': 906,\n",
       " 'replaced': 907,\n",
       " 'metal': 908,\n",
       " 'length': 909,\n",
       " 'degree': 910,\n",
       " 'gas': 911,\n",
       " 'peter': 912,\n",
       " 'tradition': 913,\n",
       " 'memory': 914,\n",
       " 'claims': 915,\n",
       " 'nearly': 916,\n",
       " 'tv': 917,\n",
       " 'washington': 918,\n",
       " 'access': 919,\n",
       " 'difficult': 920,\n",
       " 'rome': 921,\n",
       " 'notable': 922,\n",
       " 'ground': 923,\n",
       " 'medical': 924,\n",
       " 'queen': 925,\n",
       " 'claimed': 926,\n",
       " 'mid': 927,\n",
       " 'recently': 928,\n",
       " 'ten': 929,\n",
       " 'records': 930,\n",
       " 'collection': 931,\n",
       " 'animals': 932,\n",
       " 'involved': 933,\n",
       " 'schools': 934,\n",
       " 'read': 935,\n",
       " 'finally': 936,\n",
       " 'front': 937,\n",
       " 'sent': 938,\n",
       " 'performance': 939,\n",
       " 'variety': 940,\n",
       " 'changed': 941,\n",
       " 'director': 942,\n",
       " 'elections': 943,\n",
       " 'frequently': 944,\n",
       " 'liberal': 945,\n",
       " 'congress': 946,\n",
       " 'entire': 947,\n",
       " 'hard': 948,\n",
       " 'highest': 949,\n",
       " 'methods': 950,\n",
       " 'club': 951,\n",
       " 'democratic': 952,\n",
       " 'mark': 953,\n",
       " 'ideas': 954,\n",
       " 'product': 955,\n",
       " 'don': 956,\n",
       " 'served': 957,\n",
       " 'christ': 958,\n",
       " 'programs': 959,\n",
       " 'section': 960,\n",
       " 'increased': 961,\n",
       " 'louis': 962,\n",
       " 'call': 963,\n",
       " 'board': 964,\n",
       " 'relationship': 965,\n",
       " 'bbc': 966,\n",
       " 'students': 967,\n",
       " 'michael': 968,\n",
       " 'relatively': 969,\n",
       " 'discovered': 970,\n",
       " 'element': 971,\n",
       " 'conditions': 972,\n",
       " 'objects': 973,\n",
       " 'increase': 974,\n",
       " 'unit': 975,\n",
       " 'actress': 976,\n",
       " 'child': 977,\n",
       " 'appear': 978,\n",
       " 'returned': 979,\n",
       " 'existence': 980,\n",
       " 'rest': 981,\n",
       " 'appears': 982,\n",
       " 'map': 983,\n",
       " 'fall': 984,\n",
       " 'musical': 985,\n",
       " 'know': 986,\n",
       " 'minor': 987,\n",
       " 'baseball': 988,\n",
       " 'adopted': 989,\n",
       " 'orthodox': 990,\n",
       " 'except': 991,\n",
       " 'assembly': 992,\n",
       " 'nuclear': 993,\n",
       " 'user': 994,\n",
       " 'takes': 995,\n",
       " 'san': 996,\n",
       " 'event': 997,\n",
       " 'hall': 998,\n",
       " 'heavy': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "可以通过文本文件读取文字，再创建一个词汇表，前面设置的词汇表最大是30000个，\n",
    "它就是一个字典，然后再添加一个unk表示未知词，再记录单词到index的mapping和index到单词的mapping\n",
    "\"\"\"\n",
    "\n",
    "with open(\"F:\\\\自然语言处理数据集\\\\text8\\\\text8.train.txt\", \"r\") as fin:\n",
    "    text = fin.read()\n",
    "    \n",
    "\n",
    "#分词后变小写\n",
    "text = [w for w in word_tokenize(text.lower())]\n",
    "vocab = dict(Counter(text).most_common(MAX_VOCAB_SIZE-1))\n",
    "# 未知词\n",
    "vocab[\"<unk>\"] = len(text) - np.sum(list(vocab.values()))\n",
    "idx_to_word = [word for word in vocab.keys()] \n",
    "word_to_idx = {word:i for i, word in enumerate(idx_to_word)}\n",
    "word_to_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置词量和词频\n",
    "# 词量 词频\n",
    "word_counts = np.array([count for count in vocab.values()], dtype=np.float32)\n",
    "word_freqs = word_counts / np.sum(word_counts)\n",
    "word_freqs = word_freqs ** (3./4.)\n",
    "word_freqs = word_freqs / np.sum(word_freqs) # 用来做 negative sampling\n",
    "VOCAB_SIZE = len(idx_to_word)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面实现dataloader,一个dataloader需要一下的内容：\n",
    "1. 把所有text编码成数字，然后用subsampling预处理这些文字。\n",
    "1. 保存vocabulary，单词count，normalized word frequency\n",
    "1. 每个iteration sample一个中心词\n",
    "1. 根据当前的中心词返回context单词\n",
    "1. 根据中心词sample一些negative单词\n",
    "1. 返回单词的counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordEmbeddingDataset(tud.Dataset):\n",
    "    def __init__(self, text, word_to_idx, idx_to_word, word_freqs, word_counts):\n",
    "        ''' text: a list of words, all text from the training dataset\n",
    "            word_to_idx: the dictionary from word to idx\n",
    "            idx_to_word: idx to word mapping\n",
    "            word_freq: the frequency of each word\n",
    "            word_counts: the word counts\n",
    "        '''\n",
    "        super(WordEmbeddingDataset, self).__init__()\n",
    "        self.text_encoded = [word_to_idx.get(t, VOCAB_SIZE-1) for t in text]\n",
    "        self.text_encoded = torch.Tensor(self.text_encoded).long()\n",
    "        self.word_to_idx = word_to_idx\n",
    "        self.idx_to_word = idx_to_word\n",
    "        self.word_freqs = torch.Tensor(word_freqs)\n",
    "        self.word_counts = torch.Tensor(word_counts)\n",
    "        \n",
    "    def __len__(self):\n",
    "        ''' 返回整个数据集（所有单词）的长度\n",
    "        '''\n",
    "        return len(self.text_encoded)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        ''' 这个function返回以下数据用于训练\n",
    "            - 中心词\n",
    "            - 这个单词附近的(positive)单词\n",
    "            - 随机采样的K个单词作为negative sample\n",
    "        '''\n",
    "        center_word = self.text_encoded[idx]\n",
    "        pos_indices = list(range(idx-C, idx)) + list(range(idx+1, idx+C+1))\n",
    "        pos_indices = [i%len(self.text_encoded) for i in pos_indices]\n",
    "        pos_words = self.text_encoded[pos_indices] \n",
    "        neg_words = torch.multinomial(self.word_freqs, K * pos_words.shape[0], True)\n",
    "        \n",
    "        return center_word, pos_words, neg_words\n",
    "\n",
    "dataset = WordEmbeddingDataset(text, word_to_idx, idx_to_word, word_freqs, word_counts)\n",
    "dataloader = tud.DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义pytorch模型\n",
    "class EmbeddingModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size):\n",
    "        ''' 初始化输出和输出embedding\n",
    "        '''\n",
    "        super(EmbeddingModel, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embed_size = embed_size\n",
    "        \n",
    "        initrange = 0.5 / self.embed_size\n",
    "        self.out_embed = nn.Embedding(self.vocab_size, self.embed_size, sparse=False)\n",
    "        self.out_embed.weight.data.uniform_(-initrange, initrange)\n",
    "        \n",
    "        \n",
    "        self.in_embed = nn.Embedding(self.vocab_size, self.embed_size, sparse=False)\n",
    "        self.in_embed.weight.data.uniform_(-initrange, initrange)\n",
    "        \n",
    "        \n",
    "    '''输入 正确的词 错误的词'''\n",
    "    def forward(self, input_labels, pos_labels, neg_labels):\n",
    "        '''\n",
    "        input_labels: 中心词, [batch_size]\n",
    "        pos_labels: 中心词周围 context window 出现过的单词 [batch_size ,(window_size * 2)]\n",
    "        neg_labelss: 中心词周围没有出现过的单词，从 negative sampling 得到 [batch_size, (window_size * 2 * K)]\n",
    "        \n",
    "        return: loss, [batch_size]\n",
    "        '''\n",
    "        \n",
    "        batch_size = input_labels.size(0)\n",
    "        \n",
    "        '''每个数字都embed 成一个 vector'''\n",
    "        input_embedding = self.in_embed(input_labels) # B * embed_size\n",
    "        pos_embedding = self.out_embed(pos_labels) # B * (2*C) * embed_size\n",
    "        neg_embedding = self.out_embed(neg_labels) # B * (2*C * K) * embed_size\n",
    "      \n",
    "        log_pos = torch.bmm(pos_embedding, input_embedding.unsqueeze(2)).squeeze() # B * (2*C)\n",
    "        log_neg = torch.bmm(neg_embedding, -input_embedding.unsqueeze(2)).squeeze() # B * (2*C*K)\n",
    "\n",
    "        '''第一维上求和'''\n",
    "        log_pos = F.logsigmoid(log_pos).sum(1)\n",
    "        log_neg = F.logsigmoid(log_neg).sum(1) # batch_size\n",
    "       \n",
    "        loss = log_pos + log_neg\n",
    "        \n",
    "        return -loss\n",
    "    \n",
    "    def input_embeddings(self):\n",
    "        return self.in_embed.weight.data.cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device:\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device:\")\n",
    "print(device)\n",
    "\n",
    "# 运行模型，这里原先是GPU跑的，我们改成CPU的代码\n",
    "model = EmbeddingModel(VOCAB_SIZE, EMBEDDING_SIZE)\n",
    "if USE_CUDA:\n",
    "    #model = model.cuda()\n",
    "    model = model.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 下面是用于评估的代码，主要是用于测试词之间的相关性\n",
    "def evaluate(filename, embedding_weights): \n",
    "    if filename.endswith(\".csv\"):\n",
    "        data = pd.read_csv(filename, sep=\",\")\n",
    "    else:\n",
    "        data = pd.read_csv(filename, sep=\"\\t\")\n",
    "    human_similarity = []\n",
    "    model_similarity = []\n",
    "    for i in data.iloc[:, 0:2].index:\n",
    "        word1, word2 = data.iloc[i, 0], data.iloc[i, 1]\n",
    "        if word1 not in word_to_idx or word2 not in word_to_idx:\n",
    "            continue\n",
    "        else:\n",
    "            word1_idx, word2_idx = word_to_idx[word1], word_to_idx[word2]\n",
    "            word1_embed, word2_embed = embedding_weights[[word1_idx]], embedding_weights[[word2_idx]]\n",
    "            model_similarity.append(float(sklearn.metrics.pairwise.cosine_similarity(word1_embed, word2_embed)))\n",
    "            human_similarity.append(float(data.iloc[i, 2]))\n",
    "\n",
    "    return scipy.stats.spearmanr(human_similarity, model_similarity)# , model_similarity\n",
    "\n",
    "def find_nearest(word):\n",
    "    index = word_to_idx[word]\n",
    "    embedding = embedding_weights[index]\n",
    "    cos_dis = np.array([scipy.spatial.distance.cosine(e, embedding) for e in embedding_weights])\n",
    "    return [idx_to_word[i] for i in cos_dis.argsort()[:10]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, iter: 0, loss: 420.04742431640625\n",
      "epoch: 0, iter: 100, loss: 280.9455261230469\n",
      "epoch: 0, iter: 200, loss: 212.32415771484375\n",
      "epoch: 0, iter: 300, loss: 185.0164337158203\n",
      "epoch: 0, iter: 400, loss: 141.21463012695312\n",
      "epoch: 0, iter: 500, loss: 135.06698608398438\n",
      "epoch: 0, iter: 600, loss: 138.35374450683594\n",
      "epoch: 0, iter: 700, loss: 112.25232696533203\n",
      "epoch: 0, iter: 800, loss: 144.89501953125\n",
      "epoch: 0, iter: 900, loss: 94.30026245117188\n",
      "epoch: 0, iter: 1000, loss: 93.244140625\n",
      "epoch: 0, iter: 1100, loss: 97.6533203125\n",
      "epoch: 0, iter: 1200, loss: 79.48892974853516\n",
      "epoch: 0, iter: 1300, loss: 68.31893157958984\n",
      "epoch: 0, iter: 1400, loss: 70.45720672607422\n",
      "epoch: 0, iter: 1500, loss: 77.17955017089844\n",
      "epoch: 0, iter: 1600, loss: 72.80960845947266\n",
      "epoch: 0, iter: 1700, loss: 73.63546752929688\n",
      "epoch: 0, iter: 1800, loss: 70.2663803100586\n",
      "epoch: 0, iter: 1900, loss: 68.15692138671875\n",
      "epoch: 0, iter: 2000, loss: 66.25592041015625\n",
      "epoch: 0, iter: 2100, loss: 80.15396118164062\n",
      "epoch: 0, iter: 2200, loss: 60.57592010498047\n",
      "epoch: 0, iter: 2300, loss: 51.90287780761719\n",
      "epoch: 0, iter: 2400, loss: 60.86955261230469\n",
      "epoch: 0, iter: 2500, loss: 63.126182556152344\n",
      "epoch: 0, iter: 2600, loss: 62.30072784423828\n",
      "epoch: 0, iter: 2700, loss: 47.78618621826172\n",
      "epoch: 0, iter: 2800, loss: 51.613731384277344\n",
      "epoch: 0, iter: 2900, loss: 48.576683044433594\n",
      "epoch: 0, iter: 3000, loss: 64.56227111816406\n",
      "epoch: 0, iter: 3100, loss: 45.594688415527344\n",
      "epoch: 0, iter: 3200, loss: 52.61482620239258\n",
      "epoch: 0, iter: 3300, loss: 48.47160720825195\n",
      "epoch: 0, iter: 3400, loss: 49.84870147705078\n",
      "epoch: 0, iter: 3500, loss: 49.20784378051758\n",
      "epoch: 0, iter: 3600, loss: 50.857994079589844\n",
      "epoch: 0, iter: 3700, loss: 47.735557556152344\n",
      "epoch: 0, iter: 3800, loss: 54.74168395996094\n",
      "epoch: 0, iter: 3900, loss: 47.92745590209961\n",
      "epoch: 0, iter: 4000, loss: 49.16630935668945\n",
      "epoch: 0, iter: 4100, loss: 42.50245666503906\n",
      "epoch: 0, iter: 4200, loss: 54.65040969848633\n",
      "epoch: 0, iter: 4300, loss: 50.44712448120117\n",
      "epoch: 0, iter: 4400, loss: 44.13923263549805\n",
      "epoch: 0, iter: 4500, loss: 43.212066650390625\n",
      "epoch: 0, iter: 4600, loss: 44.387184143066406\n",
      "epoch: 0, iter: 4700, loss: 41.06309127807617\n",
      "epoch: 0, iter: 4800, loss: 38.82001495361328\n",
      "epoch: 0, iter: 4900, loss: 41.238616943359375\n",
      "epoch: 0, iter: 5000, loss: 42.11896514892578\n",
      "epoch: 0, iter: 5100, loss: 41.79752731323242\n",
      "epoch: 0, iter: 5200, loss: 43.36417770385742\n",
      "epoch: 0, iter: 5300, loss: 39.92736053466797\n",
      "epoch: 0, iter: 5400, loss: 47.42038345336914\n",
      "epoch: 0, iter: 5500, loss: 36.18391418457031\n",
      "epoch: 0, iter: 5600, loss: 40.884185791015625\n",
      "epoch: 0, iter: 5700, loss: 46.020957946777344\n",
      "epoch: 0, iter: 5800, loss: 42.0839729309082\n",
      "epoch: 0, iter: 5900, loss: 40.24151611328125\n",
      "epoch: 0, iter: 6000, loss: 39.68448257446289\n",
      "epoch: 0, iter: 6100, loss: 40.24412155151367\n",
      "epoch: 0, iter: 6200, loss: 36.44291687011719\n",
      "epoch: 0, iter: 6300, loss: 39.83544921875\n",
      "epoch: 0, iter: 6400, loss: 42.60533905029297\n",
      "epoch: 0, iter: 6500, loss: 34.374107360839844\n",
      "epoch: 0, iter: 6600, loss: 39.477569580078125\n",
      "epoch: 0, iter: 6700, loss: 37.62965393066406\n",
      "epoch: 0, iter: 6800, loss: 39.514060974121094\n",
      "epoch: 0, iter: 6900, loss: 39.08137512207031\n",
      "epoch: 0, iter: 7000, loss: 41.17046356201172\n",
      "epoch: 0, iter: 7100, loss: 42.6721305847168\n",
      "epoch: 0, iter: 7200, loss: 39.23042297363281\n",
      "epoch: 0, iter: 7300, loss: 39.44251251220703\n",
      "epoch: 0, iter: 7400, loss: 36.97703552246094\n",
      "epoch: 0, iter: 7500, loss: 45.05583572387695\n",
      "epoch: 0, iter: 7600, loss: 42.80658721923828\n",
      "epoch: 0, iter: 7700, loss: 38.079559326171875\n",
      "epoch: 0, iter: 7800, loss: 41.85986328125\n",
      "epoch: 0, iter: 7900, loss: 43.359283447265625\n",
      "epoch: 0, iter: 8000, loss: 36.52471160888672\n",
      "epoch: 0, iter: 8100, loss: 37.10624694824219\n",
      "epoch: 0, iter: 8200, loss: 37.87917709350586\n",
      "epoch: 0, iter: 8300, loss: 35.18643569946289\n",
      "epoch: 0, iter: 8400, loss: 43.217872619628906\n",
      "epoch: 0, iter: 8500, loss: 34.49781036376953\n",
      "epoch: 0, iter: 8600, loss: 36.73587417602539\n",
      "epoch: 0, iter: 8700, loss: 36.6077995300293\n",
      "epoch: 0, iter: 8800, loss: 36.52745056152344\n",
      "epoch: 0, iter: 8900, loss: 40.69376754760742\n",
      "epoch: 0, iter: 9000, loss: 37.67315673828125\n",
      "epoch: 0, iter: 9100, loss: 38.03416061401367\n",
      "epoch: 0, iter: 9200, loss: 34.35700988769531\n",
      "epoch: 0, iter: 9300, loss: 33.82392883300781\n",
      "epoch: 0, iter: 9400, loss: 36.185302734375\n",
      "epoch: 0, iter: 9500, loss: 34.31203079223633\n",
      "epoch: 0, iter: 9600, loss: 35.923370361328125\n",
      "epoch: 0, iter: 9700, loss: 34.482601165771484\n",
      "epoch: 0, iter: 9800, loss: 35.408226013183594\n",
      "epoch: 0, iter: 9900, loss: 33.288536071777344\n",
      "epoch: 0, iter: 10000, loss: 34.93285369873047\n",
      "epoch: 0, iter: 10100, loss: 34.805747985839844\n",
      "epoch: 0, iter: 10200, loss: 41.82639694213867\n",
      "epoch: 0, iter: 10300, loss: 37.1947021484375\n",
      "epoch: 0, iter: 10400, loss: 37.96725845336914\n",
      "epoch: 0, iter: 10500, loss: 34.17210388183594\n",
      "epoch: 0, iter: 10600, loss: 33.98469924926758\n",
      "epoch: 0, iter: 10700, loss: 32.398136138916016\n",
      "epoch: 0, iter: 10800, loss: 35.79669189453125\n",
      "epoch: 0, iter: 10900, loss: 35.14411544799805\n",
      "epoch: 0, iter: 11000, loss: 33.8041877746582\n",
      "epoch: 0, iter: 11100, loss: 33.16582489013672\n",
      "epoch: 0, iter: 11200, loss: 33.0635871887207\n",
      "epoch: 0, iter: 11300, loss: 35.36845779418945\n",
      "epoch: 0, iter: 11400, loss: 33.11705780029297\n",
      "epoch: 0, iter: 11500, loss: 33.50615692138672\n",
      "epoch: 0, iter: 11600, loss: 34.318782806396484\n",
      "epoch: 0, iter: 11700, loss: 32.39750289916992\n",
      "epoch: 0, iter: 11800, loss: 34.908565521240234\n",
      "epoch: 0, iter: 11900, loss: 34.133689880371094\n",
      "epoch: 0, iter: 12000, loss: 33.15371322631836\n",
      "epoch: 0, iter: 12100, loss: 33.79243469238281\n",
      "epoch: 0, iter: 12200, loss: 35.238033294677734\n",
      "epoch: 0, iter: 12300, loss: 38.467655181884766\n",
      "epoch: 0, iter: 12400, loss: 35.56337356567383\n",
      "epoch: 0, iter: 12500, loss: 32.962276458740234\n",
      "epoch: 0, iter: 12600, loss: 33.75431442260742\n",
      "epoch: 0, iter: 12700, loss: 33.31180953979492\n",
      "epoch: 0, iter: 12800, loss: 34.195308685302734\n",
      "epoch: 0, iter: 12900, loss: 33.03702926635742\n",
      "epoch: 0, iter: 13000, loss: 33.96427536010742\n",
      "epoch: 0, iter: 13100, loss: 32.950191497802734\n",
      "epoch: 0, iter: 13200, loss: 32.58929443359375\n",
      "epoch: 0, iter: 13300, loss: 33.71233367919922\n",
      "epoch: 0, iter: 13400, loss: 34.617801666259766\n",
      "epoch: 0, iter: 13500, loss: 34.207332611083984\n",
      "epoch: 0, iter: 13600, loss: 32.77284240722656\n",
      "epoch: 0, iter: 13700, loss: 33.37474060058594\n",
      "epoch: 0, iter: 13800, loss: 33.22520065307617\n",
      "epoch: 0, iter: 13900, loss: 39.7609977722168\n",
      "epoch: 0, iter: 14000, loss: 33.4299201965332\n",
      "epoch: 0, iter: 14100, loss: 32.66154861450195\n",
      "epoch: 0, iter: 14200, loss: 32.21037292480469\n",
      "epoch: 0, iter: 14300, loss: 35.013587951660156\n",
      "epoch: 0, iter: 14400, loss: 32.51921844482422\n",
      "epoch: 0, iter: 14500, loss: 32.914974212646484\n",
      "epoch: 0, iter: 14600, loss: 33.974205017089844\n",
      "epoch: 0, iter: 14700, loss: 33.60966491699219\n",
      "epoch: 0, iter: 14800, loss: 32.23886489868164\n",
      "epoch: 0, iter: 14900, loss: 34.9553337097168\n",
      "epoch: 0, iter: 15000, loss: 32.82667541503906\n",
      "epoch: 0, iter: 15100, loss: 32.455963134765625\n",
      "epoch: 0, iter: 15200, loss: 32.230979919433594\n",
      "epoch: 0, iter: 15300, loss: 33.44490432739258\n",
      "epoch: 0, iter: 15400, loss: 33.58524703979492\n",
      "epoch: 0, iter: 15500, loss: 32.3154182434082\n",
      "epoch: 0, iter: 15600, loss: 33.269710540771484\n",
      "epoch: 0, iter: 15700, loss: 32.17405700683594\n",
      "epoch: 0, iter: 15800, loss: 33.68590545654297\n",
      "epoch: 0, iter: 15900, loss: 32.1366081237793\n",
      "epoch: 0, iter: 16000, loss: 32.58983612060547\n",
      "epoch: 0, iter: 16100, loss: 32.42166519165039\n",
      "epoch: 0, iter: 16200, loss: 32.71759033203125\n",
      "epoch: 0, iter: 16300, loss: 32.63182830810547\n",
      "epoch: 0, iter: 16400, loss: 32.37889099121094\n",
      "epoch: 0, iter: 16500, loss: 32.70027160644531\n",
      "epoch: 0, iter: 16600, loss: 32.31616973876953\n",
      "epoch: 0, iter: 16700, loss: 32.21713638305664\n",
      "epoch: 0, iter: 16800, loss: 32.45167541503906\n",
      "epoch: 0, iter: 16900, loss: 33.1895637512207\n",
      "epoch: 0, iter: 17000, loss: 32.80384063720703\n",
      "epoch: 0, iter: 17100, loss: 31.995296478271484\n",
      "epoch: 0, iter: 17200, loss: 32.392608642578125\n",
      "epoch: 0, iter: 17300, loss: 33.17289352416992\n",
      "epoch: 0, iter: 17400, loss: 35.2242431640625\n",
      "epoch: 0, iter: 17500, loss: 32.379188537597656\n",
      "epoch: 0, iter: 17600, loss: 34.0243034362793\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, iter: 17700, loss: 32.622859954833984\n",
      "epoch: 0, iter: 17800, loss: 32.41484451293945\n",
      "epoch: 0, iter: 17900, loss: 32.946754455566406\n",
      "epoch: 0, iter: 18000, loss: 32.314414978027344\n",
      "epoch: 0, iter: 18100, loss: 32.88111114501953\n",
      "epoch: 0, iter: 18200, loss: 32.39853286743164\n",
      "epoch: 0, iter: 18300, loss: 32.69651412963867\n",
      "epoch: 0, iter: 18400, loss: 34.55544662475586\n",
      "epoch: 0, iter: 18500, loss: 32.68207550048828\n",
      "epoch: 0, iter: 18600, loss: 31.947376251220703\n",
      "epoch: 0, iter: 18700, loss: 33.11784744262695\n",
      "epoch: 0, iter: 18800, loss: 33.490089416503906\n",
      "epoch: 0, iter: 18900, loss: 33.05300521850586\n",
      "epoch: 0, iter: 19000, loss: 32.76217269897461\n",
      "epoch: 0, iter: 19100, loss: 32.0904655456543\n",
      "epoch: 0, iter: 19200, loss: 31.7235050201416\n",
      "epoch: 0, iter: 19300, loss: 32.68367385864258\n",
      "epoch: 0, iter: 19400, loss: 32.132896423339844\n",
      "epoch: 0, iter: 19500, loss: 33.041786193847656\n",
      "epoch: 0, iter: 19600, loss: 34.84003448486328\n",
      "epoch: 0, iter: 19700, loss: 31.758575439453125\n",
      "epoch: 0, iter: 19800, loss: 32.385013580322266\n",
      "epoch: 0, iter: 19900, loss: 31.525413513183594\n",
      "epoch: 0, iter: 20000, loss: 32.420291900634766\n",
      "epoch: 0, iter: 20100, loss: 32.992488861083984\n",
      "epoch: 0, iter: 20200, loss: 31.592538833618164\n",
      "epoch: 0, iter: 20300, loss: 31.9077091217041\n",
      "epoch: 0, iter: 20400, loss: 32.39976119995117\n",
      "epoch: 0, iter: 20500, loss: 32.335697174072266\n",
      "epoch: 0, iter: 20600, loss: 32.2374153137207\n",
      "epoch: 0, iter: 20700, loss: 33.94534683227539\n",
      "epoch: 0, iter: 20800, loss: 32.34968566894531\n",
      "epoch: 0, iter: 20900, loss: 32.41617965698242\n",
      "epoch: 0, iter: 21000, loss: 32.36997604370117\n",
      "epoch: 0, iter: 21100, loss: 33.137508392333984\n",
      "epoch: 0, iter: 21200, loss: 31.37743377685547\n",
      "epoch: 0, iter: 21300, loss: 32.31303024291992\n",
      "epoch: 0, iter: 21400, loss: 31.811298370361328\n",
      "epoch: 0, iter: 21500, loss: 32.688873291015625\n",
      "epoch: 0, iter: 21600, loss: 32.22806930541992\n",
      "epoch: 0, iter: 21700, loss: 32.197837829589844\n",
      "epoch: 0, iter: 21800, loss: 32.25043487548828\n",
      "epoch: 0, iter: 21900, loss: 32.141788482666016\n",
      "epoch: 0, iter: 22000, loss: 33.19182586669922\n",
      "epoch: 0, iter: 22100, loss: 32.10587692260742\n",
      "epoch: 0, iter: 22200, loss: 31.91367530822754\n",
      "epoch: 0, iter: 22300, loss: 32.2746696472168\n",
      "epoch: 0, iter: 22400, loss: 32.389217376708984\n",
      "epoch: 0, iter: 22500, loss: 31.69915771484375\n",
      "epoch: 0, iter: 22600, loss: 32.298702239990234\n",
      "epoch: 0, iter: 22700, loss: 32.22545623779297\n",
      "epoch: 0, iter: 22800, loss: 32.77168273925781\n",
      "epoch: 0, iter: 22900, loss: 31.718826293945312\n",
      "epoch: 0, iter: 23000, loss: 32.01072311401367\n",
      "epoch: 0, iter: 23100, loss: 31.729949951171875\n",
      "epoch: 0, iter: 23200, loss: 32.29273986816406\n",
      "epoch: 0, iter: 23300, loss: 32.18684768676758\n",
      "epoch: 0, iter: 23400, loss: 32.13311767578125\n",
      "epoch: 0, iter: 23500, loss: 32.46500015258789\n",
      "epoch: 0, iter: 23600, loss: 31.68636131286621\n",
      "epoch: 0, iter: 23700, loss: 31.670278549194336\n",
      "epoch: 0, iter: 23800, loss: 31.885578155517578\n",
      "epoch: 0, iter: 23900, loss: 31.907176971435547\n",
      "epoch: 0, iter: 24000, loss: 31.427350997924805\n",
      "epoch: 0, iter: 24100, loss: 32.407493591308594\n",
      "epoch: 0, iter: 24200, loss: 31.827991485595703\n",
      "epoch: 0, iter: 24300, loss: 32.2097282409668\n",
      "epoch: 0, iter: 24400, loss: 31.458377838134766\n",
      "epoch: 0, iter: 24500, loss: 32.02303695678711\n",
      "epoch: 0, iter: 24600, loss: 32.112823486328125\n",
      "epoch: 0, iter: 24700, loss: 32.42934799194336\n",
      "epoch: 0, iter: 24800, loss: 34.98139953613281\n",
      "epoch: 0, iter: 24900, loss: 31.300899505615234\n",
      "epoch: 0, iter: 25000, loss: 31.88327980041504\n",
      "epoch: 0, iter: 25100, loss: 31.243215560913086\n",
      "epoch: 0, iter: 25200, loss: 32.242042541503906\n",
      "epoch: 0, iter: 25300, loss: 32.45793533325195\n",
      "epoch: 0, iter: 25400, loss: 32.85626220703125\n",
      "epoch: 0, iter: 25500, loss: 31.37156105041504\n",
      "epoch: 0, iter: 25600, loss: 32.05868148803711\n",
      "epoch: 0, iter: 25700, loss: 31.472227096557617\n",
      "epoch: 0, iter: 25800, loss: 32.53497314453125\n",
      "epoch: 0, iter: 25900, loss: 31.789884567260742\n",
      "epoch: 0, iter: 26000, loss: 32.178565979003906\n",
      "epoch: 0, iter: 26100, loss: 31.460487365722656\n",
      "epoch: 0, iter: 26200, loss: 31.6077938079834\n",
      "epoch: 0, iter: 26300, loss: 31.66497802734375\n",
      "epoch: 0, iter: 26400, loss: 31.943403244018555\n",
      "epoch: 0, iter: 26500, loss: 31.42506980895996\n",
      "epoch: 0, iter: 26600, loss: 31.38749122619629\n",
      "epoch: 0, iter: 26700, loss: 31.777297973632812\n",
      "epoch: 0, iter: 26800, loss: 32.291255950927734\n",
      "epoch: 0, iter: 26900, loss: 31.17464828491211\n",
      "epoch: 0, iter: 27000, loss: 31.80057144165039\n",
      "epoch: 0, iter: 27100, loss: 31.25439453125\n",
      "epoch: 0, iter: 27200, loss: 31.59163475036621\n",
      "epoch: 0, iter: 27300, loss: 32.40264892578125\n",
      "epoch: 0, iter: 27400, loss: 31.419052124023438\n",
      "epoch: 0, iter: 27500, loss: 31.87005043029785\n",
      "epoch: 0, iter: 27600, loss: 32.15163803100586\n",
      "epoch: 0, iter: 27700, loss: 31.320331573486328\n",
      "epoch: 0, iter: 27800, loss: 31.479080200195312\n",
      "epoch: 0, iter: 27900, loss: 31.911746978759766\n",
      "epoch: 0, iter: 28000, loss: 31.516315460205078\n",
      "epoch: 0, iter: 28100, loss: 31.907360076904297\n",
      "epoch: 0, iter: 28200, loss: 31.46992301940918\n",
      "epoch: 0, iter: 28300, loss: 31.647260665893555\n",
      "epoch: 0, iter: 28400, loss: 31.722854614257812\n",
      "epoch: 0, iter: 28500, loss: 31.815542221069336\n",
      "epoch: 0, iter: 28600, loss: 31.879404067993164\n",
      "epoch: 0, iter: 28700, loss: 31.678712844848633\n",
      "epoch: 0, iter: 28800, loss: 31.90729522705078\n",
      "epoch: 0, iter: 28900, loss: 31.973430633544922\n",
      "epoch: 0, iter: 29000, loss: 31.65265464782715\n",
      "epoch: 0, iter: 29100, loss: 31.62870216369629\n",
      "epoch: 0, iter: 29200, loss: 31.598867416381836\n",
      "epoch: 0, iter: 29300, loss: 31.318838119506836\n",
      "epoch: 0, iter: 29400, loss: 31.3765926361084\n",
      "epoch: 0, iter: 29500, loss: 31.971019744873047\n",
      "epoch: 0, iter: 29600, loss: 32.06196594238281\n",
      "epoch: 0, iter: 29700, loss: 31.438379287719727\n",
      "epoch: 0, iter: 29800, loss: 32.19248580932617\n",
      "epoch: 0, iter: 29900, loss: 30.77573585510254\n",
      "epoch: 0, iter: 30000, loss: 30.860885620117188\n",
      "epoch: 0, iter: 30100, loss: 31.628507614135742\n",
      "epoch: 0, iter: 30200, loss: 31.929363250732422\n",
      "epoch: 0, iter: 30300, loss: 31.588869094848633\n",
      "epoch: 0, iter: 30400, loss: 31.452802658081055\n",
      "epoch: 0, iter: 30500, loss: 32.0118408203125\n",
      "epoch: 0, iter: 30600, loss: 31.714065551757812\n",
      "epoch: 0, iter: 30700, loss: 31.60309600830078\n",
      "epoch: 0, iter: 30800, loss: 31.44661521911621\n",
      "epoch: 0, iter: 30900, loss: 30.972949981689453\n",
      "epoch: 0, iter: 31000, loss: 31.219541549682617\n",
      "epoch: 0, iter: 31100, loss: 32.2234001159668\n",
      "epoch: 0, iter: 31200, loss: 30.863250732421875\n",
      "epoch: 0, iter: 31300, loss: 31.841577529907227\n",
      "epoch: 0, iter: 31400, loss: 32.360023498535156\n",
      "epoch: 0, iter: 31500, loss: 31.545373916625977\n",
      "epoch: 0, iter: 31600, loss: 31.383874893188477\n",
      "epoch: 0, iter: 31700, loss: 31.314178466796875\n",
      "epoch: 0, iter: 31800, loss: 31.487863540649414\n",
      "epoch: 0, iter: 31900, loss: 32.101253509521484\n",
      "epoch: 0, iter: 32000, loss: 31.862388610839844\n",
      "epoch: 0, iter: 32100, loss: 31.52780532836914\n",
      "epoch: 0, iter: 32200, loss: 31.273588180541992\n",
      "epoch: 0, iter: 32300, loss: 31.75358772277832\n",
      "epoch: 0, iter: 32400, loss: 31.313575744628906\n",
      "epoch: 0, iter: 32500, loss: 31.363330841064453\n",
      "epoch: 0, iter: 32600, loss: 31.27507972717285\n",
      "epoch: 0, iter: 32700, loss: 31.57537841796875\n",
      "epoch: 0, iter: 32800, loss: 31.444393157958984\n",
      "epoch: 0, iter: 32900, loss: 31.38909339904785\n",
      "epoch: 0, iter: 33000, loss: 31.602567672729492\n",
      "epoch: 0, iter: 33100, loss: 31.483118057250977\n",
      "epoch: 0, iter: 33200, loss: 31.2891845703125\n",
      "epoch: 0, iter: 33300, loss: 31.331140518188477\n",
      "epoch: 0, iter: 33400, loss: 31.491010665893555\n",
      "epoch: 0, iter: 33500, loss: 31.63121223449707\n",
      "epoch: 0, iter: 33600, loss: 31.901344299316406\n",
      "epoch: 0, iter: 33700, loss: 31.328575134277344\n",
      "epoch: 0, iter: 33800, loss: 31.588106155395508\n",
      "epoch: 0, iter: 33900, loss: 31.47100830078125\n",
      "epoch: 0, iter: 34000, loss: 31.832984924316406\n",
      "epoch: 0, iter: 34100, loss: 31.566801071166992\n",
      "epoch: 0, iter: 34200, loss: 31.900043487548828\n",
      "epoch: 0, iter: 34300, loss: 31.842403411865234\n",
      "epoch: 0, iter: 34400, loss: 31.281108856201172\n",
      "epoch: 0, iter: 34500, loss: 31.674217224121094\n",
      "epoch: 0, iter: 34600, loss: 31.132728576660156\n",
      "epoch: 0, iter: 34700, loss: 31.29608917236328\n",
      "epoch: 0, iter: 34800, loss: 32.10063171386719\n",
      "epoch: 0, iter: 34900, loss: 31.418825149536133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, iter: 35000, loss: 31.65372085571289\n",
      "epoch: 0, iter: 35100, loss: 31.492177963256836\n",
      "epoch: 0, iter: 35200, loss: 31.14501953125\n",
      "epoch: 0, iter: 35300, loss: 31.604248046875\n",
      "epoch: 0, iter: 35400, loss: 31.72936248779297\n",
      "epoch: 0, iter: 35500, loss: 31.5876522064209\n",
      "epoch: 0, iter: 35600, loss: 31.817596435546875\n",
      "epoch: 0, iter: 35700, loss: 31.336750030517578\n",
      "epoch: 0, iter: 35800, loss: 31.887115478515625\n",
      "epoch: 0, iter: 35900, loss: 31.254798889160156\n",
      "epoch: 0, iter: 36000, loss: 31.499473571777344\n",
      "epoch: 0, iter: 36100, loss: 31.621349334716797\n",
      "epoch: 0, iter: 36200, loss: 31.67698860168457\n",
      "epoch: 0, iter: 36300, loss: 31.65187644958496\n",
      "epoch: 0, iter: 36400, loss: 31.797264099121094\n",
      "epoch: 0, iter: 36500, loss: 31.74847412109375\n",
      "epoch: 0, iter: 36600, loss: 31.820606231689453\n",
      "epoch: 0, iter: 36700, loss: 31.831567764282227\n",
      "epoch: 0, iter: 36800, loss: 31.206192016601562\n",
      "epoch: 0, iter: 36900, loss: 31.717723846435547\n",
      "epoch: 0, iter: 37000, loss: 31.4779109954834\n",
      "epoch: 0, iter: 37100, loss: 31.416339874267578\n",
      "epoch: 0, iter: 37200, loss: 31.28396224975586\n",
      "epoch: 0, iter: 37300, loss: 30.7346134185791\n",
      "epoch: 0, iter: 37400, loss: 31.470523834228516\n",
      "epoch: 0, iter: 37500, loss: 30.95250701904297\n",
      "epoch: 0, iter: 37600, loss: 31.01774787902832\n",
      "epoch: 0, iter: 37700, loss: 31.20599365234375\n",
      "epoch: 0, iter: 37800, loss: 31.465131759643555\n",
      "epoch: 0, iter: 37900, loss: 31.154132843017578\n",
      "epoch: 0, iter: 38000, loss: 30.715625762939453\n",
      "epoch: 0, iter: 38100, loss: 31.228317260742188\n",
      "epoch: 0, iter: 38200, loss: 31.357070922851562\n",
      "epoch: 0, iter: 38300, loss: 31.542068481445312\n",
      "epoch: 0, iter: 38400, loss: 31.400148391723633\n",
      "epoch: 0, iter: 38500, loss: 31.983610153198242\n",
      "epoch: 0, iter: 38600, loss: 31.075729370117188\n",
      "epoch: 0, iter: 38700, loss: 31.548397064208984\n",
      "epoch: 0, iter: 38800, loss: 30.986759185791016\n",
      "epoch: 0, iter: 38900, loss: 31.21999740600586\n",
      "epoch: 0, iter: 39000, loss: 31.353660583496094\n",
      "epoch: 0, iter: 39100, loss: 31.429527282714844\n",
      "epoch: 0, iter: 39200, loss: 31.49917221069336\n",
      "epoch: 0, iter: 39300, loss: 31.60196876525879\n",
      "epoch: 0, iter: 39400, loss: 31.649303436279297\n",
      "epoch: 0, iter: 39500, loss: 31.424087524414062\n",
      "epoch: 0, iter: 39600, loss: 31.671367645263672\n",
      "epoch: 0, iter: 39700, loss: 31.63854217529297\n",
      "epoch: 0, iter: 39800, loss: 31.428936004638672\n",
      "epoch: 0, iter: 39900, loss: 31.367919921875\n",
      "epoch: 0, iter: 40000, loss: 31.274600982666016\n",
      "epoch: 0, iter: 40100, loss: 31.743728637695312\n",
      "epoch: 0, iter: 40200, loss: 31.3394718170166\n",
      "epoch: 0, iter: 40300, loss: 31.67978858947754\n",
      "epoch: 0, iter: 40400, loss: 31.778949737548828\n",
      "epoch: 0, iter: 40500, loss: 30.870929718017578\n",
      "epoch: 0, iter: 40600, loss: 31.140605926513672\n",
      "epoch: 0, iter: 40700, loss: 31.000164031982422\n",
      "epoch: 0, iter: 40800, loss: 31.31053924560547\n",
      "epoch: 0, iter: 40900, loss: 31.352901458740234\n",
      "epoch: 0, iter: 41000, loss: 31.36353302001953\n",
      "epoch: 0, iter: 41100, loss: 31.105430603027344\n",
      "epoch: 0, iter: 41200, loss: 31.15558624267578\n",
      "epoch: 0, iter: 41300, loss: 31.08633804321289\n",
      "epoch: 0, iter: 41400, loss: 31.100982666015625\n",
      "epoch: 0, iter: 41500, loss: 31.24673080444336\n",
      "epoch: 0, iter: 41600, loss: 31.347991943359375\n",
      "epoch: 0, iter: 41700, loss: 31.73244857788086\n",
      "epoch: 0, iter: 41800, loss: 31.284513473510742\n",
      "epoch: 0, iter: 41900, loss: 31.21845245361328\n",
      "epoch: 0, iter: 42000, loss: 31.31061363220215\n",
      "epoch: 0, iter: 42100, loss: 31.40144157409668\n",
      "epoch: 0, iter: 42200, loss: 31.291393280029297\n",
      "epoch: 0, iter: 42300, loss: 31.422164916992188\n",
      "epoch: 0, iter: 42400, loss: 31.334781646728516\n",
      "epoch: 0, iter: 42500, loss: 31.510927200317383\n",
      "epoch: 0, iter: 42600, loss: 31.11506462097168\n",
      "epoch: 0, iter: 42700, loss: 31.512447357177734\n",
      "epoch: 0, iter: 42800, loss: 31.095623016357422\n",
      "epoch: 0, iter: 42900, loss: 31.268695831298828\n",
      "epoch: 0, iter: 43000, loss: 30.936758041381836\n",
      "epoch: 0, iter: 43100, loss: 31.359432220458984\n",
      "epoch: 0, iter: 43200, loss: 31.19675064086914\n",
      "epoch: 0, iter: 43300, loss: 31.07942771911621\n",
      "epoch: 0, iter: 43400, loss: 31.356571197509766\n",
      "epoch: 0, iter: 43500, loss: 30.844266891479492\n",
      "epoch: 0, iter: 43600, loss: 30.9329891204834\n",
      "epoch: 0, iter: 43700, loss: 31.085357666015625\n",
      "epoch: 0, iter: 43800, loss: 30.987865447998047\n",
      "epoch: 0, iter: 43900, loss: 31.617788314819336\n",
      "epoch: 0, iter: 44000, loss: 31.22259521484375\n",
      "epoch: 0, iter: 44100, loss: 30.505800247192383\n",
      "epoch: 0, iter: 44200, loss: 31.599138259887695\n",
      "epoch: 0, iter: 44300, loss: 31.420852661132812\n",
      "epoch: 0, iter: 44400, loss: 31.135908126831055\n",
      "epoch: 0, iter: 44500, loss: 30.92605209350586\n",
      "epoch: 0, iter: 44600, loss: 31.857027053833008\n",
      "epoch: 0, iter: 44700, loss: 30.646059036254883\n",
      "epoch: 0, iter: 44800, loss: 31.15806007385254\n",
      "epoch: 0, iter: 44900, loss: 31.386226654052734\n",
      "epoch: 0, iter: 45000, loss: 31.16790771484375\n",
      "epoch: 0, iter: 45100, loss: 31.647592544555664\n",
      "epoch: 0, iter: 45200, loss: 31.517213821411133\n",
      "epoch: 0, iter: 45300, loss: 30.924945831298828\n",
      "epoch: 0, iter: 45400, loss: 31.278690338134766\n",
      "epoch: 0, iter: 45500, loss: 31.698375701904297\n",
      "epoch: 0, iter: 45600, loss: 30.72216796875\n",
      "epoch: 0, iter: 45700, loss: 31.305103302001953\n",
      "epoch: 0, iter: 45800, loss: 31.235973358154297\n",
      "epoch: 0, iter: 45900, loss: 31.298519134521484\n",
      "epoch: 0, iter: 46000, loss: 30.872421264648438\n",
      "epoch: 0, iter: 46100, loss: 30.956174850463867\n",
      "epoch: 0, iter: 46200, loss: 31.12397003173828\n",
      "epoch: 0, iter: 46300, loss: 31.247623443603516\n",
      "epoch: 0, iter: 46400, loss: 30.807613372802734\n",
      "epoch: 0, iter: 46500, loss: 31.511751174926758\n",
      "epoch: 0, iter: 46600, loss: 31.953357696533203\n",
      "epoch: 0, iter: 46700, loss: 31.57992172241211\n",
      "epoch: 0, iter: 46800, loss: 31.34687614440918\n",
      "epoch: 0, iter: 46900, loss: 31.214567184448242\n",
      "epoch: 0, iter: 47000, loss: 31.467220306396484\n",
      "epoch: 0, iter: 47100, loss: 30.577377319335938\n",
      "epoch: 0, iter: 47200, loss: 31.107452392578125\n",
      "epoch: 0, iter: 47300, loss: 31.223682403564453\n",
      "epoch: 0, iter: 47400, loss: 31.16958999633789\n",
      "epoch: 0, iter: 47500, loss: 31.293113708496094\n",
      "epoch: 0, iter: 47600, loss: 30.884424209594727\n",
      "epoch: 0, iter: 47700, loss: 31.004735946655273\n",
      "epoch: 0, iter: 47800, loss: 31.093799591064453\n",
      "epoch: 0, iter: 47900, loss: 31.349592208862305\n",
      "epoch: 0, iter: 48000, loss: 31.024375915527344\n",
      "epoch: 0, iter: 48100, loss: 31.07526969909668\n",
      "epoch: 0, iter: 48200, loss: 31.10546112060547\n",
      "epoch: 0, iter: 48300, loss: 31.062314987182617\n",
      "epoch: 0, iter: 48400, loss: 31.178455352783203\n",
      "epoch: 0, iter: 48500, loss: 31.980316162109375\n",
      "epoch: 0, iter: 48600, loss: 31.10259437561035\n",
      "epoch: 0, iter: 48700, loss: 31.136383056640625\n",
      "epoch: 0, iter: 48800, loss: 30.91892433166504\n",
      "epoch: 0, iter: 48900, loss: 31.164600372314453\n",
      "epoch: 0, iter: 49000, loss: 31.044815063476562\n",
      "epoch: 0, iter: 49100, loss: 30.943565368652344\n",
      "epoch: 0, iter: 49200, loss: 31.314943313598633\n",
      "epoch: 0, iter: 49300, loss: 30.695940017700195\n",
      "epoch: 0, iter: 49400, loss: 31.18203353881836\n",
      "epoch: 0, iter: 49500, loss: 31.081478118896484\n",
      "epoch: 0, iter: 49600, loss: 31.250837326049805\n",
      "epoch: 0, iter: 49700, loss: 31.33332061767578\n",
      "epoch: 0, iter: 49800, loss: 30.763023376464844\n",
      "epoch: 0, iter: 49900, loss: 31.403522491455078\n",
      "epoch: 0, iter: 50000, loss: 31.242321014404297\n",
      "epoch: 0, iter: 50100, loss: 30.90090560913086\n",
      "epoch: 0, iter: 50200, loss: 31.460126876831055\n",
      "epoch: 0, iter: 50300, loss: 31.117021560668945\n",
      "epoch: 0, iter: 50400, loss: 30.725788116455078\n",
      "epoch: 0, iter: 50500, loss: 31.20831298828125\n",
      "epoch: 0, iter: 50600, loss: 30.891586303710938\n",
      "epoch: 0, iter: 50700, loss: 30.50568199157715\n",
      "epoch: 0, iter: 50800, loss: 31.213497161865234\n",
      "epoch: 0, iter: 50900, loss: 31.048280715942383\n",
      "epoch: 0, iter: 51000, loss: 30.823883056640625\n",
      "epoch: 0, iter: 51100, loss: 30.964601516723633\n",
      "epoch: 0, iter: 51200, loss: 30.777759552001953\n",
      "epoch: 0, iter: 51300, loss: 31.450632095336914\n",
      "epoch: 0, iter: 51400, loss: 31.181848526000977\n",
      "epoch: 0, iter: 51500, loss: 31.247222900390625\n",
      "epoch: 0, iter: 51600, loss: 31.075626373291016\n",
      "epoch: 0, iter: 51700, loss: 31.248933792114258\n",
      "epoch: 0, iter: 51800, loss: 31.196666717529297\n",
      "epoch: 0, iter: 51900, loss: 30.777063369750977\n",
      "epoch: 0, iter: 52000, loss: 31.672931671142578\n",
      "epoch: 0, iter: 52100, loss: 31.171154022216797\n",
      "epoch: 0, iter: 52200, loss: 31.275978088378906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, iter: 52300, loss: 31.150901794433594\n",
      "epoch: 0, iter: 52400, loss: 30.906295776367188\n",
      "epoch: 0, iter: 52500, loss: 31.07915496826172\n",
      "epoch: 0, iter: 52600, loss: 31.541339874267578\n",
      "epoch: 0, iter: 52700, loss: 31.333927154541016\n",
      "epoch: 0, iter: 52800, loss: 30.98295783996582\n",
      "epoch: 0, iter: 52900, loss: 30.94872283935547\n",
      "epoch: 0, iter: 53000, loss: 30.993457794189453\n",
      "epoch: 0, iter: 53100, loss: 31.432682037353516\n",
      "epoch: 0, iter: 53200, loss: 31.11025047302246\n",
      "epoch: 0, iter: 53300, loss: 30.78118133544922\n",
      "epoch: 0, iter: 53400, loss: 31.188953399658203\n",
      "epoch: 0, iter: 53500, loss: 31.29664421081543\n",
      "epoch: 0, iter: 53600, loss: 31.00973129272461\n",
      "epoch: 0, iter: 53700, loss: 31.332082748413086\n",
      "epoch: 0, iter: 53800, loss: 30.618459701538086\n",
      "epoch: 0, iter: 53900, loss: 30.951351165771484\n",
      "epoch: 0, iter: 54000, loss: 31.382783889770508\n",
      "epoch: 0, iter: 54100, loss: 30.48594093322754\n",
      "epoch: 0, iter: 54200, loss: 30.927156448364258\n",
      "epoch: 0, iter: 54300, loss: 31.086322784423828\n",
      "epoch: 0, iter: 54400, loss: 30.737083435058594\n",
      "epoch: 0, iter: 54500, loss: 31.257322311401367\n",
      "epoch: 0, iter: 54600, loss: 30.9127197265625\n",
      "epoch: 0, iter: 54700, loss: 31.08020782470703\n",
      "epoch: 0, iter: 54800, loss: 30.731399536132812\n",
      "epoch: 0, iter: 54900, loss: 31.113351821899414\n",
      "epoch: 0, iter: 55000, loss: 30.594205856323242\n",
      "epoch: 0, iter: 55100, loss: 30.73430633544922\n",
      "epoch: 0, iter: 55200, loss: 31.048521041870117\n",
      "epoch: 0, iter: 55300, loss: 30.76434326171875\n",
      "epoch: 0, iter: 55400, loss: 30.80013084411621\n",
      "epoch: 0, iter: 55500, loss: 31.3070125579834\n",
      "epoch: 0, iter: 55600, loss: 31.14901351928711\n",
      "epoch: 0, iter: 55700, loss: 31.293018341064453\n",
      "epoch: 0, iter: 55800, loss: 31.062602996826172\n",
      "epoch: 0, iter: 55900, loss: 30.712387084960938\n",
      "epoch: 0, iter: 56000, loss: 30.829998016357422\n",
      "epoch: 0, iter: 56100, loss: 30.844432830810547\n",
      "epoch: 0, iter: 56200, loss: 31.338809967041016\n",
      "epoch: 0, iter: 56300, loss: 31.070392608642578\n",
      "epoch: 0, iter: 56400, loss: 31.117830276489258\n",
      "epoch: 0, iter: 56500, loss: 31.751785278320312\n",
      "epoch: 0, iter: 56600, loss: 31.10342788696289\n",
      "epoch: 0, iter: 56700, loss: 30.92790412902832\n",
      "epoch: 0, iter: 56800, loss: 30.973901748657227\n",
      "epoch: 0, iter: 56900, loss: 31.088478088378906\n",
      "epoch: 0, iter: 57000, loss: 30.99569320678711\n",
      "epoch: 0, iter: 57100, loss: 31.27613067626953\n",
      "epoch: 0, iter: 57200, loss: 30.799787521362305\n",
      "epoch: 0, iter: 57300, loss: 30.841562271118164\n",
      "epoch: 0, iter: 57400, loss: 31.050092697143555\n",
      "epoch: 0, iter: 57500, loss: 31.098520278930664\n",
      "epoch: 0, iter: 57600, loss: 30.856151580810547\n",
      "epoch: 0, iter: 57700, loss: 31.164501190185547\n",
      "epoch: 0, iter: 57800, loss: 30.60720443725586\n",
      "epoch: 0, iter: 57900, loss: 31.0699462890625\n",
      "epoch: 0, iter: 58000, loss: 31.23084259033203\n",
      "epoch: 0, iter: 58100, loss: 30.695858001708984\n",
      "epoch: 0, iter: 58200, loss: 31.231243133544922\n",
      "epoch: 0, iter: 58300, loss: 30.91762924194336\n",
      "epoch: 0, iter: 58400, loss: 31.429441452026367\n",
      "epoch: 0, iter: 58500, loss: 31.252853393554688\n",
      "epoch: 0, iter: 58600, loss: 30.865985870361328\n",
      "epoch: 0, iter: 58700, loss: 30.76547622680664\n",
      "epoch: 0, iter: 58800, loss: 31.584659576416016\n",
      "epoch: 0, iter: 58900, loss: 31.014373779296875\n",
      "epoch: 0, iter: 59000, loss: 30.955780029296875\n",
      "epoch: 0, iter: 59100, loss: 31.072717666625977\n",
      "epoch: 0, iter: 59200, loss: 31.24224853515625\n",
      "epoch: 0, iter: 59300, loss: 30.375965118408203\n",
      "epoch: 0, iter: 59400, loss: 30.752012252807617\n",
      "epoch: 0, iter: 59500, loss: 31.04286766052246\n",
      "epoch: 0, iter: 59600, loss: 30.864521026611328\n",
      "epoch: 0, iter: 59700, loss: 31.1716251373291\n",
      "epoch: 0, iter: 59800, loss: 30.86480712890625\n",
      "epoch: 0, iter: 59900, loss: 31.39410400390625\n",
      "epoch: 0, iter: 60000, loss: 31.49703598022461\n",
      "epoch: 0, iter: 60100, loss: 30.738773345947266\n",
      "epoch: 0, iter: 60200, loss: 31.36499786376953\n",
      "epoch: 0, iter: 60300, loss: 30.832462310791016\n",
      "epoch: 0, iter: 60400, loss: 31.054790496826172\n",
      "epoch: 0, iter: 60500, loss: 30.77410888671875\n",
      "epoch: 0, iter: 60600, loss: 31.446298599243164\n",
      "epoch: 0, iter: 60700, loss: 30.55773162841797\n",
      "epoch: 0, iter: 60800, loss: 31.272811889648438\n",
      "epoch: 0, iter: 60900, loss: 31.519044876098633\n",
      "epoch: 0, iter: 61000, loss: 30.660667419433594\n",
      "epoch: 0, iter: 61100, loss: 31.244428634643555\n",
      "epoch: 0, iter: 61200, loss: 30.849876403808594\n",
      "epoch: 0, iter: 61300, loss: 30.29256820678711\n",
      "epoch: 0, iter: 61400, loss: 31.031091690063477\n",
      "epoch: 0, iter: 61500, loss: 31.21367645263672\n",
      "epoch: 0, iter: 61600, loss: 30.910654067993164\n",
      "epoch: 0, iter: 61700, loss: 31.100963592529297\n",
      "epoch: 0, iter: 61800, loss: 31.285358428955078\n",
      "epoch: 0, iter: 61900, loss: 31.53032112121582\n",
      "epoch: 0, iter: 62000, loss: 30.916526794433594\n",
      "epoch: 0, iter: 62100, loss: 31.08417510986328\n",
      "epoch: 0, iter: 62200, loss: 31.13498878479004\n",
      "epoch: 0, iter: 62300, loss: 31.189844131469727\n",
      "epoch: 0, iter: 62400, loss: 30.86542510986328\n",
      "epoch: 0, iter: 62500, loss: 30.614587783813477\n",
      "epoch: 0, iter: 62600, loss: 30.498552322387695\n",
      "epoch: 0, iter: 62700, loss: 31.0284423828125\n",
      "epoch: 0, iter: 62800, loss: 30.78326416015625\n",
      "epoch: 0, iter: 62900, loss: 30.892902374267578\n",
      "epoch: 0, iter: 63000, loss: 30.998703002929688\n",
      "epoch: 0, iter: 63100, loss: 31.105836868286133\n",
      "epoch: 0, iter: 63200, loss: 31.65543556213379\n",
      "epoch: 0, iter: 63300, loss: 30.388635635375977\n",
      "epoch: 0, iter: 63400, loss: 31.651180267333984\n",
      "epoch: 0, iter: 63500, loss: 30.805282592773438\n",
      "epoch: 0, iter: 63600, loss: 31.168027877807617\n",
      "epoch: 0, iter: 63700, loss: 31.12360954284668\n",
      "epoch: 0, iter: 63800, loss: 30.955997467041016\n",
      "epoch: 0, iter: 63900, loss: 30.825429916381836\n",
      "epoch: 0, iter: 64000, loss: 31.108070373535156\n",
      "epoch: 0, iter: 64100, loss: 30.762371063232422\n",
      "epoch: 0, iter: 64200, loss: 30.789833068847656\n",
      "epoch: 0, iter: 64300, loss: 30.881000518798828\n",
      "epoch: 0, iter: 64400, loss: 31.249271392822266\n",
      "epoch: 0, iter: 64500, loss: 30.84442901611328\n",
      "epoch: 0, iter: 64600, loss: 30.944231033325195\n",
      "epoch: 0, iter: 64700, loss: 31.259143829345703\n",
      "epoch: 0, iter: 64800, loss: 30.856531143188477\n",
      "epoch: 0, iter: 64900, loss: 30.55644416809082\n",
      "epoch: 0, iter: 65000, loss: 31.05147933959961\n",
      "epoch: 0, iter: 65100, loss: 31.2882080078125\n",
      "epoch: 0, iter: 65200, loss: 31.299175262451172\n",
      "epoch: 0, iter: 65300, loss: 31.13555908203125\n",
      "epoch: 0, iter: 65400, loss: 31.22186851501465\n",
      "epoch: 0, iter: 65500, loss: 30.83234977722168\n",
      "epoch: 0, iter: 65600, loss: 30.717023849487305\n",
      "epoch: 0, iter: 65700, loss: 30.93946075439453\n",
      "epoch: 0, iter: 65800, loss: 30.930776596069336\n",
      "epoch: 0, iter: 65900, loss: 30.950469970703125\n",
      "epoch: 0, iter: 66000, loss: 30.941980361938477\n",
      "epoch: 0, iter: 66100, loss: 31.16675567626953\n",
      "epoch: 0, iter: 66200, loss: 30.647014617919922\n",
      "epoch: 0, iter: 66300, loss: 30.837974548339844\n",
      "epoch: 0, iter: 66400, loss: 31.18476104736328\n",
      "epoch: 0, iter: 66500, loss: 30.744232177734375\n",
      "epoch: 0, iter: 66600, loss: 30.575592041015625\n",
      "epoch: 0, iter: 66700, loss: 30.605501174926758\n",
      "epoch: 0, iter: 66800, loss: 31.23296546936035\n",
      "epoch: 0, iter: 66900, loss: 31.260147094726562\n",
      "epoch: 0, iter: 67000, loss: 31.383886337280273\n",
      "epoch: 0, iter: 67100, loss: 31.01959800720215\n",
      "epoch: 0, iter: 67200, loss: 30.93276596069336\n",
      "epoch: 0, iter: 67300, loss: 30.958152770996094\n",
      "epoch: 0, iter: 67400, loss: 30.906164169311523\n",
      "epoch: 0, iter: 67500, loss: 30.757844924926758\n",
      "epoch: 0, iter: 67600, loss: 30.400402069091797\n",
      "epoch: 0, iter: 67700, loss: 31.079317092895508\n",
      "epoch: 0, iter: 67800, loss: 31.10834312438965\n",
      "epoch: 0, iter: 67900, loss: 31.279373168945312\n",
      "epoch: 0, iter: 68000, loss: 31.12595558166504\n",
      "epoch: 0, iter: 68100, loss: 31.39122772216797\n",
      "epoch: 0, iter: 68200, loss: 30.774765014648438\n",
      "epoch: 0, iter: 68300, loss: 30.750194549560547\n",
      "epoch: 0, iter: 68400, loss: 31.728342056274414\n",
      "epoch: 0, iter: 68500, loss: 30.4342041015625\n",
      "epoch: 0, iter: 68600, loss: 30.62394905090332\n",
      "epoch: 0, iter: 68700, loss: 30.628042221069336\n",
      "epoch: 0, iter: 68800, loss: 30.964618682861328\n",
      "epoch: 0, iter: 68900, loss: 30.859542846679688\n",
      "epoch: 0, iter: 69000, loss: 30.430042266845703\n",
      "epoch: 0, iter: 69100, loss: 30.84952735900879\n",
      "epoch: 0, iter: 69200, loss: 30.384174346923828\n",
      "epoch: 0, iter: 69300, loss: 31.11663246154785\n",
      "epoch: 0, iter: 69400, loss: 30.305307388305664\n",
      "epoch: 0, iter: 69500, loss: 31.334049224853516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, iter: 69600, loss: 30.973575592041016\n",
      "epoch: 0, iter: 69700, loss: 30.55046272277832\n",
      "epoch: 0, iter: 69800, loss: 30.571338653564453\n",
      "epoch: 0, iter: 69900, loss: 31.340660095214844\n",
      "epoch: 0, iter: 70000, loss: 31.16770362854004\n",
      "epoch: 0, iter: 70100, loss: 31.178417205810547\n",
      "epoch: 0, iter: 70200, loss: 30.85662269592285\n",
      "epoch: 0, iter: 70300, loss: 30.93984603881836\n",
      "epoch: 0, iter: 70400, loss: 31.12394142150879\n",
      "epoch: 0, iter: 70500, loss: 30.65265655517578\n",
      "epoch: 0, iter: 70600, loss: 30.738887786865234\n",
      "epoch: 0, iter: 70700, loss: 31.22895622253418\n",
      "epoch: 0, iter: 70800, loss: 31.20877456665039\n",
      "epoch: 0, iter: 70900, loss: 30.531333923339844\n",
      "epoch: 0, iter: 71000, loss: 30.64777374267578\n",
      "epoch: 0, iter: 71100, loss: 30.633207321166992\n",
      "epoch: 0, iter: 71200, loss: 31.328046798706055\n",
      "epoch: 0, iter: 71300, loss: 31.190513610839844\n",
      "epoch: 0, iter: 71400, loss: 30.602359771728516\n",
      "epoch: 0, iter: 71500, loss: 31.03752326965332\n",
      "epoch: 0, iter: 71600, loss: 30.312740325927734\n",
      "epoch: 0, iter: 71700, loss: 30.910877227783203\n",
      "epoch: 0, iter: 71800, loss: 30.668853759765625\n",
      "epoch: 0, iter: 71900, loss: 30.87957000732422\n",
      "epoch: 0, iter: 72000, loss: 30.68610382080078\n",
      "epoch: 0, iter: 72100, loss: 31.1173095703125\n",
      "epoch: 0, iter: 72200, loss: 31.2646541595459\n",
      "epoch: 0, iter: 72300, loss: 30.98324966430664\n",
      "epoch: 0, iter: 72400, loss: 30.840173721313477\n",
      "epoch: 0, iter: 72500, loss: 31.062053680419922\n",
      "epoch: 0, iter: 72600, loss: 30.727888107299805\n",
      "epoch: 0, iter: 72700, loss: 30.794189453125\n",
      "epoch: 0, iter: 72800, loss: 31.041032791137695\n",
      "epoch: 0, iter: 72900, loss: 30.72784996032715\n",
      "epoch: 0, iter: 73000, loss: 31.03763198852539\n",
      "epoch: 0, iter: 73100, loss: 31.240198135375977\n",
      "epoch: 0, iter: 73200, loss: 31.065900802612305\n",
      "epoch: 0, iter: 73300, loss: 30.691251754760742\n",
      "epoch: 0, iter: 73400, loss: 30.818405151367188\n",
      "epoch: 0, iter: 73500, loss: 30.89800453186035\n",
      "epoch: 0, iter: 73600, loss: 31.125638961791992\n",
      "epoch: 0, iter: 73700, loss: 31.175554275512695\n",
      "epoch: 0, iter: 73800, loss: 30.675670623779297\n",
      "epoch: 0, iter: 73900, loss: 30.589128494262695\n",
      "epoch: 0, iter: 74000, loss: 31.056020736694336\n",
      "epoch: 0, iter: 74100, loss: 31.27462387084961\n",
      "epoch: 0, iter: 74200, loss: 30.788349151611328\n",
      "epoch: 0, iter: 74300, loss: 30.878442764282227\n",
      "epoch: 0, iter: 74400, loss: 30.863079071044922\n",
      "epoch: 0, iter: 74500, loss: 30.335514068603516\n",
      "epoch: 0, iter: 74600, loss: 31.258378982543945\n",
      "epoch: 0, iter: 74700, loss: 30.55044937133789\n",
      "epoch: 0, iter: 74800, loss: 31.46634292602539\n",
      "epoch: 0, iter: 74900, loss: 30.83053970336914\n",
      "epoch: 0, iter: 75000, loss: 31.46294403076172\n",
      "epoch: 0, iter: 75100, loss: 30.82330322265625\n",
      "epoch: 0, iter: 75200, loss: 30.692089080810547\n",
      "epoch: 0, iter: 75300, loss: 30.827285766601562\n",
      "epoch: 0, iter: 75400, loss: 31.08740234375\n",
      "epoch: 0, iter: 75500, loss: 31.104915618896484\n",
      "epoch: 0, iter: 75600, loss: 30.96943473815918\n",
      "epoch: 0, iter: 75700, loss: 30.73410415649414\n",
      "epoch: 0, iter: 75800, loss: 30.39057159423828\n",
      "epoch: 0, iter: 75900, loss: 30.59615135192871\n",
      "epoch: 0, iter: 76000, loss: 30.89775276184082\n",
      "epoch: 0, iter: 76100, loss: 31.17781639099121\n",
      "epoch: 0, iter: 76200, loss: 31.0789794921875\n",
      "epoch: 0, iter: 76300, loss: 31.03806495666504\n",
      "epoch: 0, iter: 76400, loss: 31.320466995239258\n",
      "epoch: 0, iter: 76500, loss: 30.87887191772461\n",
      "epoch: 0, iter: 76600, loss: 31.055091857910156\n",
      "epoch: 0, iter: 76700, loss: 31.404579162597656\n",
      "epoch: 0, iter: 76800, loss: 30.74361228942871\n",
      "epoch: 0, iter: 76900, loss: 30.474199295043945\n",
      "epoch: 0, iter: 77000, loss: 31.16591453552246\n",
      "epoch: 0, iter: 77100, loss: 31.014629364013672\n",
      "epoch: 0, iter: 77200, loss: 31.283506393432617\n",
      "epoch: 0, iter: 77300, loss: 31.015972137451172\n",
      "epoch: 0, iter: 77400, loss: 30.674022674560547\n",
      "epoch: 0, iter: 77500, loss: 31.055599212646484\n",
      "epoch: 0, iter: 77600, loss: 30.6943302154541\n",
      "epoch: 0, iter: 77700, loss: 30.97377586364746\n",
      "epoch: 0, iter: 77800, loss: 30.851869583129883\n",
      "epoch: 0, iter: 77900, loss: 31.43417739868164\n",
      "epoch: 0, iter: 78000, loss: 30.227794647216797\n",
      "epoch: 0, iter: 78100, loss: 30.332672119140625\n",
      "epoch: 0, iter: 78200, loss: 30.973234176635742\n",
      "epoch: 0, iter: 78300, loss: 31.095333099365234\n",
      "epoch: 0, iter: 78400, loss: 30.683895111083984\n",
      "epoch: 0, iter: 78500, loss: 30.676897048950195\n",
      "epoch: 0, iter: 78600, loss: 30.199337005615234\n",
      "epoch: 0, iter: 78700, loss: 30.743724822998047\n",
      "epoch: 0, iter: 78800, loss: 31.516855239868164\n",
      "epoch: 0, iter: 78900, loss: 31.273759841918945\n",
      "epoch: 0, iter: 79000, loss: 31.120637893676758\n",
      "epoch: 0, iter: 79100, loss: 30.616369247436523\n",
      "epoch: 0, iter: 79200, loss: 30.5263729095459\n",
      "epoch: 0, iter: 79300, loss: 30.998445510864258\n",
      "epoch: 0, iter: 79400, loss: 31.08501434326172\n",
      "epoch: 0, iter: 79500, loss: 30.775440216064453\n",
      "epoch: 0, iter: 79600, loss: 30.416107177734375\n",
      "epoch: 0, iter: 79700, loss: 30.813467025756836\n",
      "epoch: 0, iter: 79800, loss: 30.532733917236328\n",
      "epoch: 0, iter: 79900, loss: 30.93060874938965\n",
      "epoch: 0, iter: 80000, loss: 31.121809005737305\n",
      "epoch: 0, iter: 80100, loss: 31.029142379760742\n",
      "epoch: 0, iter: 80200, loss: 30.639877319335938\n",
      "epoch: 0, iter: 80300, loss: 30.688875198364258\n",
      "epoch: 0, iter: 80400, loss: 30.654966354370117\n",
      "epoch: 0, iter: 80500, loss: 30.75569725036621\n",
      "epoch: 0, iter: 80600, loss: 30.476459503173828\n",
      "epoch: 0, iter: 80700, loss: 31.128463745117188\n",
      "epoch: 0, iter: 80800, loss: 30.462085723876953\n",
      "epoch: 0, iter: 80900, loss: 31.27433204650879\n",
      "epoch: 0, iter: 81000, loss: 30.879711151123047\n",
      "epoch: 0, iter: 81100, loss: 31.04444122314453\n",
      "epoch: 0, iter: 81200, loss: 31.00887680053711\n",
      "epoch: 0, iter: 81300, loss: 31.128759384155273\n",
      "epoch: 0, iter: 81400, loss: 30.920175552368164\n",
      "epoch: 0, iter: 81500, loss: 30.747209548950195\n",
      "epoch: 0, iter: 81600, loss: 30.923059463500977\n",
      "epoch: 0, iter: 81700, loss: 30.666460037231445\n",
      "epoch: 0, iter: 81800, loss: 30.985807418823242\n",
      "epoch: 0, iter: 81900, loss: 30.830028533935547\n",
      "epoch: 0, iter: 82000, loss: 31.137371063232422\n",
      "epoch: 0, iter: 82100, loss: 31.15390396118164\n",
      "epoch: 0, iter: 82200, loss: 30.90130043029785\n",
      "epoch: 0, iter: 82300, loss: 30.96506118774414\n",
      "epoch: 0, iter: 82400, loss: 31.148317337036133\n",
      "epoch: 0, iter: 82500, loss: 31.04027557373047\n",
      "epoch: 0, iter: 82600, loss: 31.060590744018555\n",
      "epoch: 0, iter: 82700, loss: 30.795761108398438\n",
      "epoch: 0, iter: 82800, loss: 31.100889205932617\n",
      "epoch: 0, iter: 82900, loss: 30.805713653564453\n",
      "epoch: 0, iter: 83000, loss: 30.72894287109375\n",
      "epoch: 0, iter: 83100, loss: 30.477046966552734\n",
      "epoch: 0, iter: 83200, loss: 31.01129913330078\n",
      "epoch: 0, iter: 83300, loss: 30.889690399169922\n",
      "epoch: 0, iter: 83400, loss: 30.995838165283203\n",
      "epoch: 0, iter: 83500, loss: 30.792701721191406\n",
      "epoch: 0, iter: 83600, loss: 30.925125122070312\n",
      "epoch: 0, iter: 83700, loss: 30.7823486328125\n",
      "epoch: 0, iter: 83800, loss: 31.084606170654297\n",
      "epoch: 0, iter: 83900, loss: 30.25952911376953\n",
      "epoch: 0, iter: 84000, loss: 30.82536506652832\n",
      "epoch: 0, iter: 84100, loss: 31.223220825195312\n",
      "epoch: 0, iter: 84200, loss: 30.570018768310547\n",
      "epoch: 0, iter: 84300, loss: 30.795621871948242\n",
      "epoch: 0, iter: 84400, loss: 30.849056243896484\n",
      "epoch: 0, iter: 84500, loss: 31.070478439331055\n",
      "epoch: 0, iter: 84600, loss: 30.66322135925293\n",
      "epoch: 0, iter: 84700, loss: 30.754980087280273\n",
      "epoch: 0, iter: 84800, loss: 31.086193084716797\n",
      "epoch: 0, iter: 84900, loss: 31.143638610839844\n",
      "epoch: 0, iter: 85000, loss: 31.24083709716797\n",
      "epoch: 0, iter: 85100, loss: 30.9083251953125\n",
      "epoch: 0, iter: 85200, loss: 30.985435485839844\n",
      "epoch: 0, iter: 85300, loss: 31.02812957763672\n",
      "epoch: 0, iter: 85400, loss: 30.694793701171875\n",
      "epoch: 0, iter: 85500, loss: 30.79397964477539\n",
      "epoch: 0, iter: 85600, loss: 30.80388069152832\n",
      "epoch: 0, iter: 85700, loss: 31.172117233276367\n",
      "epoch: 0, iter: 85800, loss: 31.141239166259766\n",
      "epoch: 0, iter: 85900, loss: 29.56962776184082\n",
      "epoch: 0, iter: 86000, loss: 30.992881774902344\n",
      "epoch: 0, iter: 86100, loss: 30.083444595336914\n",
      "epoch: 0, iter: 86200, loss: 30.93154525756836\n",
      "epoch: 0, iter: 86300, loss: 30.5662784576416\n",
      "epoch: 0, iter: 86400, loss: 31.350173950195312\n",
      "epoch: 0, iter: 86500, loss: 30.487886428833008\n",
      "epoch: 0, iter: 86600, loss: 31.411882400512695\n",
      "epoch: 0, iter: 86700, loss: 30.85624122619629\n",
      "epoch: 0, iter: 86800, loss: 31.064353942871094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, iter: 86900, loss: 31.112844467163086\n",
      "epoch: 0, iter: 87000, loss: 30.646249771118164\n",
      "epoch: 0, iter: 87100, loss: 30.514963150024414\n",
      "epoch: 0, iter: 87200, loss: 30.814855575561523\n",
      "epoch: 0, iter: 87300, loss: 30.547473907470703\n",
      "epoch: 0, iter: 87400, loss: 31.03626823425293\n",
      "epoch: 0, iter: 87500, loss: 30.531963348388672\n",
      "epoch: 0, iter: 87600, loss: 30.970291137695312\n",
      "epoch: 0, iter: 87700, loss: 31.113658905029297\n",
      "epoch: 0, iter: 87800, loss: 30.70583152770996\n",
      "epoch: 0, iter: 87900, loss: 30.231983184814453\n",
      "epoch: 0, iter: 88000, loss: 31.034385681152344\n",
      "epoch: 0, iter: 88100, loss: 31.26152801513672\n",
      "epoch: 0, iter: 88200, loss: 30.556272506713867\n",
      "epoch: 0, iter: 88300, loss: 30.37435531616211\n",
      "epoch: 0, iter: 88400, loss: 30.888999938964844\n",
      "epoch: 0, iter: 88500, loss: 31.43544578552246\n",
      "epoch: 0, iter: 88600, loss: 30.379802703857422\n",
      "epoch: 0, iter: 88700, loss: 30.733320236206055\n",
      "epoch: 0, iter: 88800, loss: 30.518768310546875\n",
      "epoch: 0, iter: 88900, loss: 30.729991912841797\n",
      "epoch: 0, iter: 89000, loss: 31.13309669494629\n",
      "epoch: 0, iter: 89100, loss: 30.896142959594727\n",
      "epoch: 0, iter: 89200, loss: 30.597803115844727\n",
      "epoch: 0, iter: 89300, loss: 31.136886596679688\n",
      "epoch: 0, iter: 89400, loss: 30.436264038085938\n",
      "epoch: 0, iter: 89500, loss: 30.681610107421875\n",
      "epoch: 0, iter: 89600, loss: 30.570541381835938\n",
      "epoch: 0, iter: 89700, loss: 31.173402786254883\n",
      "epoch: 0, iter: 89800, loss: 31.17083740234375\n",
      "epoch: 0, iter: 89900, loss: 31.253141403198242\n",
      "epoch: 0, iter: 90000, loss: 30.66145896911621\n",
      "epoch: 0, iter: 90100, loss: 31.088430404663086\n",
      "epoch: 0, iter: 90200, loss: 31.082210540771484\n",
      "epoch: 0, iter: 90300, loss: 30.936887741088867\n",
      "epoch: 0, iter: 90400, loss: 31.31647300720215\n",
      "epoch: 0, iter: 90500, loss: 31.11327362060547\n",
      "epoch: 0, iter: 90600, loss: 30.910507202148438\n",
      "epoch: 0, iter: 90700, loss: 30.94036865234375\n",
      "epoch: 0, iter: 90800, loss: 30.77941131591797\n",
      "epoch: 0, iter: 90900, loss: 31.132694244384766\n",
      "epoch: 0, iter: 91000, loss: 30.67490005493164\n",
      "epoch: 0, iter: 91100, loss: 30.617082595825195\n",
      "epoch: 0, iter: 91200, loss: 30.665359497070312\n",
      "epoch: 0, iter: 91300, loss: 30.672290802001953\n",
      "epoch: 0, iter: 91400, loss: 31.238948822021484\n",
      "epoch: 0, iter: 91500, loss: 31.020816802978516\n",
      "epoch: 0, iter: 91600, loss: 30.624351501464844\n",
      "epoch: 0, iter: 91700, loss: 31.030975341796875\n",
      "epoch: 0, iter: 91800, loss: 30.238483428955078\n",
      "epoch: 0, iter: 91900, loss: 30.810483932495117\n",
      "epoch: 0, iter: 92000, loss: 30.870370864868164\n",
      "epoch: 0, iter: 92100, loss: 30.50164031982422\n",
      "epoch: 0, iter: 92200, loss: 30.922927856445312\n",
      "epoch: 0, iter: 92300, loss: 30.740140914916992\n",
      "epoch: 0, iter: 92400, loss: 30.86549186706543\n",
      "epoch: 0, iter: 92500, loss: 30.76512336730957\n",
      "epoch: 0, iter: 92600, loss: 30.849071502685547\n",
      "epoch: 0, iter: 92700, loss: 30.62224578857422\n",
      "epoch: 0, iter: 92800, loss: 30.761404037475586\n",
      "epoch: 0, iter: 92900, loss: 30.782934188842773\n",
      "epoch: 0, iter: 93000, loss: 30.448442459106445\n",
      "epoch: 0, iter: 93100, loss: 30.639789581298828\n",
      "epoch: 0, iter: 93200, loss: 30.678634643554688\n",
      "epoch: 0, iter: 93300, loss: 30.356935501098633\n",
      "epoch: 0, iter: 93400, loss: 30.662830352783203\n",
      "epoch: 0, iter: 93500, loss: 30.7647762298584\n",
      "epoch: 0, iter: 93600, loss: 30.747936248779297\n",
      "epoch: 0, iter: 93700, loss: 30.693830490112305\n",
      "epoch: 0, iter: 93800, loss: 30.751811981201172\n",
      "epoch: 0, iter: 93900, loss: 30.591703414916992\n",
      "epoch: 0, iter: 94000, loss: 30.5693302154541\n",
      "epoch: 0, iter: 94100, loss: 30.890851974487305\n",
      "epoch: 0, iter: 94200, loss: 30.925321578979492\n",
      "epoch: 0, iter: 94300, loss: 30.97283172607422\n",
      "epoch: 0, iter: 94400, loss: 30.851831436157227\n",
      "epoch: 0, iter: 94500, loss: 31.206554412841797\n",
      "epoch: 0, iter: 94600, loss: 30.727079391479492\n",
      "epoch: 0, iter: 94700, loss: 30.567398071289062\n",
      "epoch: 0, iter: 94800, loss: 31.104768753051758\n",
      "epoch: 0, iter: 94900, loss: 30.617074966430664\n",
      "epoch: 0, iter: 95000, loss: 30.56743812561035\n",
      "epoch: 0, iter: 95100, loss: 30.799884796142578\n",
      "epoch: 0, iter: 95200, loss: 30.337610244750977\n",
      "epoch: 0, iter: 95300, loss: 30.580066680908203\n",
      "epoch: 0, iter: 95400, loss: 30.963781356811523\n",
      "epoch: 0, iter: 95500, loss: 30.64681625366211\n",
      "epoch: 0, iter: 95600, loss: 31.4830379486084\n",
      "epoch: 0, iter: 95700, loss: 31.06965446472168\n",
      "epoch: 0, iter: 95800, loss: 30.807870864868164\n",
      "epoch: 0, iter: 95900, loss: 31.08989715576172\n",
      "epoch: 0, iter: 96000, loss: 30.126066207885742\n",
      "epoch: 0, iter: 96100, loss: 30.287994384765625\n",
      "epoch: 0, iter: 96200, loss: 30.598657608032227\n",
      "epoch: 0, iter: 96300, loss: 31.247819900512695\n",
      "epoch: 0, iter: 96400, loss: 30.846649169921875\n",
      "epoch: 0, iter: 96500, loss: 30.76819610595703\n",
      "epoch: 0, iter: 96600, loss: 30.712188720703125\n",
      "epoch: 0, iter: 96700, loss: 30.764808654785156\n",
      "epoch: 0, iter: 96800, loss: 30.897815704345703\n",
      "epoch: 0, iter: 96900, loss: 30.864992141723633\n",
      "epoch: 0, iter: 97000, loss: 31.13882064819336\n",
      "epoch: 0, iter: 97100, loss: 30.896085739135742\n",
      "epoch: 0, iter: 97200, loss: 30.81494140625\n",
      "epoch: 0, iter: 97300, loss: 30.723651885986328\n",
      "epoch: 0, iter: 97400, loss: 30.82052993774414\n",
      "epoch: 0, iter: 97500, loss: 30.955944061279297\n",
      "epoch: 0, iter: 97600, loss: 31.337432861328125\n",
      "epoch: 0, iter: 97700, loss: 30.778579711914062\n",
      "epoch: 0, iter: 97800, loss: 30.725671768188477\n",
      "epoch: 0, iter: 97900, loss: 30.82990837097168\n",
      "epoch: 0, iter: 98000, loss: 30.69306182861328\n",
      "epoch: 0, iter: 98100, loss: 31.389711380004883\n",
      "epoch: 0, iter: 98200, loss: 29.90970230102539\n",
      "epoch: 0, iter: 98300, loss: 30.927400588989258\n",
      "epoch: 0, iter: 98400, loss: 30.55514907836914\n",
      "epoch: 0, iter: 98500, loss: 31.17979621887207\n",
      "epoch: 0, iter: 98600, loss: 30.55588722229004\n",
      "epoch: 0, iter: 98700, loss: 30.929475784301758\n",
      "epoch: 0, iter: 98800, loss: 30.483463287353516\n",
      "epoch: 0, iter: 98900, loss: 30.797460556030273\n",
      "epoch: 0, iter: 99000, loss: 31.254650115966797\n",
      "epoch: 0, iter: 99100, loss: 30.689170837402344\n",
      "epoch: 0, iter: 99200, loss: 30.732757568359375\n",
      "epoch: 0, iter: 99300, loss: 30.43136215209961\n",
      "epoch: 0, iter: 99400, loss: 30.85513687133789\n",
      "epoch: 0, iter: 99500, loss: 30.309202194213867\n",
      "epoch: 0, iter: 99600, loss: 30.580289840698242\n",
      "epoch: 0, iter: 99700, loss: 31.006162643432617\n",
      "epoch: 0, iter: 99800, loss: 30.49274253845215\n",
      "epoch: 0, iter: 99900, loss: 30.239696502685547\n",
      "epoch: 0, iter: 100000, loss: 30.375003814697266\n",
      "epoch: 0, iter: 100100, loss: 30.92219352722168\n",
      "epoch: 0, iter: 100200, loss: 30.547624588012695\n",
      "epoch: 0, iter: 100300, loss: 30.554847717285156\n",
      "epoch: 0, iter: 100400, loss: 31.024307250976562\n",
      "epoch: 0, iter: 100500, loss: 31.283863067626953\n",
      "epoch: 0, iter: 100600, loss: 30.456933975219727\n",
      "epoch: 0, iter: 100700, loss: 30.80967903137207\n",
      "epoch: 0, iter: 100800, loss: 30.973037719726562\n",
      "epoch: 0, iter: 100900, loss: 31.213367462158203\n",
      "epoch: 0, iter: 101000, loss: 30.900239944458008\n",
      "epoch: 0, iter: 101100, loss: 30.723804473876953\n",
      "epoch: 0, iter: 101200, loss: 30.991994857788086\n",
      "epoch: 0, iter: 101300, loss: 30.289505004882812\n",
      "epoch: 0, iter: 101400, loss: 30.978687286376953\n",
      "epoch: 0, iter: 101500, loss: 31.144458770751953\n",
      "epoch: 0, iter: 101600, loss: 30.91904067993164\n",
      "epoch: 0, iter: 101700, loss: 30.61262321472168\n",
      "epoch: 0, iter: 101800, loss: 30.826539993286133\n",
      "epoch: 0, iter: 101900, loss: 30.457256317138672\n",
      "epoch: 0, iter: 102000, loss: 30.818912506103516\n",
      "epoch: 0, iter: 102100, loss: 30.80122184753418\n",
      "epoch: 0, iter: 102200, loss: 30.92974853515625\n",
      "epoch: 0, iter: 102300, loss: 31.081729888916016\n",
      "epoch: 0, iter: 102400, loss: 30.863895416259766\n",
      "epoch: 0, iter: 102500, loss: 30.10222625732422\n",
      "epoch: 0, iter: 102600, loss: 31.21503257751465\n",
      "epoch: 0, iter: 102700, loss: 30.906782150268555\n",
      "epoch: 0, iter: 102800, loss: 30.73101234436035\n",
      "epoch: 0, iter: 102900, loss: 30.172529220581055\n",
      "epoch: 0, iter: 103000, loss: 30.39205551147461\n",
      "epoch: 0, iter: 103100, loss: 30.72955894470215\n",
      "epoch: 0, iter: 103200, loss: 30.794689178466797\n",
      "epoch: 0, iter: 103300, loss: 30.53317642211914\n",
      "epoch: 0, iter: 103400, loss: 30.924497604370117\n",
      "epoch: 0, iter: 103500, loss: 30.256738662719727\n",
      "epoch: 0, iter: 103600, loss: 30.477338790893555\n",
      "epoch: 0, iter: 103700, loss: 30.660566329956055\n",
      "epoch: 0, iter: 103800, loss: 30.599773406982422\n",
      "epoch: 0, iter: 103900, loss: 31.163162231445312\n",
      "epoch: 0, iter: 104000, loss: 30.746313095092773\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, iter: 104100, loss: 30.34078598022461\n",
      "epoch: 0, iter: 104200, loss: 30.904800415039062\n",
      "epoch: 0, iter: 104300, loss: 31.234813690185547\n",
      "epoch: 0, iter: 104400, loss: 30.50078773498535\n",
      "epoch: 0, iter: 104500, loss: 30.261173248291016\n",
      "epoch: 0, iter: 104600, loss: 30.976444244384766\n",
      "epoch: 0, iter: 104700, loss: 30.89337730407715\n",
      "epoch: 0, iter: 104800, loss: 30.80858612060547\n",
      "epoch: 0, iter: 104900, loss: 31.038652420043945\n",
      "epoch: 0, iter: 105000, loss: 31.101478576660156\n",
      "epoch: 0, iter: 105100, loss: 30.45868682861328\n",
      "epoch: 0, iter: 105200, loss: 30.741971969604492\n",
      "epoch: 0, iter: 105300, loss: 30.977130889892578\n",
      "epoch: 0, iter: 105400, loss: 31.44770622253418\n",
      "epoch: 0, iter: 105500, loss: 30.89352035522461\n",
      "epoch: 0, iter: 105600, loss: 31.16472816467285\n",
      "epoch: 0, iter: 105700, loss: 30.47923469543457\n",
      "epoch: 0, iter: 105800, loss: 30.902729034423828\n",
      "epoch: 0, iter: 105900, loss: 30.82274627685547\n",
      "epoch: 0, iter: 106000, loss: 30.664066314697266\n",
      "epoch: 0, iter: 106100, loss: 30.950355529785156\n",
      "epoch: 0, iter: 106200, loss: 30.95834732055664\n",
      "epoch: 0, iter: 106300, loss: 30.953453063964844\n",
      "epoch: 0, iter: 106400, loss: 30.938037872314453\n",
      "epoch: 0, iter: 106500, loss: 30.253528594970703\n",
      "epoch: 0, iter: 106600, loss: 30.900829315185547\n",
      "epoch: 0, iter: 106700, loss: 30.997156143188477\n",
      "epoch: 0, iter: 106800, loss: 30.959163665771484\n",
      "epoch: 0, iter: 106900, loss: 30.25995635986328\n",
      "epoch: 0, iter: 107000, loss: 31.358966827392578\n",
      "epoch: 0, iter: 107100, loss: 31.050128936767578\n",
      "epoch: 0, iter: 107200, loss: 30.540958404541016\n",
      "epoch: 0, iter: 107300, loss: 30.457988739013672\n",
      "epoch: 0, iter: 107400, loss: 31.057571411132812\n",
      "epoch: 0, iter: 107500, loss: 30.48465919494629\n",
      "epoch: 0, iter: 107600, loss: 30.622617721557617\n",
      "epoch: 0, iter: 107700, loss: 30.28931427001953\n",
      "epoch: 0, iter: 107800, loss: 30.7711181640625\n",
      "epoch: 0, iter: 107900, loss: 31.036828994750977\n",
      "epoch: 0, iter: 108000, loss: 30.621479034423828\n",
      "epoch: 0, iter: 108100, loss: 31.096948623657227\n",
      "epoch: 0, iter: 108200, loss: 30.83790397644043\n",
      "epoch: 0, iter: 108300, loss: 30.5223388671875\n",
      "epoch: 0, iter: 108400, loss: 30.2062931060791\n",
      "epoch: 0, iter: 108500, loss: 30.55908203125\n",
      "epoch: 0, iter: 108600, loss: 30.945127487182617\n",
      "epoch: 0, iter: 108700, loss: 30.912288665771484\n",
      "epoch: 0, iter: 108800, loss: 30.614734649658203\n",
      "epoch: 0, iter: 108900, loss: 31.290775299072266\n",
      "epoch: 0, iter: 109000, loss: 30.47054672241211\n",
      "epoch: 0, iter: 109100, loss: 30.383161544799805\n",
      "epoch: 0, iter: 109200, loss: 31.516700744628906\n",
      "epoch: 0, iter: 109300, loss: 29.88556671142578\n",
      "epoch: 0, iter: 109400, loss: 30.2825927734375\n",
      "epoch: 0, iter: 109500, loss: 30.720993041992188\n",
      "epoch: 0, iter: 109600, loss: 30.596769332885742\n",
      "epoch: 0, iter: 109700, loss: 30.483686447143555\n",
      "epoch: 0, iter: 109800, loss: 30.259992599487305\n",
      "epoch: 0, iter: 109900, loss: 30.335065841674805\n",
      "epoch: 0, iter: 110000, loss: 30.88282012939453\n",
      "epoch: 0, iter: 110100, loss: 30.674474716186523\n",
      "epoch: 0, iter: 110200, loss: 30.788896560668945\n",
      "epoch: 0, iter: 110300, loss: 30.746295928955078\n",
      "epoch: 0, iter: 110400, loss: 30.936155319213867\n",
      "epoch: 0, iter: 110500, loss: 30.467388153076172\n",
      "epoch: 0, iter: 110600, loss: 31.09268569946289\n",
      "epoch: 0, iter: 110700, loss: 31.046510696411133\n",
      "epoch: 0, iter: 110800, loss: 30.208818435668945\n",
      "epoch: 0, iter: 110900, loss: 30.948806762695312\n",
      "epoch: 0, iter: 111000, loss: 31.15755271911621\n",
      "epoch: 0, iter: 111100, loss: 31.062522888183594\n",
      "epoch: 0, iter: 111200, loss: 30.890575408935547\n",
      "epoch: 0, iter: 111300, loss: 31.029285430908203\n",
      "epoch: 0, iter: 111400, loss: 30.865192413330078\n",
      "epoch: 0, iter: 111500, loss: 30.692184448242188\n",
      "epoch: 0, iter: 111600, loss: 30.910886764526367\n",
      "epoch: 0, iter: 111700, loss: 31.04434585571289\n",
      "epoch: 0, iter: 111800, loss: 30.779367446899414\n",
      "epoch: 0, iter: 111900, loss: 30.55717658996582\n",
      "epoch: 0, iter: 112000, loss: 31.110464096069336\n",
      "epoch: 0, iter: 112100, loss: 30.35770034790039\n",
      "epoch: 0, iter: 112200, loss: 30.552339553833008\n",
      "epoch: 0, iter: 112300, loss: 30.88503646850586\n",
      "epoch: 0, iter: 112400, loss: 31.204917907714844\n",
      "epoch: 0, iter: 112500, loss: 31.05364227294922\n",
      "epoch: 0, iter: 112600, loss: 30.180225372314453\n",
      "epoch: 0, iter: 112700, loss: 30.69591522216797\n",
      "epoch: 0, iter: 112800, loss: 30.85122299194336\n",
      "epoch: 0, iter: 112900, loss: 31.04861068725586\n",
      "epoch: 0, iter: 113000, loss: 30.970481872558594\n",
      "epoch: 0, iter: 113100, loss: 30.878299713134766\n",
      "epoch: 0, iter: 113200, loss: 30.53907585144043\n",
      "epoch: 0, iter: 113300, loss: 30.814659118652344\n",
      "epoch: 0, iter: 113400, loss: 30.61598014831543\n",
      "epoch: 0, iter: 113500, loss: 30.48956298828125\n",
      "epoch: 0, iter: 113600, loss: 30.771947860717773\n",
      "epoch: 0, iter: 113700, loss: 30.561992645263672\n",
      "epoch: 0, iter: 113800, loss: 30.6326904296875\n",
      "epoch: 0, iter: 113900, loss: 30.393102645874023\n",
      "epoch: 0, iter: 114000, loss: 30.484708786010742\n",
      "epoch: 0, iter: 114100, loss: 30.394893646240234\n",
      "epoch: 0, iter: 114200, loss: 30.907106399536133\n",
      "epoch: 0, iter: 114300, loss: 30.371328353881836\n",
      "epoch: 0, iter: 114400, loss: 30.40375518798828\n",
      "epoch: 0, iter: 114500, loss: 30.391937255859375\n",
      "epoch: 0, iter: 114600, loss: 30.752023696899414\n",
      "epoch: 0, iter: 114700, loss: 31.209815979003906\n",
      "epoch: 0, iter: 114800, loss: 30.837574005126953\n",
      "epoch: 0, iter: 114900, loss: 30.638473510742188\n",
      "epoch: 0, iter: 115000, loss: 30.73928451538086\n",
      "epoch: 0, iter: 115100, loss: 30.82617950439453\n",
      "epoch: 0, iter: 115200, loss: 30.983123779296875\n",
      "epoch: 0, iter: 115300, loss: 31.203813552856445\n",
      "epoch: 0, iter: 115400, loss: 30.756240844726562\n",
      "epoch: 0, iter: 115500, loss: 30.220211029052734\n",
      "epoch: 0, iter: 115600, loss: 30.639745712280273\n",
      "epoch: 0, iter: 115700, loss: 30.197038650512695\n",
      "epoch: 0, iter: 115800, loss: 30.903886795043945\n",
      "epoch: 0, iter: 115900, loss: 31.06612205505371\n",
      "epoch: 0, iter: 116000, loss: 30.792659759521484\n",
      "epoch: 0, iter: 116100, loss: 30.41764259338379\n",
      "epoch: 0, iter: 116200, loss: 30.90638542175293\n",
      "epoch: 0, iter: 116300, loss: 30.53609275817871\n",
      "epoch: 0, iter: 116400, loss: 30.669937133789062\n",
      "epoch: 0, iter: 116500, loss: 30.4545841217041\n",
      "epoch: 0, iter: 116600, loss: 30.501014709472656\n",
      "epoch: 0, iter: 116700, loss: 30.879850387573242\n",
      "epoch: 0, iter: 116800, loss: 30.933570861816406\n",
      "epoch: 0, iter: 116900, loss: 30.366348266601562\n",
      "epoch: 0, iter: 117000, loss: 30.605085372924805\n",
      "epoch: 0, iter: 117100, loss: 30.32795524597168\n",
      "epoch: 0, iter: 117200, loss: 30.773908615112305\n",
      "epoch: 0, iter: 117300, loss: 30.29454231262207\n",
      "epoch: 0, iter: 117400, loss: 30.40686798095703\n",
      "epoch: 0, iter: 117500, loss: 30.778337478637695\n",
      "epoch: 0, iter: 117600, loss: 30.563369750976562\n",
      "epoch: 0, iter: 117700, loss: 30.390085220336914\n",
      "epoch: 0, iter: 117800, loss: 30.576858520507812\n",
      "epoch: 0, iter: 117900, loss: 30.849607467651367\n",
      "epoch: 0, iter: 118000, loss: 31.218624114990234\n",
      "epoch: 0, iter: 118100, loss: 30.59288787841797\n",
      "epoch: 0, iter: 118200, loss: 30.863386154174805\n",
      "epoch: 0, iter: 118300, loss: 30.787599563598633\n",
      "epoch: 0, iter: 118400, loss: 30.883785247802734\n",
      "epoch: 0, iter: 118500, loss: 31.023422241210938\n",
      "epoch: 0, iter: 118600, loss: 31.01622772216797\n",
      "epoch: 0, iter: 118700, loss: 30.629697799682617\n",
      "epoch: 0, iter: 118800, loss: 29.853357315063477\n",
      "epoch: 0, iter: 118900, loss: 30.70974349975586\n",
      "epoch: 0, iter: 119000, loss: 30.870885848999023\n",
      "epoch: 0, iter: 119100, loss: 30.394126892089844\n",
      "epoch: 0, iter: 119200, loss: 30.918296813964844\n",
      "epoch: 0, iter: 119300, loss: 31.084056854248047\n",
      "epoch: 0, iter: 119400, loss: 30.584741592407227\n",
      "epoch: 0, iter: 119500, loss: 30.252042770385742\n",
      "epoch: 1, iter: 0, loss: 31.01276969909668\n",
      "epoch: 1, iter: 100, loss: 30.721696853637695\n",
      "epoch: 1, iter: 200, loss: 30.616695404052734\n",
      "epoch: 1, iter: 300, loss: 30.55349349975586\n",
      "epoch: 1, iter: 400, loss: 30.96331787109375\n",
      "epoch: 1, iter: 500, loss: 30.412263870239258\n",
      "epoch: 1, iter: 600, loss: 30.775264739990234\n",
      "epoch: 1, iter: 700, loss: 30.041627883911133\n",
      "epoch: 1, iter: 800, loss: 30.483760833740234\n",
      "epoch: 1, iter: 900, loss: 30.386850357055664\n",
      "epoch: 1, iter: 1000, loss: 30.612600326538086\n",
      "epoch: 1, iter: 1100, loss: 31.286972045898438\n",
      "epoch: 1, iter: 1200, loss: 30.643640518188477\n",
      "epoch: 1, iter: 1300, loss: 30.64628791809082\n",
      "epoch: 1, iter: 1400, loss: 30.40475082397461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, iter: 1500, loss: 31.255069732666016\n",
      "epoch: 1, iter: 1600, loss: 30.734466552734375\n",
      "epoch: 1, iter: 1700, loss: 30.547897338867188\n",
      "epoch: 1, iter: 1800, loss: 30.663860321044922\n",
      "epoch: 1, iter: 1900, loss: 30.66433334350586\n",
      "epoch: 1, iter: 2000, loss: 30.804462432861328\n",
      "epoch: 1, iter: 2100, loss: 30.185583114624023\n",
      "epoch: 1, iter: 2200, loss: 30.620018005371094\n",
      "epoch: 1, iter: 2300, loss: 31.070510864257812\n",
      "epoch: 1, iter: 2400, loss: 30.151710510253906\n",
      "epoch: 1, iter: 2500, loss: 30.3049259185791\n",
      "epoch: 1, iter: 2600, loss: 30.486413955688477\n",
      "epoch: 1, iter: 2700, loss: 30.44532012939453\n",
      "epoch: 1, iter: 2800, loss: 30.69796371459961\n",
      "epoch: 1, iter: 2900, loss: 30.20358657836914\n",
      "epoch: 1, iter: 3000, loss: 30.52279281616211\n",
      "epoch: 1, iter: 3100, loss: 30.76050567626953\n",
      "epoch: 1, iter: 3200, loss: 30.07227325439453\n",
      "epoch: 1, iter: 3300, loss: 30.465713500976562\n",
      "epoch: 1, iter: 3400, loss: 30.810346603393555\n",
      "epoch: 1, iter: 3500, loss: 30.72740364074707\n",
      "epoch: 1, iter: 3600, loss: 30.805564880371094\n",
      "epoch: 1, iter: 3700, loss: 30.544849395751953\n",
      "epoch: 1, iter: 3800, loss: 30.966154098510742\n",
      "epoch: 1, iter: 3900, loss: 30.63279151916504\n",
      "epoch: 1, iter: 4000, loss: 30.566852569580078\n",
      "epoch: 1, iter: 4100, loss: 30.818862915039062\n",
      "epoch: 1, iter: 4200, loss: 30.609878540039062\n",
      "epoch: 1, iter: 4300, loss: 30.767616271972656\n",
      "epoch: 1, iter: 4400, loss: 30.52621078491211\n",
      "epoch: 1, iter: 4500, loss: 30.922657012939453\n",
      "epoch: 1, iter: 4600, loss: 30.687192916870117\n",
      "epoch: 1, iter: 4700, loss: 30.681140899658203\n",
      "epoch: 1, iter: 4800, loss: 30.589099884033203\n",
      "epoch: 1, iter: 4900, loss: 31.065645217895508\n",
      "epoch: 1, iter: 5000, loss: 31.057044982910156\n",
      "epoch: 1, iter: 5100, loss: 30.959686279296875\n",
      "epoch: 1, iter: 5200, loss: 30.399744033813477\n",
      "epoch: 1, iter: 5300, loss: 30.739540100097656\n",
      "epoch: 1, iter: 5400, loss: 30.414064407348633\n",
      "epoch: 1, iter: 5500, loss: 30.836271286010742\n",
      "epoch: 1, iter: 5600, loss: 30.699440002441406\n",
      "epoch: 1, iter: 5700, loss: 30.656208038330078\n",
      "epoch: 1, iter: 5800, loss: 31.098186492919922\n",
      "epoch: 1, iter: 5900, loss: 30.41501235961914\n",
      "epoch: 1, iter: 6000, loss: 30.718570709228516\n",
      "epoch: 1, iter: 6100, loss: 30.328922271728516\n",
      "epoch: 1, iter: 6200, loss: 30.896909713745117\n",
      "epoch: 1, iter: 6300, loss: 30.81861686706543\n",
      "epoch: 1, iter: 6400, loss: 30.358890533447266\n",
      "epoch: 1, iter: 6500, loss: 30.318933486938477\n",
      "epoch: 1, iter: 6600, loss: 30.52031707763672\n",
      "epoch: 1, iter: 6700, loss: 30.47077178955078\n",
      "epoch: 1, iter: 6800, loss: 30.573997497558594\n",
      "epoch: 1, iter: 6900, loss: 30.563003540039062\n",
      "epoch: 1, iter: 7000, loss: 30.401065826416016\n",
      "epoch: 1, iter: 7100, loss: 31.160839080810547\n",
      "epoch: 1, iter: 7200, loss: 30.675579071044922\n",
      "epoch: 1, iter: 7300, loss: 30.718063354492188\n",
      "epoch: 1, iter: 7400, loss: 30.867584228515625\n",
      "epoch: 1, iter: 7500, loss: 30.526823043823242\n",
      "epoch: 1, iter: 7600, loss: 30.681299209594727\n",
      "epoch: 1, iter: 7700, loss: 30.538373947143555\n",
      "epoch: 1, iter: 7800, loss: 30.549097061157227\n",
      "epoch: 1, iter: 7900, loss: 30.070707321166992\n",
      "epoch: 1, iter: 8000, loss: 30.75438690185547\n",
      "epoch: 1, iter: 8100, loss: 30.277875900268555\n",
      "epoch: 1, iter: 8200, loss: 30.24178123474121\n",
      "epoch: 1, iter: 8300, loss: 30.940832138061523\n",
      "epoch: 1, iter: 8400, loss: 30.588787078857422\n",
      "epoch: 1, iter: 8500, loss: 30.363229751586914\n",
      "epoch: 1, iter: 8600, loss: 30.52595329284668\n",
      "epoch: 1, iter: 8700, loss: 29.958803176879883\n",
      "epoch: 1, iter: 8800, loss: 30.707670211791992\n",
      "epoch: 1, iter: 8900, loss: 30.300214767456055\n",
      "epoch: 1, iter: 9000, loss: 31.033599853515625\n",
      "epoch: 1, iter: 9100, loss: 30.544273376464844\n",
      "epoch: 1, iter: 9200, loss: 30.501401901245117\n",
      "epoch: 1, iter: 9300, loss: 30.225351333618164\n",
      "epoch: 1, iter: 9400, loss: 30.840003967285156\n",
      "epoch: 1, iter: 9500, loss: 30.539213180541992\n",
      "epoch: 1, iter: 9600, loss: 30.219337463378906\n",
      "epoch: 1, iter: 9700, loss: 30.55360221862793\n",
      "epoch: 1, iter: 9800, loss: 30.066797256469727\n",
      "epoch: 1, iter: 9900, loss: 30.76303482055664\n",
      "epoch: 1, iter: 10000, loss: 30.93598747253418\n",
      "epoch: 1, iter: 10100, loss: 31.11339569091797\n",
      "epoch: 1, iter: 10200, loss: 30.519439697265625\n",
      "epoch: 1, iter: 10300, loss: 30.153404235839844\n",
      "epoch: 1, iter: 10400, loss: 30.737281799316406\n",
      "epoch: 1, iter: 10500, loss: 30.462562561035156\n",
      "epoch: 1, iter: 10600, loss: 30.246257781982422\n",
      "epoch: 1, iter: 10700, loss: 30.910884857177734\n",
      "epoch: 1, iter: 10800, loss: 31.1839599609375\n",
      "epoch: 1, iter: 10900, loss: 30.146549224853516\n",
      "epoch: 1, iter: 11000, loss: 30.13471221923828\n",
      "epoch: 1, iter: 11100, loss: 30.981948852539062\n",
      "epoch: 1, iter: 11200, loss: 30.731548309326172\n",
      "epoch: 1, iter: 11300, loss: 30.821651458740234\n",
      "epoch: 1, iter: 11400, loss: 30.084142684936523\n",
      "epoch: 1, iter: 11500, loss: 30.34653091430664\n",
      "epoch: 1, iter: 11600, loss: 30.719715118408203\n",
      "epoch: 1, iter: 11700, loss: 30.932357788085938\n",
      "epoch: 1, iter: 11800, loss: 30.504045486450195\n",
      "epoch: 1, iter: 11900, loss: 30.557273864746094\n",
      "epoch: 1, iter: 12000, loss: 30.384511947631836\n",
      "epoch: 1, iter: 12100, loss: 30.15725326538086\n",
      "epoch: 1, iter: 12200, loss: 30.36155128479004\n",
      "epoch: 1, iter: 12300, loss: 30.466588973999023\n",
      "epoch: 1, iter: 12400, loss: 30.594491958618164\n",
      "epoch: 1, iter: 12500, loss: 30.369529724121094\n",
      "epoch: 1, iter: 12600, loss: 30.338727951049805\n",
      "epoch: 1, iter: 12700, loss: 30.462234497070312\n",
      "epoch: 1, iter: 12800, loss: 30.4429931640625\n",
      "epoch: 1, iter: 12900, loss: 30.979660034179688\n",
      "epoch: 1, iter: 13000, loss: 30.417659759521484\n",
      "epoch: 1, iter: 13100, loss: 30.46562385559082\n",
      "epoch: 1, iter: 13200, loss: 30.530244827270508\n",
      "epoch: 1, iter: 13300, loss: 30.503040313720703\n",
      "epoch: 1, iter: 13400, loss: 30.285505294799805\n",
      "epoch: 1, iter: 13500, loss: 30.748628616333008\n",
      "epoch: 1, iter: 13600, loss: 30.806291580200195\n",
      "epoch: 1, iter: 13700, loss: 30.712587356567383\n",
      "epoch: 1, iter: 13800, loss: 30.639007568359375\n",
      "epoch: 1, iter: 13900, loss: 30.488052368164062\n",
      "epoch: 1, iter: 14000, loss: 30.37378692626953\n",
      "epoch: 1, iter: 14100, loss: 30.470558166503906\n",
      "epoch: 1, iter: 14200, loss: 30.676393508911133\n",
      "epoch: 1, iter: 14300, loss: 30.954133987426758\n",
      "epoch: 1, iter: 14400, loss: 30.436607360839844\n",
      "epoch: 1, iter: 14500, loss: 30.622297286987305\n",
      "epoch: 1, iter: 14600, loss: 30.81203269958496\n",
      "epoch: 1, iter: 14700, loss: 30.91973114013672\n",
      "epoch: 1, iter: 14800, loss: 30.618778228759766\n",
      "epoch: 1, iter: 14900, loss: 30.384920120239258\n",
      "epoch: 1, iter: 15000, loss: 30.819976806640625\n",
      "epoch: 1, iter: 15100, loss: 30.790565490722656\n",
      "epoch: 1, iter: 15200, loss: 30.622676849365234\n",
      "epoch: 1, iter: 15300, loss: 30.872161865234375\n",
      "epoch: 1, iter: 15400, loss: 30.495037078857422\n",
      "epoch: 1, iter: 15500, loss: 30.705968856811523\n",
      "epoch: 1, iter: 15600, loss: 30.559743881225586\n",
      "epoch: 1, iter: 15700, loss: 30.909503936767578\n",
      "epoch: 1, iter: 15800, loss: 30.756542205810547\n",
      "epoch: 1, iter: 15900, loss: 30.57802391052246\n",
      "epoch: 1, iter: 16000, loss: 30.515737533569336\n",
      "epoch: 1, iter: 16100, loss: 30.14340591430664\n",
      "epoch: 1, iter: 16200, loss: 30.421934127807617\n",
      "epoch: 1, iter: 16300, loss: 30.844058990478516\n",
      "epoch: 1, iter: 16400, loss: 30.477346420288086\n",
      "epoch: 1, iter: 16500, loss: 30.806228637695312\n",
      "epoch: 1, iter: 16600, loss: 30.772666931152344\n",
      "epoch: 1, iter: 16700, loss: 30.98383140563965\n",
      "epoch: 1, iter: 16800, loss: 29.954425811767578\n",
      "epoch: 1, iter: 16900, loss: 30.888673782348633\n",
      "epoch: 1, iter: 17000, loss: 30.626258850097656\n",
      "epoch: 1, iter: 17100, loss: 30.643936157226562\n",
      "epoch: 1, iter: 17200, loss: 30.150684356689453\n",
      "epoch: 1, iter: 17300, loss: 30.060070037841797\n",
      "epoch: 1, iter: 17400, loss: 30.754133224487305\n",
      "epoch: 1, iter: 17500, loss: 30.26877212524414\n",
      "epoch: 1, iter: 17600, loss: 30.424392700195312\n",
      "epoch: 1, iter: 17700, loss: 31.215723037719727\n",
      "epoch: 1, iter: 17800, loss: 30.54749298095703\n",
      "epoch: 1, iter: 17900, loss: 30.64118003845215\n",
      "epoch: 1, iter: 18000, loss: 30.803585052490234\n",
      "epoch: 1, iter: 18100, loss: 30.393749237060547\n",
      "epoch: 1, iter: 18200, loss: 30.40350914001465\n",
      "epoch: 1, iter: 18300, loss: 30.76776885986328\n",
      "epoch: 1, iter: 18400, loss: 31.026235580444336\n",
      "epoch: 1, iter: 18500, loss: 31.078702926635742\n",
      "epoch: 1, iter: 18600, loss: 30.8095760345459\n",
      "epoch: 1, iter: 18700, loss: 31.039751052856445\n",
      "epoch: 1, iter: 18800, loss: 30.745861053466797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, iter: 18900, loss: 30.538433074951172\n",
      "epoch: 1, iter: 19000, loss: 30.877334594726562\n",
      "epoch: 1, iter: 19100, loss: 31.18408966064453\n",
      "epoch: 1, iter: 19200, loss: 29.835643768310547\n",
      "epoch: 1, iter: 19300, loss: 30.767580032348633\n",
      "epoch: 1, iter: 19400, loss: 30.22886848449707\n",
      "epoch: 1, iter: 19500, loss: 30.625030517578125\n",
      "epoch: 1, iter: 19600, loss: 30.608631134033203\n",
      "epoch: 1, iter: 19700, loss: 29.807720184326172\n",
      "epoch: 1, iter: 19800, loss: 30.422557830810547\n",
      "epoch: 1, iter: 19900, loss: 30.826189041137695\n",
      "epoch: 1, iter: 20000, loss: 30.36678123474121\n",
      "epoch: 1, iter: 20100, loss: 30.468250274658203\n",
      "epoch: 1, iter: 20200, loss: 31.115556716918945\n",
      "epoch: 1, iter: 20300, loss: 31.02297019958496\n",
      "epoch: 1, iter: 20400, loss: 30.46123695373535\n",
      "epoch: 1, iter: 20500, loss: 30.97983741760254\n",
      "epoch: 1, iter: 20600, loss: 30.242549896240234\n",
      "epoch: 1, iter: 20700, loss: 30.25586700439453\n",
      "epoch: 1, iter: 20800, loss: 30.98520278930664\n",
      "epoch: 1, iter: 20900, loss: 30.591732025146484\n",
      "epoch: 1, iter: 21000, loss: 30.393606185913086\n",
      "epoch: 1, iter: 21100, loss: 30.226032257080078\n",
      "epoch: 1, iter: 21200, loss: 30.487964630126953\n",
      "epoch: 1, iter: 21300, loss: 30.64012908935547\n",
      "epoch: 1, iter: 21400, loss: 30.829214096069336\n",
      "epoch: 1, iter: 21500, loss: 30.71271514892578\n",
      "epoch: 1, iter: 21600, loss: 30.532405853271484\n",
      "epoch: 1, iter: 21700, loss: 30.156599044799805\n",
      "epoch: 1, iter: 21800, loss: 30.625423431396484\n",
      "epoch: 1, iter: 21900, loss: 30.827865600585938\n",
      "epoch: 1, iter: 22000, loss: 30.496633529663086\n",
      "epoch: 1, iter: 22100, loss: 30.42180824279785\n",
      "epoch: 1, iter: 22200, loss: 30.620983123779297\n",
      "epoch: 1, iter: 22300, loss: 30.518434524536133\n",
      "epoch: 1, iter: 22400, loss: 30.01074981689453\n",
      "epoch: 1, iter: 22500, loss: 30.375228881835938\n",
      "epoch: 1, iter: 22600, loss: 30.456298828125\n",
      "epoch: 1, iter: 22700, loss: 30.95376968383789\n",
      "epoch: 1, iter: 22800, loss: 30.43727684020996\n",
      "epoch: 1, iter: 22900, loss: 29.722068786621094\n",
      "epoch: 1, iter: 23000, loss: 30.323183059692383\n",
      "epoch: 1, iter: 23100, loss: 30.874107360839844\n",
      "epoch: 1, iter: 23200, loss: 30.887678146362305\n",
      "epoch: 1, iter: 23300, loss: 30.786462783813477\n",
      "epoch: 1, iter: 23400, loss: 30.18665885925293\n",
      "epoch: 1, iter: 23500, loss: 30.557418823242188\n",
      "epoch: 1, iter: 23600, loss: 30.682506561279297\n",
      "epoch: 1, iter: 23700, loss: 30.615535736083984\n",
      "epoch: 1, iter: 23800, loss: 30.65541648864746\n",
      "epoch: 1, iter: 23900, loss: 30.60395622253418\n",
      "epoch: 1, iter: 24000, loss: 30.384845733642578\n",
      "epoch: 1, iter: 24100, loss: 30.366594314575195\n",
      "epoch: 1, iter: 24200, loss: 30.03936767578125\n",
      "epoch: 1, iter: 24300, loss: 31.050180435180664\n",
      "epoch: 1, iter: 24400, loss: 30.25106430053711\n",
      "epoch: 1, iter: 24500, loss: 30.580608367919922\n",
      "epoch: 1, iter: 24600, loss: 29.80062484741211\n",
      "epoch: 1, iter: 24700, loss: 30.679269790649414\n",
      "epoch: 1, iter: 24800, loss: 30.65584945678711\n",
      "epoch: 1, iter: 24900, loss: 30.07927131652832\n",
      "epoch: 1, iter: 25000, loss: 30.516082763671875\n",
      "epoch: 1, iter: 25100, loss: 30.281597137451172\n",
      "epoch: 1, iter: 25200, loss: 30.274337768554688\n",
      "epoch: 1, iter: 25300, loss: 30.368812561035156\n",
      "epoch: 1, iter: 25400, loss: 30.780012130737305\n",
      "epoch: 1, iter: 25500, loss: 30.546302795410156\n",
      "epoch: 1, iter: 25600, loss: 30.819093704223633\n",
      "epoch: 1, iter: 25700, loss: 30.080219268798828\n",
      "epoch: 1, iter: 25800, loss: 30.65166473388672\n",
      "epoch: 1, iter: 25900, loss: 30.530620574951172\n",
      "epoch: 1, iter: 26000, loss: 30.34059715270996\n",
      "epoch: 1, iter: 26100, loss: 30.791574478149414\n",
      "epoch: 1, iter: 26200, loss: 30.792217254638672\n",
      "epoch: 1, iter: 26300, loss: 30.49408721923828\n",
      "epoch: 1, iter: 26400, loss: 30.66201400756836\n",
      "epoch: 1, iter: 26500, loss: 30.671049118041992\n",
      "epoch: 1, iter: 26600, loss: 30.55076026916504\n",
      "epoch: 1, iter: 26700, loss: 31.012664794921875\n",
      "epoch: 1, iter: 26800, loss: 30.752685546875\n",
      "epoch: 1, iter: 26900, loss: 30.95185661315918\n",
      "epoch: 1, iter: 27000, loss: 30.93860626220703\n",
      "epoch: 1, iter: 27100, loss: 29.82770538330078\n",
      "epoch: 1, iter: 27200, loss: 30.171117782592773\n",
      "epoch: 1, iter: 27300, loss: 30.686750411987305\n",
      "epoch: 1, iter: 27400, loss: 30.927814483642578\n",
      "epoch: 1, iter: 27500, loss: 30.415470123291016\n",
      "epoch: 1, iter: 27600, loss: 30.65414047241211\n",
      "epoch: 1, iter: 27700, loss: 30.317604064941406\n",
      "epoch: 1, iter: 27800, loss: 30.899778366088867\n",
      "epoch: 1, iter: 27900, loss: 30.233333587646484\n",
      "epoch: 1, iter: 28000, loss: 31.143465042114258\n",
      "epoch: 1, iter: 28100, loss: 30.75992202758789\n",
      "epoch: 1, iter: 28200, loss: 30.56341552734375\n",
      "epoch: 1, iter: 28300, loss: 29.974578857421875\n",
      "epoch: 1, iter: 28400, loss: 30.665849685668945\n",
      "epoch: 1, iter: 28500, loss: 30.524946212768555\n",
      "epoch: 1, iter: 28600, loss: 30.25557518005371\n",
      "epoch: 1, iter: 28700, loss: 30.311275482177734\n",
      "epoch: 1, iter: 28800, loss: 30.193252563476562\n",
      "epoch: 1, iter: 28900, loss: 30.71644401550293\n",
      "epoch: 1, iter: 29000, loss: 30.957210540771484\n",
      "epoch: 1, iter: 29100, loss: 30.407411575317383\n",
      "epoch: 1, iter: 29200, loss: 30.928735733032227\n",
      "epoch: 1, iter: 29300, loss: 30.561599731445312\n",
      "epoch: 1, iter: 29400, loss: 30.72217559814453\n",
      "epoch: 1, iter: 29500, loss: 30.1928653717041\n",
      "epoch: 1, iter: 29600, loss: 30.285245895385742\n",
      "epoch: 1, iter: 29700, loss: 30.45124626159668\n",
      "epoch: 1, iter: 29800, loss: 30.49966049194336\n",
      "epoch: 1, iter: 29900, loss: 30.76898193359375\n",
      "epoch: 1, iter: 30000, loss: 30.28360366821289\n",
      "epoch: 1, iter: 30100, loss: 30.21377944946289\n",
      "epoch: 1, iter: 30200, loss: 30.34101104736328\n",
      "epoch: 1, iter: 30300, loss: 30.452131271362305\n",
      "epoch: 1, iter: 30400, loss: 30.48491096496582\n",
      "epoch: 1, iter: 30500, loss: 30.075178146362305\n",
      "epoch: 1, iter: 30600, loss: 30.958824157714844\n",
      "epoch: 1, iter: 30700, loss: 30.394229888916016\n",
      "epoch: 1, iter: 30800, loss: 29.77785301208496\n",
      "epoch: 1, iter: 30900, loss: 30.6461181640625\n",
      "epoch: 1, iter: 31000, loss: 30.337509155273438\n",
      "epoch: 1, iter: 31100, loss: 30.326805114746094\n",
      "epoch: 1, iter: 31200, loss: 30.279544830322266\n",
      "epoch: 1, iter: 31300, loss: 30.394912719726562\n",
      "epoch: 1, iter: 31400, loss: 30.201269149780273\n",
      "epoch: 1, iter: 31500, loss: 30.602209091186523\n",
      "epoch: 1, iter: 31600, loss: 30.54585838317871\n",
      "epoch: 1, iter: 31700, loss: 30.015321731567383\n",
      "epoch: 1, iter: 31800, loss: 31.25337028503418\n",
      "epoch: 1, iter: 31900, loss: 30.539215087890625\n",
      "epoch: 1, iter: 32000, loss: 30.800504684448242\n",
      "epoch: 1, iter: 32100, loss: 30.648059844970703\n",
      "epoch: 1, iter: 32200, loss: 30.426729202270508\n",
      "epoch: 1, iter: 32300, loss: 30.54332733154297\n",
      "epoch: 1, iter: 32400, loss: 30.175853729248047\n",
      "epoch: 1, iter: 32500, loss: 29.8902587890625\n",
      "epoch: 1, iter: 32600, loss: 30.693756103515625\n",
      "epoch: 1, iter: 32700, loss: 30.75664710998535\n",
      "epoch: 1, iter: 32800, loss: 30.1783504486084\n",
      "epoch: 1, iter: 32900, loss: 30.463584899902344\n",
      "epoch: 1, iter: 33000, loss: 30.576292037963867\n",
      "epoch: 1, iter: 33100, loss: 30.7469482421875\n",
      "epoch: 1, iter: 33200, loss: 30.82852554321289\n",
      "epoch: 1, iter: 33300, loss: 30.676271438598633\n",
      "epoch: 1, iter: 33400, loss: 30.442739486694336\n",
      "epoch: 1, iter: 33500, loss: 30.436206817626953\n",
      "epoch: 1, iter: 33600, loss: 30.329998016357422\n",
      "epoch: 1, iter: 33700, loss: 30.712467193603516\n",
      "epoch: 1, iter: 33800, loss: 30.468353271484375\n",
      "epoch: 1, iter: 33900, loss: 30.994365692138672\n",
      "epoch: 1, iter: 34000, loss: 30.285167694091797\n",
      "epoch: 1, iter: 34100, loss: 30.62109375\n",
      "epoch: 1, iter: 34200, loss: 31.192956924438477\n",
      "epoch: 1, iter: 34300, loss: 30.743764877319336\n",
      "epoch: 1, iter: 34400, loss: 30.613204956054688\n",
      "epoch: 1, iter: 34500, loss: 30.233320236206055\n",
      "epoch: 1, iter: 34600, loss: 30.666433334350586\n",
      "epoch: 1, iter: 34700, loss: 30.557226181030273\n",
      "epoch: 1, iter: 34800, loss: 30.337200164794922\n",
      "epoch: 1, iter: 34900, loss: 31.006103515625\n",
      "epoch: 1, iter: 35000, loss: 30.440834045410156\n",
      "epoch: 1, iter: 35100, loss: 30.53887367248535\n",
      "epoch: 1, iter: 35200, loss: 30.90546417236328\n",
      "epoch: 1, iter: 35300, loss: 30.688182830810547\n",
      "epoch: 1, iter: 35400, loss: 30.91659927368164\n",
      "epoch: 1, iter: 35500, loss: 30.48771858215332\n",
      "epoch: 1, iter: 35600, loss: 30.521644592285156\n",
      "epoch: 1, iter: 35700, loss: 30.57048988342285\n",
      "epoch: 1, iter: 35800, loss: 30.571399688720703\n",
      "epoch: 1, iter: 35900, loss: 30.507274627685547\n",
      "epoch: 1, iter: 36000, loss: 30.361370086669922\n",
      "epoch: 1, iter: 36100, loss: 30.439075469970703\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, iter: 36200, loss: 30.946800231933594\n",
      "epoch: 1, iter: 36300, loss: 30.634357452392578\n",
      "epoch: 1, iter: 36400, loss: 30.616987228393555\n",
      "epoch: 1, iter: 36500, loss: 30.4654598236084\n",
      "epoch: 1, iter: 36600, loss: 30.1270809173584\n",
      "epoch: 1, iter: 36700, loss: 30.501789093017578\n",
      "epoch: 1, iter: 36800, loss: 29.987722396850586\n",
      "epoch: 1, iter: 36900, loss: 30.554763793945312\n",
      "epoch: 1, iter: 37000, loss: 30.672256469726562\n",
      "epoch: 1, iter: 37100, loss: 30.579334259033203\n",
      "epoch: 1, iter: 37200, loss: 30.264326095581055\n",
      "epoch: 1, iter: 37300, loss: 30.972774505615234\n",
      "epoch: 1, iter: 37400, loss: 30.168289184570312\n",
      "epoch: 1, iter: 37500, loss: 30.339183807373047\n",
      "epoch: 1, iter: 37600, loss: 30.45969581604004\n",
      "epoch: 1, iter: 37700, loss: 30.209287643432617\n",
      "epoch: 1, iter: 37800, loss: 30.717679977416992\n",
      "epoch: 1, iter: 37900, loss: 30.499910354614258\n",
      "epoch: 1, iter: 38000, loss: 29.963001251220703\n",
      "epoch: 1, iter: 38100, loss: 29.734071731567383\n",
      "epoch: 1, iter: 38200, loss: 30.455270767211914\n",
      "epoch: 1, iter: 38300, loss: 30.483718872070312\n",
      "epoch: 1, iter: 38400, loss: 30.57241439819336\n",
      "epoch: 1, iter: 38500, loss: 31.07808494567871\n",
      "epoch: 1, iter: 38600, loss: 30.789724349975586\n",
      "epoch: 1, iter: 38700, loss: 30.501873016357422\n",
      "epoch: 1, iter: 38800, loss: 30.760709762573242\n",
      "epoch: 1, iter: 38900, loss: 30.450458526611328\n",
      "epoch: 1, iter: 39000, loss: 30.566537857055664\n",
      "epoch: 1, iter: 39100, loss: 30.95343017578125\n",
      "epoch: 1, iter: 39200, loss: 30.505069732666016\n",
      "epoch: 1, iter: 39300, loss: 30.575288772583008\n",
      "epoch: 1, iter: 39400, loss: 30.552820205688477\n",
      "epoch: 1, iter: 39500, loss: 30.683195114135742\n",
      "epoch: 1, iter: 39600, loss: 30.35895347595215\n",
      "epoch: 1, iter: 39700, loss: 30.410781860351562\n",
      "epoch: 1, iter: 39800, loss: 30.620220184326172\n",
      "epoch: 1, iter: 39900, loss: 30.418567657470703\n",
      "epoch: 1, iter: 40000, loss: 30.252532958984375\n",
      "epoch: 1, iter: 40100, loss: 30.933605194091797\n",
      "epoch: 1, iter: 40200, loss: 30.442434310913086\n",
      "epoch: 1, iter: 40300, loss: 30.139636993408203\n",
      "epoch: 1, iter: 40400, loss: 30.383899688720703\n",
      "epoch: 1, iter: 40500, loss: 30.362642288208008\n",
      "epoch: 1, iter: 40600, loss: 30.644262313842773\n",
      "epoch: 1, iter: 40700, loss: 30.312192916870117\n",
      "epoch: 1, iter: 40800, loss: 30.47162437438965\n",
      "epoch: 1, iter: 40900, loss: 30.63578224182129\n",
      "epoch: 1, iter: 41000, loss: 30.15975570678711\n",
      "epoch: 1, iter: 41100, loss: 30.2078914642334\n",
      "epoch: 1, iter: 41200, loss: 30.209396362304688\n",
      "epoch: 1, iter: 41300, loss: 30.38637351989746\n",
      "epoch: 1, iter: 41400, loss: 31.09282112121582\n",
      "epoch: 1, iter: 41500, loss: 30.51858901977539\n",
      "epoch: 1, iter: 41600, loss: 30.597368240356445\n",
      "epoch: 1, iter: 41700, loss: 30.411863327026367\n",
      "epoch: 1, iter: 41800, loss: 30.91633415222168\n",
      "epoch: 1, iter: 41900, loss: 30.248369216918945\n",
      "epoch: 1, iter: 42000, loss: 30.550212860107422\n",
      "epoch: 1, iter: 42100, loss: 30.562793731689453\n",
      "epoch: 1, iter: 42200, loss: 30.178998947143555\n",
      "epoch: 1, iter: 42300, loss: 30.365345001220703\n",
      "epoch: 1, iter: 42400, loss: 30.014999389648438\n",
      "epoch: 1, iter: 42500, loss: 30.675006866455078\n",
      "epoch: 1, iter: 42600, loss: 30.673110961914062\n",
      "epoch: 1, iter: 42700, loss: 30.019596099853516\n",
      "epoch: 1, iter: 42800, loss: 30.996145248413086\n",
      "epoch: 1, iter: 42900, loss: 30.58327865600586\n",
      "epoch: 1, iter: 43000, loss: 30.423633575439453\n",
      "epoch: 1, iter: 43100, loss: 30.311504364013672\n",
      "epoch: 1, iter: 43200, loss: 30.454811096191406\n",
      "epoch: 1, iter: 43300, loss: 30.582988739013672\n",
      "epoch: 1, iter: 43400, loss: 30.6115779876709\n",
      "epoch: 1, iter: 43500, loss: 30.322906494140625\n",
      "epoch: 1, iter: 43600, loss: 30.54576301574707\n",
      "epoch: 1, iter: 43700, loss: 30.5471134185791\n",
      "epoch: 1, iter: 43800, loss: 30.774654388427734\n",
      "epoch: 1, iter: 43900, loss: 30.09152603149414\n",
      "epoch: 1, iter: 44000, loss: 30.336124420166016\n",
      "epoch: 1, iter: 44100, loss: 30.967924118041992\n",
      "epoch: 1, iter: 44200, loss: 30.086278915405273\n",
      "epoch: 1, iter: 44300, loss: 30.77555274963379\n",
      "epoch: 1, iter: 44400, loss: 30.13079071044922\n",
      "epoch: 1, iter: 44500, loss: 30.413503646850586\n",
      "epoch: 1, iter: 44600, loss: 30.231937408447266\n",
      "epoch: 1, iter: 44700, loss: 30.569734573364258\n",
      "epoch: 1, iter: 44800, loss: 30.046470642089844\n",
      "epoch: 1, iter: 44900, loss: 30.177112579345703\n",
      "epoch: 1, iter: 45000, loss: 30.64748191833496\n",
      "epoch: 1, iter: 45100, loss: 30.80302619934082\n",
      "epoch: 1, iter: 45200, loss: 31.02594566345215\n",
      "epoch: 1, iter: 45300, loss: 30.047555923461914\n",
      "epoch: 1, iter: 45400, loss: 30.791927337646484\n",
      "epoch: 1, iter: 45500, loss: 30.21674919128418\n",
      "epoch: 1, iter: 45600, loss: 30.446969985961914\n",
      "epoch: 1, iter: 45700, loss: 30.833541870117188\n",
      "epoch: 1, iter: 45800, loss: 30.735305786132812\n",
      "epoch: 1, iter: 45900, loss: 30.32754898071289\n",
      "epoch: 1, iter: 46000, loss: 30.2409725189209\n",
      "epoch: 1, iter: 46100, loss: 30.316896438598633\n",
      "epoch: 1, iter: 46200, loss: 30.631887435913086\n",
      "epoch: 1, iter: 46300, loss: 30.465167999267578\n",
      "epoch: 1, iter: 46400, loss: 30.189706802368164\n",
      "epoch: 1, iter: 46500, loss: 30.52279281616211\n",
      "epoch: 1, iter: 46600, loss: 30.152774810791016\n",
      "epoch: 1, iter: 46700, loss: 30.522144317626953\n",
      "epoch: 1, iter: 46800, loss: 30.648229598999023\n",
      "epoch: 1, iter: 46900, loss: 30.710981369018555\n",
      "epoch: 1, iter: 47000, loss: 29.85228157043457\n",
      "epoch: 1, iter: 47100, loss: 30.517202377319336\n",
      "epoch: 1, iter: 47200, loss: 30.798213958740234\n",
      "epoch: 1, iter: 47300, loss: 30.325448989868164\n",
      "epoch: 1, iter: 47400, loss: 30.771602630615234\n",
      "epoch: 1, iter: 47500, loss: 30.32245635986328\n",
      "epoch: 1, iter: 47600, loss: 30.38846206665039\n",
      "epoch: 1, iter: 47700, loss: 30.23231315612793\n",
      "epoch: 1, iter: 47800, loss: 30.540729522705078\n",
      "epoch: 1, iter: 47900, loss: 30.670547485351562\n",
      "epoch: 1, iter: 48000, loss: 30.507753372192383\n",
      "epoch: 1, iter: 48100, loss: 31.076183319091797\n",
      "epoch: 1, iter: 48200, loss: 30.595279693603516\n",
      "epoch: 1, iter: 48300, loss: 30.414134979248047\n",
      "epoch: 1, iter: 48400, loss: 30.680709838867188\n",
      "epoch: 1, iter: 48500, loss: 30.53091049194336\n",
      "epoch: 1, iter: 48600, loss: 30.07793617248535\n",
      "epoch: 1, iter: 48700, loss: 31.15222930908203\n",
      "epoch: 1, iter: 48800, loss: 30.339330673217773\n",
      "epoch: 1, iter: 48900, loss: 30.130935668945312\n",
      "epoch: 1, iter: 49000, loss: 30.874717712402344\n",
      "epoch: 1, iter: 49100, loss: 30.374967575073242\n",
      "epoch: 1, iter: 49200, loss: 30.79701042175293\n",
      "epoch: 1, iter: 49300, loss: 29.859079360961914\n",
      "epoch: 1, iter: 49400, loss: 30.303001403808594\n",
      "epoch: 1, iter: 49500, loss: 30.628271102905273\n",
      "epoch: 1, iter: 49600, loss: 30.10057830810547\n",
      "epoch: 1, iter: 49700, loss: 30.81802749633789\n",
      "epoch: 1, iter: 49800, loss: 30.060148239135742\n",
      "epoch: 1, iter: 49900, loss: 30.59162712097168\n",
      "epoch: 1, iter: 50000, loss: 30.40926170349121\n",
      "epoch: 1, iter: 50100, loss: 30.813440322875977\n",
      "epoch: 1, iter: 50200, loss: 30.350154876708984\n",
      "epoch: 1, iter: 50300, loss: 30.913026809692383\n",
      "epoch: 1, iter: 50400, loss: 30.677593231201172\n",
      "epoch: 1, iter: 50500, loss: 30.444351196289062\n",
      "epoch: 1, iter: 50600, loss: 30.277328491210938\n",
      "epoch: 1, iter: 50700, loss: 30.674362182617188\n",
      "epoch: 1, iter: 50800, loss: 30.91777801513672\n",
      "epoch: 1, iter: 50900, loss: 30.436033248901367\n",
      "epoch: 1, iter: 51000, loss: 30.19267463684082\n",
      "epoch: 1, iter: 51100, loss: 30.479904174804688\n",
      "epoch: 1, iter: 51200, loss: 30.3010196685791\n",
      "epoch: 1, iter: 51300, loss: 31.008459091186523\n",
      "epoch: 1, iter: 51400, loss: 30.76485252380371\n",
      "epoch: 1, iter: 51500, loss: 30.078453063964844\n",
      "epoch: 1, iter: 51600, loss: 30.544727325439453\n",
      "epoch: 1, iter: 51700, loss: 30.659799575805664\n",
      "epoch: 1, iter: 51800, loss: 30.428543090820312\n",
      "epoch: 1, iter: 51900, loss: 30.230682373046875\n",
      "epoch: 1, iter: 52000, loss: 30.290679931640625\n",
      "epoch: 1, iter: 52100, loss: 30.257221221923828\n",
      "epoch: 1, iter: 52200, loss: 31.085861206054688\n",
      "epoch: 1, iter: 52300, loss: 30.87493133544922\n",
      "epoch: 1, iter: 52400, loss: 30.08088493347168\n",
      "epoch: 1, iter: 52500, loss: 30.655197143554688\n",
      "epoch: 1, iter: 52600, loss: 30.588768005371094\n",
      "epoch: 1, iter: 52700, loss: 30.907670974731445\n",
      "epoch: 1, iter: 52800, loss: 30.61322021484375\n",
      "epoch: 1, iter: 52900, loss: 30.829286575317383\n",
      "epoch: 1, iter: 53000, loss: 30.351917266845703\n",
      "epoch: 1, iter: 53100, loss: 30.43603515625\n",
      "epoch: 1, iter: 53200, loss: 30.84954071044922\n",
      "epoch: 1, iter: 53300, loss: 30.820653915405273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, iter: 53400, loss: 30.636764526367188\n",
      "epoch: 1, iter: 53500, loss: 30.41672706604004\n",
      "epoch: 1, iter: 53600, loss: 30.121938705444336\n",
      "epoch: 1, iter: 53700, loss: 30.12906265258789\n",
      "epoch: 1, iter: 53800, loss: 30.263370513916016\n",
      "epoch: 1, iter: 53900, loss: 30.39374542236328\n",
      "epoch: 1, iter: 54000, loss: 30.63083267211914\n",
      "epoch: 1, iter: 54100, loss: 30.913244247436523\n",
      "epoch: 1, iter: 54200, loss: 30.351009368896484\n",
      "epoch: 1, iter: 54300, loss: 30.269506454467773\n",
      "epoch: 1, iter: 54400, loss: 30.370874404907227\n",
      "epoch: 1, iter: 54500, loss: 30.889720916748047\n",
      "epoch: 1, iter: 54600, loss: 30.222816467285156\n",
      "epoch: 1, iter: 54700, loss: 30.6479549407959\n",
      "epoch: 1, iter: 54800, loss: 30.750118255615234\n",
      "epoch: 1, iter: 54900, loss: 30.138599395751953\n",
      "epoch: 1, iter: 55000, loss: 30.798246383666992\n",
      "epoch: 1, iter: 55100, loss: 30.780776977539062\n",
      "epoch: 1, iter: 55200, loss: 30.994680404663086\n",
      "epoch: 1, iter: 55300, loss: 30.043785095214844\n",
      "epoch: 1, iter: 55400, loss: 30.59393310546875\n",
      "epoch: 1, iter: 55500, loss: 30.228639602661133\n",
      "epoch: 1, iter: 55600, loss: 30.402381896972656\n",
      "epoch: 1, iter: 55700, loss: 30.168148040771484\n",
      "epoch: 1, iter: 55800, loss: 29.70488739013672\n",
      "epoch: 1, iter: 55900, loss: 30.137643814086914\n",
      "epoch: 1, iter: 56000, loss: 30.590831756591797\n",
      "epoch: 1, iter: 56100, loss: 30.773775100708008\n",
      "epoch: 1, iter: 56200, loss: 29.998140335083008\n",
      "epoch: 1, iter: 56300, loss: 29.94550323486328\n",
      "epoch: 1, iter: 56400, loss: 30.502103805541992\n",
      "epoch: 1, iter: 56500, loss: 30.047496795654297\n",
      "epoch: 1, iter: 56600, loss: 30.5257568359375\n",
      "epoch: 1, iter: 56700, loss: 30.58146858215332\n",
      "epoch: 1, iter: 56800, loss: 30.48436737060547\n",
      "epoch: 1, iter: 56900, loss: 30.437103271484375\n",
      "epoch: 1, iter: 57000, loss: 29.82017707824707\n",
      "epoch: 1, iter: 57100, loss: 30.359474182128906\n",
      "epoch: 1, iter: 57200, loss: 30.472517013549805\n",
      "epoch: 1, iter: 57300, loss: 30.35908317565918\n",
      "epoch: 1, iter: 57400, loss: 30.11188316345215\n",
      "epoch: 1, iter: 57500, loss: 30.61446762084961\n",
      "epoch: 1, iter: 57600, loss: 30.191381454467773\n",
      "epoch: 1, iter: 57700, loss: 30.338632583618164\n",
      "epoch: 1, iter: 57800, loss: 30.38064193725586\n",
      "epoch: 1, iter: 57900, loss: 31.150802612304688\n",
      "epoch: 1, iter: 58000, loss: 30.394275665283203\n",
      "epoch: 1, iter: 58100, loss: 30.449758529663086\n",
      "epoch: 1, iter: 58200, loss: 30.76979637145996\n",
      "epoch: 1, iter: 58300, loss: 30.723785400390625\n",
      "epoch: 1, iter: 58400, loss: 30.625394821166992\n",
      "epoch: 1, iter: 58500, loss: 30.474340438842773\n",
      "epoch: 1, iter: 58600, loss: 30.57107925415039\n",
      "epoch: 1, iter: 58700, loss: 30.318056106567383\n",
      "epoch: 1, iter: 58800, loss: 30.845726013183594\n",
      "epoch: 1, iter: 58900, loss: 30.47364616394043\n",
      "epoch: 1, iter: 59000, loss: 30.07771873474121\n",
      "epoch: 1, iter: 59100, loss: 30.754776000976562\n",
      "epoch: 1, iter: 59200, loss: 30.583141326904297\n",
      "epoch: 1, iter: 59300, loss: 30.6114501953125\n",
      "epoch: 1, iter: 59400, loss: 30.635513305664062\n",
      "epoch: 1, iter: 59500, loss: 30.231403350830078\n",
      "epoch: 1, iter: 59600, loss: 30.44651222229004\n",
      "epoch: 1, iter: 59700, loss: 30.37082290649414\n",
      "epoch: 1, iter: 59800, loss: 30.041778564453125\n",
      "epoch: 1, iter: 59900, loss: 30.119462966918945\n",
      "epoch: 1, iter: 60000, loss: 30.735504150390625\n",
      "epoch: 1, iter: 60100, loss: 30.484922409057617\n",
      "epoch: 1, iter: 60200, loss: 30.052030563354492\n",
      "epoch: 1, iter: 60300, loss: 30.46146011352539\n",
      "epoch: 1, iter: 60400, loss: 30.567340850830078\n",
      "epoch: 1, iter: 60500, loss: 30.382110595703125\n",
      "epoch: 1, iter: 60600, loss: 30.23341941833496\n",
      "epoch: 1, iter: 60700, loss: 30.313199996948242\n",
      "epoch: 1, iter: 60800, loss: 30.50081443786621\n",
      "epoch: 1, iter: 60900, loss: 30.10613250732422\n",
      "epoch: 1, iter: 61000, loss: 30.50251007080078\n",
      "epoch: 1, iter: 61100, loss: 30.174528121948242\n",
      "epoch: 1, iter: 61200, loss: 30.73162269592285\n",
      "epoch: 1, iter: 61300, loss: 30.144655227661133\n",
      "epoch: 1, iter: 61400, loss: 30.248180389404297\n",
      "epoch: 1, iter: 61500, loss: 30.033233642578125\n",
      "epoch: 1, iter: 61600, loss: 30.2045955657959\n",
      "epoch: 1, iter: 61700, loss: 30.3883056640625\n",
      "epoch: 1, iter: 61800, loss: 30.15802574157715\n",
      "epoch: 1, iter: 61900, loss: 30.64572525024414\n",
      "epoch: 1, iter: 62000, loss: 30.403112411499023\n",
      "epoch: 1, iter: 62100, loss: 30.674089431762695\n",
      "epoch: 1, iter: 62200, loss: 30.75604248046875\n",
      "epoch: 1, iter: 62300, loss: 30.889135360717773\n",
      "epoch: 1, iter: 62400, loss: 30.47696304321289\n",
      "epoch: 1, iter: 62500, loss: 30.278430938720703\n",
      "epoch: 1, iter: 62600, loss: 30.327638626098633\n",
      "epoch: 1, iter: 62700, loss: 31.104848861694336\n",
      "epoch: 1, iter: 62800, loss: 30.914854049682617\n",
      "epoch: 1, iter: 62900, loss: 30.486698150634766\n",
      "epoch: 1, iter: 63000, loss: 30.642534255981445\n",
      "epoch: 1, iter: 63100, loss: 30.354448318481445\n",
      "epoch: 1, iter: 63200, loss: 30.60367774963379\n",
      "epoch: 1, iter: 63300, loss: 30.554645538330078\n",
      "epoch: 1, iter: 63400, loss: 30.760114669799805\n",
      "epoch: 1, iter: 63500, loss: 30.296926498413086\n",
      "epoch: 1, iter: 63600, loss: 29.821510314941406\n",
      "epoch: 1, iter: 63700, loss: 29.733346939086914\n",
      "epoch: 1, iter: 63800, loss: 30.756784439086914\n",
      "epoch: 1, iter: 63900, loss: 30.32729148864746\n",
      "epoch: 1, iter: 64000, loss: 30.55672836303711\n",
      "epoch: 1, iter: 64100, loss: 30.22893714904785\n",
      "epoch: 1, iter: 64200, loss: 30.422428131103516\n",
      "epoch: 1, iter: 64300, loss: 30.76600456237793\n",
      "epoch: 1, iter: 64400, loss: 30.26150894165039\n",
      "epoch: 1, iter: 64500, loss: 30.527538299560547\n",
      "epoch: 1, iter: 64600, loss: 30.35605812072754\n",
      "epoch: 1, iter: 64700, loss: 30.345754623413086\n",
      "epoch: 1, iter: 64800, loss: 30.446319580078125\n",
      "epoch: 1, iter: 64900, loss: 30.180038452148438\n",
      "epoch: 1, iter: 65000, loss: 30.79827117919922\n",
      "epoch: 1, iter: 65100, loss: 30.87726593017578\n",
      "epoch: 1, iter: 65200, loss: 30.265430450439453\n",
      "epoch: 1, iter: 65300, loss: 30.416675567626953\n",
      "epoch: 1, iter: 65400, loss: 30.27136993408203\n",
      "epoch: 1, iter: 65500, loss: 30.567792892456055\n",
      "epoch: 1, iter: 65600, loss: 30.33649253845215\n",
      "epoch: 1, iter: 65700, loss: 30.90211296081543\n",
      "epoch: 1, iter: 65800, loss: 30.169950485229492\n",
      "epoch: 1, iter: 65900, loss: 30.366363525390625\n",
      "epoch: 1, iter: 66000, loss: 30.519262313842773\n",
      "epoch: 1, iter: 66100, loss: 30.166898727416992\n",
      "epoch: 1, iter: 66200, loss: 30.551944732666016\n",
      "epoch: 1, iter: 66300, loss: 29.626678466796875\n",
      "epoch: 1, iter: 66400, loss: 30.589778900146484\n",
      "epoch: 1, iter: 66500, loss: 30.421945571899414\n",
      "epoch: 1, iter: 66600, loss: 30.647947311401367\n",
      "epoch: 1, iter: 66700, loss: 30.36995506286621\n",
      "epoch: 1, iter: 66800, loss: 30.555675506591797\n",
      "epoch: 1, iter: 66900, loss: 30.165260314941406\n",
      "epoch: 1, iter: 67000, loss: 30.712203979492188\n",
      "epoch: 1, iter: 67100, loss: 31.031688690185547\n",
      "epoch: 1, iter: 67200, loss: 30.573991775512695\n",
      "epoch: 1, iter: 67300, loss: 30.573453903198242\n",
      "epoch: 1, iter: 67400, loss: 30.428878784179688\n",
      "epoch: 1, iter: 67500, loss: 30.765153884887695\n",
      "epoch: 1, iter: 67600, loss: 30.536209106445312\n",
      "epoch: 1, iter: 67700, loss: 30.31056022644043\n",
      "epoch: 1, iter: 67800, loss: 30.440303802490234\n",
      "epoch: 1, iter: 67900, loss: 30.47879409790039\n",
      "epoch: 1, iter: 68000, loss: 30.510244369506836\n",
      "epoch: 1, iter: 68100, loss: 30.79482650756836\n",
      "epoch: 1, iter: 68200, loss: 30.460330963134766\n",
      "epoch: 1, iter: 68300, loss: 30.289478302001953\n",
      "epoch: 1, iter: 68400, loss: 30.186288833618164\n",
      "epoch: 1, iter: 68500, loss: 30.541351318359375\n",
      "epoch: 1, iter: 68600, loss: 30.386863708496094\n",
      "epoch: 1, iter: 68700, loss: 30.813365936279297\n",
      "epoch: 1, iter: 68800, loss: 30.04252052307129\n",
      "epoch: 1, iter: 68900, loss: 30.336057662963867\n",
      "epoch: 1, iter: 69000, loss: 30.65456199645996\n",
      "epoch: 1, iter: 69100, loss: 30.62702178955078\n",
      "epoch: 1, iter: 69200, loss: 30.179330825805664\n",
      "epoch: 1, iter: 69300, loss: 30.734416961669922\n",
      "epoch: 1, iter: 69400, loss: 30.707366943359375\n",
      "epoch: 1, iter: 69500, loss: 31.235488891601562\n",
      "epoch: 1, iter: 69600, loss: 30.55866050720215\n",
      "epoch: 1, iter: 69700, loss: 30.52281379699707\n",
      "epoch: 1, iter: 69800, loss: 30.665546417236328\n",
      "epoch: 1, iter: 69900, loss: 30.721416473388672\n",
      "epoch: 1, iter: 70000, loss: 30.542301177978516\n",
      "epoch: 1, iter: 70100, loss: 30.4296932220459\n",
      "epoch: 1, iter: 70200, loss: 30.41008758544922\n",
      "epoch: 1, iter: 70300, loss: 30.553653717041016\n",
      "epoch: 1, iter: 70400, loss: 30.40019416809082\n",
      "epoch: 1, iter: 70500, loss: 30.247516632080078\n",
      "epoch: 1, iter: 70600, loss: 30.1279239654541\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, iter: 70700, loss: 30.16600799560547\n",
      "epoch: 1, iter: 70800, loss: 31.183349609375\n",
      "epoch: 1, iter: 70900, loss: 30.591449737548828\n",
      "epoch: 1, iter: 71000, loss: 30.225963592529297\n",
      "epoch: 1, iter: 71100, loss: 30.788251876831055\n",
      "epoch: 1, iter: 71200, loss: 29.75831413269043\n",
      "epoch: 1, iter: 71300, loss: 30.115829467773438\n",
      "epoch: 1, iter: 71400, loss: 30.414857864379883\n",
      "epoch: 1, iter: 71500, loss: 30.734912872314453\n",
      "epoch: 1, iter: 71600, loss: 30.05133056640625\n",
      "epoch: 1, iter: 71700, loss: 29.749170303344727\n",
      "epoch: 1, iter: 71800, loss: 30.840194702148438\n",
      "epoch: 1, iter: 71900, loss: 30.2999324798584\n",
      "epoch: 1, iter: 72000, loss: 30.25675392150879\n",
      "epoch: 1, iter: 72100, loss: 30.026107788085938\n",
      "epoch: 1, iter: 72200, loss: 30.221410751342773\n",
      "epoch: 1, iter: 72300, loss: 31.193042755126953\n",
      "epoch: 1, iter: 72400, loss: 30.52434730529785\n",
      "epoch: 1, iter: 72500, loss: 30.21171760559082\n",
      "epoch: 1, iter: 72600, loss: 30.864728927612305\n",
      "epoch: 1, iter: 72700, loss: 29.95269203186035\n",
      "epoch: 1, iter: 72800, loss: 30.351465225219727\n",
      "epoch: 1, iter: 72900, loss: 30.352619171142578\n",
      "epoch: 1, iter: 73000, loss: 30.238628387451172\n",
      "epoch: 1, iter: 73100, loss: 30.50385856628418\n",
      "epoch: 1, iter: 73200, loss: 30.560144424438477\n",
      "epoch: 1, iter: 73300, loss: 30.099822998046875\n",
      "epoch: 1, iter: 73400, loss: 30.3656005859375\n",
      "epoch: 1, iter: 73500, loss: 30.546781539916992\n",
      "epoch: 1, iter: 73600, loss: 30.30428695678711\n",
      "epoch: 1, iter: 73700, loss: 30.513202667236328\n",
      "epoch: 1, iter: 73800, loss: 30.982330322265625\n",
      "epoch: 1, iter: 73900, loss: 30.498476028442383\n",
      "epoch: 1, iter: 74000, loss: 30.094654083251953\n",
      "epoch: 1, iter: 74100, loss: 30.96308135986328\n",
      "epoch: 1, iter: 74200, loss: 30.727188110351562\n",
      "epoch: 1, iter: 74300, loss: 30.247821807861328\n",
      "epoch: 1, iter: 74400, loss: 30.601438522338867\n",
      "epoch: 1, iter: 74500, loss: 30.035564422607422\n",
      "epoch: 1, iter: 74600, loss: 30.120811462402344\n",
      "epoch: 1, iter: 74700, loss: 30.181825637817383\n",
      "epoch: 1, iter: 74800, loss: 30.37913703918457\n",
      "epoch: 1, iter: 74900, loss: 30.57356834411621\n",
      "epoch: 1, iter: 75000, loss: 30.21506118774414\n",
      "epoch: 1, iter: 75100, loss: 30.36924934387207\n",
      "epoch: 1, iter: 75200, loss: 30.960172653198242\n",
      "epoch: 1, iter: 75300, loss: 30.609663009643555\n",
      "epoch: 1, iter: 75400, loss: 30.93850326538086\n",
      "epoch: 1, iter: 75500, loss: 30.866161346435547\n",
      "epoch: 1, iter: 75600, loss: 30.07329559326172\n",
      "epoch: 1, iter: 75700, loss: 30.310016632080078\n",
      "epoch: 1, iter: 75800, loss: 30.39911651611328\n",
      "epoch: 1, iter: 75900, loss: 30.79131507873535\n",
      "epoch: 1, iter: 76000, loss: 30.58469581604004\n",
      "epoch: 1, iter: 76100, loss: 30.190448760986328\n",
      "epoch: 1, iter: 76200, loss: 30.404998779296875\n",
      "epoch: 1, iter: 76300, loss: 30.75896644592285\n",
      "epoch: 1, iter: 76400, loss: 30.7967586517334\n",
      "epoch: 1, iter: 76500, loss: 30.49815559387207\n",
      "epoch: 1, iter: 76600, loss: 30.435415267944336\n",
      "epoch: 1, iter: 76700, loss: 30.75322151184082\n",
      "epoch: 1, iter: 76800, loss: 30.1884708404541\n",
      "epoch: 1, iter: 76900, loss: 30.08530044555664\n",
      "epoch: 1, iter: 77000, loss: 30.550344467163086\n",
      "epoch: 1, iter: 77100, loss: 29.907506942749023\n",
      "epoch: 1, iter: 77200, loss: 30.2344970703125\n",
      "epoch: 1, iter: 77300, loss: 31.119873046875\n",
      "epoch: 1, iter: 77400, loss: 30.18850326538086\n",
      "epoch: 1, iter: 77500, loss: 30.72948455810547\n",
      "epoch: 1, iter: 77600, loss: 30.909976959228516\n",
      "epoch: 1, iter: 77700, loss: 30.56422233581543\n",
      "epoch: 1, iter: 77800, loss: 30.447877883911133\n",
      "epoch: 1, iter: 77900, loss: 30.187461853027344\n",
      "epoch: 1, iter: 78000, loss: 29.96015739440918\n",
      "epoch: 1, iter: 78100, loss: 30.65516471862793\n",
      "epoch: 1, iter: 78200, loss: 30.69933319091797\n",
      "epoch: 1, iter: 78300, loss: 30.203128814697266\n",
      "epoch: 1, iter: 78400, loss: 30.365888595581055\n",
      "epoch: 1, iter: 78500, loss: 29.948894500732422\n",
      "epoch: 1, iter: 78600, loss: 30.34050750732422\n",
      "epoch: 1, iter: 78700, loss: 30.440187454223633\n",
      "epoch: 1, iter: 78800, loss: 30.25627326965332\n",
      "epoch: 1, iter: 78900, loss: 30.947052001953125\n",
      "epoch: 1, iter: 79000, loss: 30.23166275024414\n",
      "epoch: 1, iter: 79100, loss: 29.967185974121094\n",
      "epoch: 1, iter: 79200, loss: 30.490598678588867\n",
      "epoch: 1, iter: 79300, loss: 30.380558013916016\n",
      "epoch: 1, iter: 79400, loss: 30.766727447509766\n",
      "epoch: 1, iter: 79500, loss: 30.240629196166992\n",
      "epoch: 1, iter: 79600, loss: 30.2783145904541\n",
      "epoch: 1, iter: 79700, loss: 30.639379501342773\n",
      "epoch: 1, iter: 79800, loss: 30.50143051147461\n",
      "epoch: 1, iter: 79900, loss: 30.058704376220703\n",
      "epoch: 1, iter: 80000, loss: 29.972450256347656\n",
      "epoch: 1, iter: 80100, loss: 30.311275482177734\n",
      "epoch: 1, iter: 80200, loss: 30.43866539001465\n",
      "epoch: 1, iter: 80300, loss: 30.736522674560547\n",
      "epoch: 1, iter: 80400, loss: 30.69866180419922\n",
      "epoch: 1, iter: 80500, loss: 30.46001434326172\n",
      "epoch: 1, iter: 80600, loss: 30.33167266845703\n",
      "epoch: 1, iter: 80700, loss: 30.734039306640625\n",
      "epoch: 1, iter: 80800, loss: 30.05256462097168\n",
      "epoch: 1, iter: 80900, loss: 30.614429473876953\n",
      "epoch: 1, iter: 81000, loss: 30.88721466064453\n",
      "epoch: 1, iter: 81100, loss: 30.014141082763672\n",
      "epoch: 1, iter: 81200, loss: 30.97422218322754\n",
      "epoch: 1, iter: 81300, loss: 30.65877914428711\n",
      "epoch: 1, iter: 81400, loss: 30.381452560424805\n",
      "epoch: 1, iter: 81500, loss: 31.04953956604004\n",
      "epoch: 1, iter: 81600, loss: 30.643718719482422\n",
      "epoch: 1, iter: 81700, loss: 30.52318000793457\n",
      "epoch: 1, iter: 81800, loss: 30.07030487060547\n",
      "epoch: 1, iter: 81900, loss: 30.322662353515625\n",
      "epoch: 1, iter: 82000, loss: 30.253093719482422\n",
      "epoch: 1, iter: 82100, loss: 30.4664363861084\n",
      "epoch: 1, iter: 82200, loss: 30.315780639648438\n",
      "epoch: 1, iter: 82300, loss: 30.062484741210938\n",
      "epoch: 1, iter: 82400, loss: 30.60272216796875\n",
      "epoch: 1, iter: 82500, loss: 30.396217346191406\n",
      "epoch: 1, iter: 82600, loss: 30.15776252746582\n",
      "epoch: 1, iter: 82700, loss: 30.050289154052734\n",
      "epoch: 1, iter: 82800, loss: 30.730316162109375\n",
      "epoch: 1, iter: 82900, loss: 29.92969512939453\n",
      "epoch: 1, iter: 83000, loss: 30.29527473449707\n",
      "epoch: 1, iter: 83100, loss: 30.25787925720215\n",
      "epoch: 1, iter: 83200, loss: 30.306047439575195\n",
      "epoch: 1, iter: 83300, loss: 30.331787109375\n",
      "epoch: 1, iter: 83400, loss: 30.266965866088867\n",
      "epoch: 1, iter: 83500, loss: 30.51712989807129\n",
      "epoch: 1, iter: 83600, loss: 30.48470115661621\n",
      "epoch: 1, iter: 83700, loss: 30.081857681274414\n",
      "epoch: 1, iter: 83800, loss: 30.38753890991211\n",
      "epoch: 1, iter: 83900, loss: 30.146059036254883\n",
      "epoch: 1, iter: 84000, loss: 31.044172286987305\n",
      "epoch: 1, iter: 84100, loss: 30.053918838500977\n",
      "epoch: 1, iter: 84200, loss: 30.451753616333008\n",
      "epoch: 1, iter: 84300, loss: 30.60870361328125\n",
      "epoch: 1, iter: 84400, loss: 30.692989349365234\n",
      "epoch: 1, iter: 84500, loss: 30.34242820739746\n",
      "epoch: 1, iter: 84600, loss: 30.344160079956055\n",
      "epoch: 1, iter: 84700, loss: 30.07901382446289\n",
      "epoch: 1, iter: 84800, loss: 30.778120040893555\n",
      "epoch: 1, iter: 84900, loss: 30.219152450561523\n",
      "epoch: 1, iter: 85000, loss: 30.27910041809082\n",
      "epoch: 1, iter: 85100, loss: 29.539627075195312\n",
      "epoch: 1, iter: 85200, loss: 30.74110984802246\n",
      "epoch: 1, iter: 85300, loss: 29.752012252807617\n",
      "epoch: 1, iter: 85400, loss: 30.384862899780273\n",
      "epoch: 1, iter: 85500, loss: 30.16025161743164\n",
      "epoch: 1, iter: 85600, loss: 30.407163619995117\n",
      "epoch: 1, iter: 85700, loss: 30.210006713867188\n",
      "epoch: 1, iter: 85800, loss: 30.340526580810547\n",
      "epoch: 1, iter: 85900, loss: 30.441762924194336\n",
      "epoch: 1, iter: 86000, loss: 30.41437530517578\n",
      "epoch: 1, iter: 86100, loss: 30.46278190612793\n",
      "epoch: 1, iter: 86200, loss: 30.642375946044922\n",
      "epoch: 1, iter: 86300, loss: 30.338516235351562\n",
      "epoch: 1, iter: 86400, loss: 29.784210205078125\n",
      "epoch: 1, iter: 86500, loss: 30.38555335998535\n",
      "epoch: 1, iter: 86600, loss: 30.50635528564453\n",
      "epoch: 1, iter: 86700, loss: 30.099681854248047\n",
      "epoch: 1, iter: 86800, loss: 30.609241485595703\n",
      "epoch: 1, iter: 86900, loss: 29.75034523010254\n",
      "epoch: 1, iter: 87000, loss: 30.291431427001953\n",
      "epoch: 1, iter: 87100, loss: 30.354894638061523\n",
      "epoch: 1, iter: 87200, loss: 30.43152618408203\n",
      "epoch: 1, iter: 87300, loss: 30.534866333007812\n",
      "epoch: 1, iter: 87400, loss: 30.205917358398438\n",
      "epoch: 1, iter: 87500, loss: 30.492847442626953\n",
      "epoch: 1, iter: 87600, loss: 30.519554138183594\n",
      "epoch: 1, iter: 87700, loss: 30.47796630859375\n",
      "epoch: 1, iter: 87800, loss: 30.210498809814453\n",
      "epoch: 1, iter: 87900, loss: 30.800277709960938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, iter: 88000, loss: 30.622028350830078\n",
      "epoch: 1, iter: 88100, loss: 30.535669326782227\n",
      "epoch: 1, iter: 88200, loss: 30.221040725708008\n",
      "epoch: 1, iter: 88300, loss: 30.317367553710938\n",
      "epoch: 1, iter: 88400, loss: 30.19761848449707\n",
      "epoch: 1, iter: 88500, loss: 30.48804473876953\n",
      "epoch: 1, iter: 88600, loss: 30.860395431518555\n",
      "epoch: 1, iter: 88700, loss: 31.044105529785156\n",
      "epoch: 1, iter: 88800, loss: 30.652788162231445\n",
      "epoch: 1, iter: 88900, loss: 30.680356979370117\n",
      "epoch: 1, iter: 89000, loss: 30.222814559936523\n",
      "epoch: 1, iter: 89100, loss: 30.2125244140625\n",
      "epoch: 1, iter: 89200, loss: 30.532150268554688\n",
      "epoch: 1, iter: 89300, loss: 30.421567916870117\n",
      "epoch: 1, iter: 89400, loss: 30.806224822998047\n",
      "epoch: 1, iter: 89500, loss: 30.464120864868164\n",
      "epoch: 1, iter: 89600, loss: 30.079832077026367\n",
      "epoch: 1, iter: 89700, loss: 30.178625106811523\n",
      "epoch: 1, iter: 89800, loss: 30.632232666015625\n",
      "epoch: 1, iter: 89900, loss: 30.290834426879883\n",
      "epoch: 1, iter: 90000, loss: 30.19477081298828\n",
      "epoch: 1, iter: 90100, loss: 30.711105346679688\n",
      "epoch: 1, iter: 90200, loss: 30.15572166442871\n",
      "epoch: 1, iter: 90300, loss: 30.250228881835938\n",
      "epoch: 1, iter: 90400, loss: 30.30948257446289\n",
      "epoch: 1, iter: 90500, loss: 30.477998733520508\n",
      "epoch: 1, iter: 90600, loss: 30.713268280029297\n",
      "epoch: 1, iter: 90700, loss: 30.92864990234375\n",
      "epoch: 1, iter: 90800, loss: 30.612567901611328\n",
      "epoch: 1, iter: 90900, loss: 30.98495864868164\n",
      "epoch: 1, iter: 91000, loss: 30.394418716430664\n",
      "epoch: 1, iter: 91100, loss: 30.481494903564453\n",
      "epoch: 1, iter: 91200, loss: 30.37108039855957\n",
      "epoch: 1, iter: 91300, loss: 30.464462280273438\n",
      "epoch: 1, iter: 91400, loss: 30.159841537475586\n",
      "epoch: 1, iter: 91500, loss: 30.65635871887207\n",
      "epoch: 1, iter: 91600, loss: 30.542499542236328\n",
      "epoch: 1, iter: 91700, loss: 30.349468231201172\n",
      "epoch: 1, iter: 91800, loss: 30.19397735595703\n",
      "epoch: 1, iter: 91900, loss: 29.938575744628906\n",
      "epoch: 1, iter: 92000, loss: 30.019235610961914\n",
      "epoch: 1, iter: 92100, loss: 30.727954864501953\n",
      "epoch: 1, iter: 92200, loss: 30.17649269104004\n",
      "epoch: 1, iter: 92300, loss: 30.226972579956055\n",
      "epoch: 1, iter: 92400, loss: 30.233285903930664\n",
      "epoch: 1, iter: 92500, loss: 30.609094619750977\n",
      "epoch: 1, iter: 92600, loss: 30.36417579650879\n",
      "epoch: 1, iter: 92700, loss: 30.342243194580078\n",
      "epoch: 1, iter: 92800, loss: 29.92962646484375\n",
      "epoch: 1, iter: 92900, loss: 30.610153198242188\n",
      "epoch: 1, iter: 93000, loss: 30.845762252807617\n",
      "epoch: 1, iter: 93100, loss: 30.806766510009766\n",
      "epoch: 1, iter: 93200, loss: 31.014219284057617\n",
      "epoch: 1, iter: 93300, loss: 30.600866317749023\n",
      "epoch: 1, iter: 93400, loss: 30.415061950683594\n",
      "epoch: 1, iter: 93500, loss: 29.860088348388672\n",
      "epoch: 1, iter: 93600, loss: 30.4263973236084\n",
      "epoch: 1, iter: 93700, loss: 30.12486457824707\n",
      "epoch: 1, iter: 93800, loss: 29.96918296813965\n",
      "epoch: 1, iter: 93900, loss: 30.12778091430664\n",
      "epoch: 1, iter: 94000, loss: 30.002540588378906\n",
      "epoch: 1, iter: 94100, loss: 30.20210838317871\n",
      "epoch: 1, iter: 94200, loss: 30.977214813232422\n",
      "epoch: 1, iter: 94300, loss: 30.55582618713379\n",
      "epoch: 1, iter: 94400, loss: 30.145366668701172\n",
      "epoch: 1, iter: 94500, loss: 30.67055320739746\n",
      "epoch: 1, iter: 94600, loss: 30.1098575592041\n",
      "epoch: 1, iter: 94700, loss: 30.89596939086914\n",
      "epoch: 1, iter: 94800, loss: 30.4053955078125\n",
      "epoch: 1, iter: 94900, loss: 30.709819793701172\n",
      "epoch: 1, iter: 95000, loss: 30.216655731201172\n",
      "epoch: 1, iter: 95100, loss: 30.606929779052734\n",
      "epoch: 1, iter: 95200, loss: 29.995468139648438\n",
      "epoch: 1, iter: 95300, loss: 30.23760986328125\n",
      "epoch: 1, iter: 95400, loss: 30.2121524810791\n",
      "epoch: 1, iter: 95500, loss: 30.432193756103516\n",
      "epoch: 1, iter: 95600, loss: 30.620079040527344\n",
      "epoch: 1, iter: 95700, loss: 30.2227725982666\n",
      "epoch: 1, iter: 95800, loss: 30.535001754760742\n",
      "epoch: 1, iter: 95900, loss: 30.595027923583984\n",
      "epoch: 1, iter: 96000, loss: 29.91016387939453\n",
      "epoch: 1, iter: 96100, loss: 30.293075561523438\n",
      "epoch: 1, iter: 96200, loss: 30.521303176879883\n",
      "epoch: 1, iter: 96300, loss: 30.39607810974121\n",
      "epoch: 1, iter: 96400, loss: 30.098386764526367\n",
      "epoch: 1, iter: 96500, loss: 30.658655166625977\n",
      "epoch: 1, iter: 96600, loss: 30.304241180419922\n",
      "epoch: 1, iter: 96700, loss: 30.09971809387207\n",
      "epoch: 1, iter: 96800, loss: 30.683788299560547\n",
      "epoch: 1, iter: 96900, loss: 30.667211532592773\n",
      "epoch: 1, iter: 97000, loss: 30.709537506103516\n",
      "epoch: 1, iter: 97100, loss: 30.33319091796875\n",
      "epoch: 1, iter: 97200, loss: 30.066720962524414\n",
      "epoch: 1, iter: 97300, loss: 30.625749588012695\n",
      "epoch: 1, iter: 97400, loss: 29.962862014770508\n",
      "epoch: 1, iter: 97500, loss: 30.850671768188477\n",
      "epoch: 1, iter: 97600, loss: 30.153995513916016\n",
      "epoch: 1, iter: 97700, loss: 30.403488159179688\n",
      "epoch: 1, iter: 97800, loss: 30.53845977783203\n",
      "epoch: 1, iter: 97900, loss: 30.205148696899414\n",
      "epoch: 1, iter: 98000, loss: 30.32813835144043\n",
      "epoch: 1, iter: 98100, loss: 30.348472595214844\n",
      "epoch: 1, iter: 98200, loss: 30.837242126464844\n",
      "epoch: 1, iter: 98300, loss: 29.900787353515625\n",
      "epoch: 1, iter: 98400, loss: 30.248422622680664\n",
      "epoch: 1, iter: 98500, loss: 30.518470764160156\n",
      "epoch: 1, iter: 98600, loss: 30.999372482299805\n",
      "epoch: 1, iter: 98700, loss: 30.02832794189453\n",
      "epoch: 1, iter: 98800, loss: 30.202543258666992\n",
      "epoch: 1, iter: 98900, loss: 30.554683685302734\n",
      "epoch: 1, iter: 99000, loss: 30.607112884521484\n",
      "epoch: 1, iter: 99100, loss: 30.550514221191406\n",
      "epoch: 1, iter: 99200, loss: 30.201196670532227\n",
      "epoch: 1, iter: 99300, loss: 30.828351974487305\n",
      "epoch: 1, iter: 99400, loss: 30.603620529174805\n",
      "epoch: 1, iter: 99500, loss: 30.130599975585938\n",
      "epoch: 1, iter: 99600, loss: 29.96300506591797\n",
      "epoch: 1, iter: 99700, loss: 30.67007827758789\n",
      "epoch: 1, iter: 99800, loss: 30.615427017211914\n",
      "epoch: 1, iter: 99900, loss: 30.324005126953125\n",
      "epoch: 1, iter: 100000, loss: 30.13285255432129\n",
      "epoch: 1, iter: 100100, loss: 31.09637451171875\n",
      "epoch: 1, iter: 100200, loss: 30.5378360748291\n",
      "epoch: 1, iter: 100300, loss: 29.933517456054688\n",
      "epoch: 1, iter: 100400, loss: 30.08753204345703\n",
      "epoch: 1, iter: 100500, loss: 30.45780372619629\n",
      "epoch: 1, iter: 100600, loss: 30.901609420776367\n",
      "epoch: 1, iter: 100700, loss: 30.71097183227539\n",
      "epoch: 1, iter: 100800, loss: 30.577743530273438\n",
      "epoch: 1, iter: 100900, loss: 30.209918975830078\n",
      "epoch: 1, iter: 101000, loss: 30.190500259399414\n",
      "epoch: 1, iter: 101100, loss: 30.185958862304688\n",
      "epoch: 1, iter: 101200, loss: 29.640838623046875\n",
      "epoch: 1, iter: 101300, loss: 30.574398040771484\n",
      "epoch: 1, iter: 101400, loss: 30.39850425720215\n",
      "epoch: 1, iter: 101500, loss: 30.2584171295166\n",
      "epoch: 1, iter: 101600, loss: 29.97443962097168\n",
      "epoch: 1, iter: 101700, loss: 29.936752319335938\n",
      "epoch: 1, iter: 101800, loss: 30.457050323486328\n",
      "epoch: 1, iter: 101900, loss: 30.433368682861328\n",
      "epoch: 1, iter: 102000, loss: 30.6328125\n",
      "epoch: 1, iter: 102100, loss: 30.27060890197754\n",
      "epoch: 1, iter: 102200, loss: 30.695995330810547\n",
      "epoch: 1, iter: 102300, loss: 30.483518600463867\n",
      "epoch: 1, iter: 102400, loss: 30.37261962890625\n",
      "epoch: 1, iter: 102500, loss: 29.948402404785156\n",
      "epoch: 1, iter: 102600, loss: 30.79597282409668\n",
      "epoch: 1, iter: 102700, loss: 30.51368522644043\n",
      "epoch: 1, iter: 102800, loss: 30.878387451171875\n",
      "epoch: 1, iter: 102900, loss: 29.92729949951172\n",
      "epoch: 1, iter: 103000, loss: 30.604267120361328\n",
      "epoch: 1, iter: 103100, loss: 30.804948806762695\n",
      "epoch: 1, iter: 103200, loss: 31.156021118164062\n",
      "epoch: 1, iter: 103300, loss: 30.046192169189453\n",
      "epoch: 1, iter: 103400, loss: 30.030010223388672\n",
      "epoch: 1, iter: 103500, loss: 30.12049674987793\n",
      "epoch: 1, iter: 103600, loss: 30.442899703979492\n",
      "epoch: 1, iter: 103700, loss: 30.353551864624023\n",
      "epoch: 1, iter: 103800, loss: 30.605058670043945\n",
      "epoch: 1, iter: 103900, loss: 30.182842254638672\n",
      "epoch: 1, iter: 104000, loss: 30.547935485839844\n",
      "epoch: 1, iter: 104100, loss: 30.432960510253906\n",
      "epoch: 1, iter: 104200, loss: 30.57921600341797\n",
      "epoch: 1, iter: 104300, loss: 30.669456481933594\n",
      "epoch: 1, iter: 104400, loss: 30.10702896118164\n",
      "epoch: 1, iter: 104500, loss: 29.83172607421875\n",
      "epoch: 1, iter: 104600, loss: 29.651905059814453\n",
      "epoch: 1, iter: 104700, loss: 30.62567138671875\n",
      "epoch: 1, iter: 104800, loss: 30.26267433166504\n",
      "epoch: 1, iter: 104900, loss: 30.359939575195312\n",
      "epoch: 1, iter: 105000, loss: 30.14834213256836\n",
      "epoch: 1, iter: 105100, loss: 30.80293083190918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, iter: 105200, loss: 30.59814453125\n",
      "epoch: 1, iter: 105300, loss: 31.09385108947754\n",
      "epoch: 1, iter: 105400, loss: 30.71389389038086\n",
      "epoch: 1, iter: 105500, loss: 30.132606506347656\n",
      "epoch: 1, iter: 105600, loss: 30.67302703857422\n",
      "epoch: 1, iter: 105700, loss: 30.170761108398438\n",
      "epoch: 1, iter: 105800, loss: 30.473005294799805\n",
      "epoch: 1, iter: 105900, loss: 30.78424835205078\n",
      "epoch: 1, iter: 106000, loss: 30.167783737182617\n",
      "epoch: 1, iter: 106100, loss: 30.344383239746094\n",
      "epoch: 1, iter: 106200, loss: 30.43816375732422\n",
      "epoch: 1, iter: 106300, loss: 29.755826950073242\n",
      "epoch: 1, iter: 106400, loss: 30.154783248901367\n",
      "epoch: 1, iter: 106500, loss: 30.50189208984375\n",
      "epoch: 1, iter: 106600, loss: 30.070846557617188\n",
      "epoch: 1, iter: 106700, loss: 30.227800369262695\n",
      "epoch: 1, iter: 106800, loss: 30.58196449279785\n",
      "epoch: 1, iter: 106900, loss: 30.158279418945312\n",
      "epoch: 1, iter: 107000, loss: 29.916120529174805\n",
      "epoch: 1, iter: 107100, loss: 30.114656448364258\n",
      "epoch: 1, iter: 107200, loss: 30.10445785522461\n",
      "epoch: 1, iter: 107300, loss: 30.048194885253906\n",
      "epoch: 1, iter: 107400, loss: 29.876283645629883\n",
      "epoch: 1, iter: 107500, loss: 29.805849075317383\n",
      "epoch: 1, iter: 107600, loss: 29.855667114257812\n",
      "epoch: 1, iter: 107700, loss: 30.13275909423828\n",
      "epoch: 1, iter: 107800, loss: 30.089113235473633\n",
      "epoch: 1, iter: 107900, loss: 30.143016815185547\n",
      "epoch: 1, iter: 108000, loss: 30.305234909057617\n",
      "epoch: 1, iter: 108100, loss: 30.40914535522461\n",
      "epoch: 1, iter: 108200, loss: 30.22026824951172\n",
      "epoch: 1, iter: 108300, loss: 30.362998962402344\n",
      "epoch: 1, iter: 108400, loss: 30.220813751220703\n",
      "epoch: 1, iter: 108500, loss: 30.41436767578125\n",
      "epoch: 1, iter: 108600, loss: 30.35293960571289\n",
      "epoch: 1, iter: 108700, loss: 30.680408477783203\n",
      "epoch: 1, iter: 108800, loss: 30.682523727416992\n",
      "epoch: 1, iter: 108900, loss: 30.374858856201172\n",
      "epoch: 1, iter: 109000, loss: 29.887956619262695\n",
      "epoch: 1, iter: 109100, loss: 30.33063316345215\n",
      "epoch: 1, iter: 109200, loss: 30.353565216064453\n",
      "epoch: 1, iter: 109300, loss: 30.715301513671875\n",
      "epoch: 1, iter: 109400, loss: 30.66729736328125\n",
      "epoch: 1, iter: 109500, loss: 30.148406982421875\n",
      "epoch: 1, iter: 109600, loss: 30.1328125\n",
      "epoch: 1, iter: 109700, loss: 30.30843162536621\n",
      "epoch: 1, iter: 109800, loss: 30.54330825805664\n",
      "epoch: 1, iter: 109900, loss: 30.38875961303711\n",
      "epoch: 1, iter: 110000, loss: 30.122398376464844\n",
      "epoch: 1, iter: 110100, loss: 30.079103469848633\n",
      "epoch: 1, iter: 110200, loss: 30.65056610107422\n",
      "epoch: 1, iter: 110300, loss: 30.262603759765625\n",
      "epoch: 1, iter: 110400, loss: 29.993078231811523\n",
      "epoch: 1, iter: 110500, loss: 30.53595542907715\n",
      "epoch: 1, iter: 110600, loss: 30.128704071044922\n",
      "epoch: 1, iter: 110700, loss: 29.580955505371094\n",
      "epoch: 1, iter: 110800, loss: 30.3508243560791\n",
      "epoch: 1, iter: 110900, loss: 30.397409439086914\n",
      "epoch: 1, iter: 111000, loss: 30.104385375976562\n",
      "epoch: 1, iter: 111100, loss: 30.415294647216797\n",
      "epoch: 1, iter: 111200, loss: 30.17923355102539\n",
      "epoch: 1, iter: 111300, loss: 30.74176788330078\n",
      "epoch: 1, iter: 111400, loss: 30.486955642700195\n",
      "epoch: 1, iter: 111500, loss: 30.73497200012207\n",
      "epoch: 1, iter: 111600, loss: 30.554729461669922\n",
      "epoch: 1, iter: 111700, loss: 30.257770538330078\n",
      "epoch: 1, iter: 111800, loss: 30.183378219604492\n",
      "epoch: 1, iter: 111900, loss: 30.266780853271484\n",
      "epoch: 1, iter: 112000, loss: 30.138404846191406\n",
      "epoch: 1, iter: 112100, loss: 30.228683471679688\n",
      "epoch: 1, iter: 112200, loss: 30.507226943969727\n",
      "epoch: 1, iter: 112300, loss: 30.691587448120117\n",
      "epoch: 1, iter: 112400, loss: 30.36788558959961\n",
      "epoch: 1, iter: 112500, loss: 30.592010498046875\n",
      "epoch: 1, iter: 112600, loss: 30.787109375\n",
      "epoch: 1, iter: 112700, loss: 30.045944213867188\n",
      "epoch: 1, iter: 112800, loss: 30.457002639770508\n",
      "epoch: 1, iter: 112900, loss: 29.957157135009766\n",
      "epoch: 1, iter: 113000, loss: 30.776405334472656\n",
      "epoch: 1, iter: 113100, loss: 30.642433166503906\n",
      "epoch: 1, iter: 113200, loss: 30.84912109375\n",
      "epoch: 1, iter: 113300, loss: 30.27685546875\n",
      "epoch: 1, iter: 113400, loss: 30.80552101135254\n",
      "epoch: 1, iter: 113500, loss: 30.428821563720703\n",
      "epoch: 1, iter: 113600, loss: 30.460918426513672\n",
      "epoch: 1, iter: 113700, loss: 30.245582580566406\n",
      "epoch: 1, iter: 113800, loss: 30.617900848388672\n",
      "epoch: 1, iter: 113900, loss: 30.752792358398438\n",
      "epoch: 1, iter: 114000, loss: 30.62793731689453\n",
      "epoch: 1, iter: 114100, loss: 30.157663345336914\n",
      "epoch: 1, iter: 114200, loss: 29.87978172302246\n",
      "epoch: 1, iter: 114300, loss: 31.0101318359375\n",
      "epoch: 1, iter: 114400, loss: 30.33450698852539\n",
      "epoch: 1, iter: 114500, loss: 30.077293395996094\n",
      "epoch: 1, iter: 114600, loss: 30.319000244140625\n",
      "epoch: 1, iter: 114700, loss: 30.63218879699707\n",
      "epoch: 1, iter: 114800, loss: 30.362998962402344\n",
      "epoch: 1, iter: 114900, loss: 30.471498489379883\n",
      "epoch: 1, iter: 115000, loss: 29.909128189086914\n",
      "epoch: 1, iter: 115100, loss: 30.47178077697754\n",
      "epoch: 1, iter: 115200, loss: 30.66302490234375\n",
      "epoch: 1, iter: 115300, loss: 30.423093795776367\n",
      "epoch: 1, iter: 115400, loss: 30.487022399902344\n",
      "epoch: 1, iter: 115500, loss: 30.522539138793945\n",
      "epoch: 1, iter: 115600, loss: 30.66838836669922\n",
      "epoch: 1, iter: 115700, loss: 29.974790573120117\n",
      "epoch: 1, iter: 115800, loss: 29.85453987121582\n",
      "epoch: 1, iter: 115900, loss: 30.353740692138672\n",
      "epoch: 1, iter: 116000, loss: 30.010963439941406\n",
      "epoch: 1, iter: 116100, loss: 30.414159774780273\n",
      "epoch: 1, iter: 116200, loss: 30.51902961730957\n",
      "epoch: 1, iter: 116300, loss: 29.943992614746094\n",
      "epoch: 1, iter: 116400, loss: 30.40375518798828\n",
      "epoch: 1, iter: 116500, loss: 30.30113410949707\n",
      "epoch: 1, iter: 116600, loss: 29.950721740722656\n",
      "epoch: 1, iter: 116700, loss: 30.362524032592773\n",
      "epoch: 1, iter: 116800, loss: 30.3818302154541\n",
      "epoch: 1, iter: 116900, loss: 30.345703125\n",
      "epoch: 1, iter: 117000, loss: 29.989721298217773\n",
      "epoch: 1, iter: 117100, loss: 30.211746215820312\n",
      "epoch: 1, iter: 117200, loss: 30.524404525756836\n",
      "epoch: 1, iter: 117300, loss: 30.259044647216797\n",
      "epoch: 1, iter: 117400, loss: 30.26878547668457\n",
      "epoch: 1, iter: 117500, loss: 30.387704849243164\n",
      "epoch: 1, iter: 117600, loss: 30.744915008544922\n",
      "epoch: 1, iter: 117700, loss: 30.643516540527344\n",
      "epoch: 1, iter: 117800, loss: 29.759199142456055\n",
      "epoch: 1, iter: 117900, loss: 30.36412811279297\n",
      "epoch: 1, iter: 118000, loss: 30.66568374633789\n",
      "epoch: 1, iter: 118100, loss: 30.419078826904297\n",
      "epoch: 1, iter: 118200, loss: 30.518779754638672\n",
      "epoch: 1, iter: 118300, loss: 29.760757446289062\n",
      "epoch: 1, iter: 118400, loss: 30.380847930908203\n",
      "epoch: 1, iter: 118500, loss: 29.943628311157227\n",
      "epoch: 1, iter: 118600, loss: 30.351470947265625\n",
      "epoch: 1, iter: 118700, loss: 30.246414184570312\n",
      "epoch: 1, iter: 118800, loss: 30.570680618286133\n",
      "epoch: 1, iter: 118900, loss: 29.978002548217773\n",
      "epoch: 1, iter: 119000, loss: 30.582979202270508\n",
      "epoch: 1, iter: 119100, loss: 30.235795974731445\n",
      "epoch: 1, iter: 119200, loss: 30.31627082824707\n",
      "epoch: 1, iter: 119300, loss: 30.20663070678711\n",
      "epoch: 1, iter: 119400, loss: 30.194395065307617\n",
      "epoch: 1, iter: 119500, loss: 30.013647079467773\n"
     ]
    }
   ],
   "source": [
    "#训练部分的代码\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE)\n",
    "for e in range(NUM_EPOCHS):\n",
    "    for i, (input_labels, pos_labels, neg_labels) in enumerate(dataloader):\n",
    "        \n",
    "        \n",
    "        # TODO\n",
    "        input_labels = input_labels.long()\n",
    "        pos_labels = pos_labels.long()\n",
    "        neg_labels = neg_labels.long()\n",
    "        if USE_CUDA:\n",
    "            input_labels = input_labels.cuda()\n",
    "            pos_labels = pos_labels.cuda()\n",
    "            neg_labels = neg_labels.cuda()\n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "        '''平均的loss'''\n",
    "        loss = model(input_labels, pos_labels, neg_labels).mean()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            with open(LOG_FILE, \"a\") as fout:\n",
    "                fout.write(\"epoch: {}, iter: {}, loss: {}\\n\".format(e, i, loss.item()))\n",
    "                print(\"epoch: {}, iter: {}, loss: {}\".format(e, i, loss.item()))\n",
    "            \n",
    "        \n",
    "                \n",
    "    embedding_weights = model.input_embeddings()\n",
    "    np.save(\"embedding-{}\".format(EMBEDDING_SIZE), embedding_weights)\n",
    "    torch.save(model.state_dict(), \"embedding-{}.th\".format(EMBEDDING_SIZE))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good ['good', 'bad', 'alone', 'perfect', 'experience', 'hard', 'truth', 'money', 'really', 'poor']\n",
      "fresh ['fresh', 'grain', 'dense', 'lighter', 'waste', 'noise', 'cooling', 'sized', 'mild', 'rigid']\n",
      "monster ['monster', 'giant', 'robot', 'blade', 'stone', 'clown', 'hammer', 'bull', 'ghost', 'finger']\n",
      "green ['green', 'blue', 'yellow', 'white', 'cross', 'orange', 'red', 'black', 'snow', 'mountain']\n",
      "like ['like', 'etc', 'unlike', 'animals', 'amongst', 'soft', 'whereas', 'rich', 'eat', 'similarly']\n",
      "america ['america', 'africa', 'korea', 'india', 'turkey', 'australia', 'pakistan', 'indian', 'argentina', 'carolina']\n",
      "chicago ['chicago', 'boston', 'london', 'texas', 'illinois', 'indiana', 'massachusetts', 'florida', 'ohio', 'pennsylvania']\n",
      "work ['work', 'writing', 'job', 'marx', 'solo', 'nietzsche', 'writings', 'vision', 'appearance', 'songs']\n",
      "computer ['computer', 'digital', 'audio', 'electronic', 'video', 'graphics', 'hardware', 'computers', 'software', 'program']\n",
      "language ['language', 'languages', 'alphabet', 'arabic', 'grammar', 'dialect', 'pronunciation', 'spelling', 'spoken', 'programming']\n"
     ]
    }
   ],
   "source": [
    "# 训练好了就可以用于做相关性的测试，导入训练好的权重，就可以得到下面的结果。\n",
    "model.load_state_dict(torch.load(\"embedding-{}.th\".format(EMBEDDING_SIZE)))\n",
    "embedding_weights = model.input_embeddings()\n",
    "for word in [\"good\", \"fresh\", \"monster\", \"green\", \"like\", \"america\", \"chicago\", \"work\", \"computer\", \"language\"]:\n",
    "    print(word, find_nearest(word))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

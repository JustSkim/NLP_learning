{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# NLP句子相似性方法总结及实现\n",
    "## 基于Word2Vec的余弦相似度\n",
    "对句子分词，使用Gensim的Word2Vec训练词向量，获取每个词对应的词向量，然后将所有的词向量相加求平均，得到句子向量，最后计算两个句子向量的余弦值(余弦相似度)。\n",
    "余弦相似度：用向量空间中的两个向量夹角的余弦值作为衡量两个个体间差异大小的度量，值越接近1，就说明夹角角度越接近0°，也就是两个向量越相似。\n",
    "公式：$similarity = cos(θ)=\\frac{A·B}{\\|A\\| \\|B\\|}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#对每个句子的所有词向量取均值，来生成一个句子的vector\n",
    "#sentence是输入的句子，size是词向量维度，w2v_model是训练好的词向量模型\n",
    "def build_sentence_vector(sentence,size,w2v_model):\n",
    "    vec=np.zeros(size).reshape((1,size))\n",
    "    count=0\n",
    "    for word in sentence:\n",
    "        try:\n",
    "            vec+=w2v_model[word].reshape((1,size))\n",
    "            count+=1\n",
    "        except KeyError:\n",
    "            continue\n",
    "    if count!=0:\n",
    "        vec/=count\n",
    "    return vec\n",
    "\n",
    "#计算两个句向量的余弦相似性值\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    a= np.array(vec1)\n",
    "    b= np.array(vec2)\n",
    "    cos1 = np.sum(a * b)\n",
    "    cos21 = np.sqrt(sum(a ** 2))\n",
    "    cos22 = np.sqrt(sum(b ** 2))\n",
    "    cosine_value = cos1 / float(cos21 * cos22)\n",
    "    return cosine_value\n",
    "\n",
    "#输入两个句子，计算两个句子的余弦相似性\n",
    "def compute_cosine_similarity(sents_1, sents_2):\n",
    "    size=300\n",
    "    w2v_model=Word2Vec.load('w2v_model.pkl')\n",
    "    vec1=build_sentence_vector(sents_1,size,w2v_model)\n",
    "    vec2=build_sentence_vector(sents_2,size,w2v_model)\n",
    "    similarity = cosine_similarity(vec1, vec2)\n",
    "    return similarity\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## TextRank算法中的句子相似性\n",
    "**句子相似性公式**：\n",
    "![句子相似性公式](https://img-blog.csdnimg.cn/20190730214711448.png)\n",
    "其中，$S_i$，$S_j$分别表示两个句子，$w_k$表示句子中的词，那么:\n",
    "- 分子部分的意思,是同时出现在两个句子中的相同词的个数\n",
    "- 分母:对句子中词的个数求对数之和。\n",
    "分母这样设计，可以**遏制较长的句子在相似度计算上的优势**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "def two_sentences_similarity(sents_1, sents_2):\n",
    "    counter = 0\n",
    "    for sent in sents_1:\n",
    "        if sent in sents_2:\n",
    "            counter += 1\n",
    "    sents_similarity=counter/(math.log(len(sents_1))+math.log(len(sents_2)))\n",
    "    return sents_similarity"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 莱文斯坦距离\n",
    "莱文斯坦（Levenshtein）距离，是编辑距离（edit distance）的一种，作用是描述**由一个字串转化成另一个字串最少的编辑操作次数**（操作包括插入、删除和替换）。\n",
    "\n",
    "举例：要将\"kitten\"转成\"sitting\"，经历以下三步，所以二者的莱文斯坦距离为3：\n",
    "1. sitten（k替换为→s）\n",
    "2. sittin （e替换为→i）\n",
    "3. sitting （添加→g）\n",
    "\n",
    "**使用python计算莱文斯坦距离**\n",
    "可以使用python_Levenshtein包进行计算，需要在[whl文件下载网站](https://www.lfd.uci.edu/~gohlke/pythonlibs/#python-levenshtein)中找到适合的版本下载，\n",
    "或者直接使用`pip install python_levenshtein`\n",
    "\n",
    "在下载安装的时候可能遇到报错：`error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/`\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import Levenshtein\n",
    "s1='kitten'\n",
    "s2='sitting'\n",
    "lev_distance=Levenshtein.distance(s1,s2)\n",
    "print(lev_distance)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 莱文斯坦比\n",
    "莱文斯坦比计算公式$r = (sum - ldist) / sum$， 其中sum是指str1 和 str2 字串的长度总和，ldist是类编辑距离。\n",
    "注意：这里的类编辑距离不是上面所说的编辑距离，上面的文档中是三种操作中每个操作+1。而在此处，删除、插入依然+1，但是**替换+2**。\n",
    "这样设计的目的：`ratio('a', 'c')`，`sum=2`,按上面旧方法计算为（2-1）/2 = 0.5,’a','c'没有重合，显然不合算，但是替换操作设为+2，就可以解决这个问题。\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 汉明距离\n",
    "描述两个等长字串之间对应位置上不同字符的个数，前提要求str1和str2必须长度一致。\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import Levenshtein\n",
    "s1='abc'\n",
    "s2='cba'\n",
    "lev_distance=Levenshtein.hamming(s1,s2)\n",
    "print(lev_distance)\n",
    "#结果输出为2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Jaro距离（Jaro Distance）\n",
    "一种计算两个字符串之间相似度的方法，计算公式如下所示：\n",
    "![Jaro距离](https://img-blog.csdnimg.cn/20190731220233984.png)\n",
    "其中，m为S1和S2的匹配长度（即匹配的字符数），t是换位的数目；如果m=0，则dj=0。\n",
    "如果两个分别来自S1和S2的字符如果相距不超过：\n",
    "![](https://img-blog.csdnimg.cn/2019073122075282.png)\n",
    "那么就认为这两个字符串是匹配的；而这些相互匹配的字符则决定了换位的数目t，简单来说就是不同顺序的匹配字符的数目的一半即为换位的数目t。\n",
    "\n",
    "举例：MARTHA与MARHTA的字符都是匹配的，但是这些匹配的字符中，T和H要换位才能把MARTHA变为MARHTA，那么T和H就是不同的顺序的匹配字符，t=2/2=1。那么这两个字符串的Jaro Distance即为：\n",
    "![](https://img-blog.csdnimg.cn/20190731221138386.png)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import Levenshtein\n",
    "s1='MARTHA'\n",
    "s2='MARHTA'\n",
    "lev_distance=Levenshtein.jaro(s1,s2)\n",
    "print(lev_distance)\n",
    "#结果输出为0.9444"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Jaro-Winkler距离（Jaro-Winkler Distance）\n",
    "Jaro-Winkler Distance给予了起始部分就相同的字符串更高的分数，他定义了一个前缀p，计算公式如下：\n",
    "![](https://img-blog.csdnimg.cn/20190731222044972.png)\n",
    "\n",
    "其中，$d_j$是两个字符串的Jaro Distance，是前缀的相同的长度，但是**规定最大为4**，p则是调整分数的常数，规定不能超过0.25，不然可能出现$d_w$大于1的情况，Winkler将这个常数定义为0.1。\n",
    "\n",
    "举例计算：MARTHA和MARHTA的Jaro-Winkler Distance为：$d_w = 0.944 + (3 * 0.1(1 − 0.944)) = 0.961$\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/w2v/doc2vec_model.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_17384\\3253950105.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mgensim\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmodels\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdoc2vec\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mDoc2Vec\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m \u001B[0md2v_model\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mDoc2Vec\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mload\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'data/w2v/doc2vec_model.pkl'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      3\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[1;31m#推断一个句子的向量\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[0msen_vec1\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0md2v_model\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0minfer_vector\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'挺 菜品 单一 扇贝 好吃 水果 太少 服务 服务员 服务 挺 开心'\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msplit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mG:\\anaconda3\\envs\\py37\\lib\\site-packages\\gensim\\models\\doc2vec.py\u001B[0m in \u001B[0;36mload\u001B[1;34m(cls, *args, **kwargs)\u001B[0m\n\u001B[0;32m    807\u001B[0m         \"\"\"\n\u001B[0;32m    808\u001B[0m         \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 809\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0msuper\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mDoc2Vec\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcls\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mload\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mrethrow\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    810\u001B[0m         \u001B[1;32mexcept\u001B[0m \u001B[0mAttributeError\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mae\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    811\u001B[0m             logger.error(\n",
      "\u001B[1;32mG:\\anaconda3\\envs\\py37\\lib\\site-packages\\gensim\\models\\word2vec.py\u001B[0m in \u001B[0;36mload\u001B[1;34m(cls, rethrow, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1937\u001B[0m         \"\"\"\n\u001B[0;32m   1938\u001B[0m         \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1939\u001B[1;33m             \u001B[0mmodel\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0msuper\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mWord2Vec\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcls\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mload\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1940\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0misinstance\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mWord2Vec\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1941\u001B[0m                 \u001B[0mrethrow\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mTrue\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mG:\\anaconda3\\envs\\py37\\lib\\site-packages\\gensim\\utils.py\u001B[0m in \u001B[0;36mload\u001B[1;34m(cls, fname, mmap)\u001B[0m\n\u001B[0;32m    484\u001B[0m         \u001B[0mcompress\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msubname\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mSaveLoad\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_adapt_by_suffix\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfname\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    485\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 486\u001B[1;33m         \u001B[0mobj\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0munpickle\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfname\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    487\u001B[0m         \u001B[0mobj\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_load_specials\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfname\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmmap\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcompress\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msubname\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    488\u001B[0m         \u001B[0mobj\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0madd_lifecycle_event\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"loaded\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfname\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mfname\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mG:\\anaconda3\\envs\\py37\\lib\\site-packages\\gensim\\utils.py\u001B[0m in \u001B[0;36munpickle\u001B[1;34m(fname)\u001B[0m\n\u001B[0;32m   1458\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1459\u001B[0m     \"\"\"\n\u001B[1;32m-> 1460\u001B[1;33m     \u001B[1;32mwith\u001B[0m \u001B[0mopen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfname\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'rb'\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mf\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1461\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0m_pickle\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mload\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mf\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mencoding\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'latin1'\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# needed because loading from S3 doesn't support readline()\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1462\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mG:\\anaconda3\\envs\\py37\\lib\\site-packages\\smart_open\\smart_open_lib.py\u001B[0m in \u001B[0;36mopen\u001B[1;34m(uri, mode, buffering, encoding, errors, newline, closefd, opener, compression, transport_params)\u001B[0m\n\u001B[0;32m    182\u001B[0m         \u001B[0mencoding\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mencoding\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    183\u001B[0m         \u001B[0merrors\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0merrors\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 184\u001B[1;33m         \u001B[0mnewline\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mnewline\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    185\u001B[0m     )\n\u001B[0;32m    186\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mfobj\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mG:\\anaconda3\\envs\\py37\\lib\\site-packages\\smart_open\\smart_open_lib.py\u001B[0m in \u001B[0;36m_shortcut_open\u001B[1;34m(uri, mode, compression, buffering, encoding, errors, newline)\u001B[0m\n\u001B[0;32m    361\u001B[0m         \u001B[0mopen_kwargs\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'errors'\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0merrors\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    362\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 363\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0m_builtin_open\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlocal_path\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmode\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbuffering\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mbuffering\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mopen_kwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    364\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    365\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'data/w2v/doc2vec_model.pkl'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "基于Doc2Vec的句子相似度计算\n",
    "\"\"\"\n",
    "from gensim.models.doc2vec import Doc2Vec\n",
    "#必须先加载模型\n",
    "d2v_model=Doc2Vec.load('data/w2v/doc2vec_model.pkl')\n",
    "\n",
    "#推断一个句子的向量\n",
    "sen_vec1=d2v_model.infer_vector('挺 菜品 单一 扇贝 好吃 水果 太少 服务 服务员 服务 挺 开心'.split())\n",
    "print(sen_vec1)\n",
    "\n",
    "#返回文档中和sen_vec句子最相似的前top个句子\n",
    "sen_similar=d2v_model.docvecs.most_similar([sen_vec1],topn=3)\n",
    "print(sen_similar)  #返回的是句子的编号和相似度\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}